[{"id":"b560fa9a3b1b6316fdcd91b0b326e0f3","title":"浪浪山打工人旅游指南（零）系列的起源","content":"\n“我想离开浪浪山”，小猪妖如是说道。\n每一个打工人都身处于困住自己的浪浪山里，在干着“大王让我来巡山”的工作，想要走出去闯闯，却要被身边的声音所左右。\n最终也没有勇气走出浪浪山，或者说当你离开这座浪浪山后，你会发现有无数个浪浪山……\n小猪妖的故事触动了很多打工人的心，让无数人直呼“这不是就是我嘛”。\n很多打工人在自己的浪浪山里漂泊着，在别人的眼中可能只是一块用来擦锅的抹布而已，在“猪妈妈”眼中却是最厉害的宝宝，小猪妖在面对这两种看法时，要平衡自己内心的失落，只能偶尔跟在妈妈面前抱怨一下，浪浪山就是个官僚思想严重的夕阳单位，不鼓励创新、等级制度森严、工作风险和压力贼大。\n但只有小猪妖自己知道，自己劳动不被认可，自己的价值不被认可，但是还是要被鞭策着不停干活，领导的PUA使得小猪妖曾一度怀疑自己的“猪生”，在浪浪山，他似乎已经没有了自我，也许他心底也认清了当下的局面，在领导心里自己只不过是一个“工具猪”而已，梦想什么的，离自己还是太遥远了。所以只能在自己一个人的时候，透过洞口望着天空,说想离开浪浪山，一辈子在这，终是无趣，不如出去闯闯。\n“离开浪浪山”，也并不是让我们割舍熟悉的生长之地。这更多的是一种向阳而生的梦想，可以是在精神世界中寻找无比广阔的外延，也可以是握紧自己的命运，去无畏地朝舒适圈挥手。纵马踏花向自由，若想离开，就不要在意嘲笑和羁绊，真正爱你的人会懂你的决定，而能决定生命如何度过的，也只有你自己。\n整理个浪浪山打工人旅游（跑路）指南，希望各位小猪妖、小兔妖、无名小妖找到自己的路。\n旅游指南：\n基础篇1.浪浪山打工人旅游指南（一）Java 面试题【汇总篇】\n进阶篇持续更新中\n专题篇持续更新中\n","slug":"浪浪山打工人/浪浪山打工人旅游指南（零）系列的起源","date":"2023-01-16T11:26:11.000Z","categories_index":"浪浪山打工人","tags_index":"JAVA,Java基础,Java面试题","author_index":"Anchor"},{"id":"d8253a8b0f6101721f69eb1f7316985f","title":"Mybatis一级缓存导致的内存溢出","content":"\n\n\n\n\n\n\n\n\n接上篇 Druid 监控导致的内存溢出问题定位处理 JVM 内存溢出相关，废话不多说直接上分析过程。\n\n\n1、服务器内存快照分析  首先通过快照查看最大的二十个对象如下图：  \n根据反馈数据可以发现前十个对象大小基本差不多，猜测应该由一个问题导致，点击去进一步定位问题。\n2、定位引起内存溢出的关键对象  发现引起内存溢出的对象很明确为 mybatis 的 PerpetualCache 对象：    \n3、分析引起内存溢出的原因\n猜测溢出\nPerpetualCache 其实是 Mybatis 的一级缓存对象，且全部为 HashMap 类型对象，所以可以大胆猜测是由于 Mybatis 一级缓存不正确使用造成的，敢于如此猜测是因为：\nMyBatis 对会话（Session）级别的一级缓存设计的比较简单，就简单地使用了 HashMap 来维护，并没有对 HashMap 的容量和大小进行限制。\n所以如果我们一直使用某一个 SqlSession 对象查询数据，这样会不会导致 HashMap 太大，而导致 java.lang.OutOfMemoryError 错误？\n\n\n\n验证溢出\nMybatis 的一级缓存是事务级别的，一旦事务提交就会清空。因此可能该线程的事务一直未结束和提交。那就从一个拥有大量查询业务繁杂的功能入手验证，结合二阶段定位到的零星线索，发现服务器内存溢出时正在处理的业务是数据下发，那我们就以次为入手点验证：\nA.首先设置 JVM 参数，为了尽快实现内存溢出效果，设定一个合适的参数，可根据本地环境调整：\n-server -XX:PermSize=256M -XX:MaxPermSize=256m\n-Xms300M -Xmx300M\n-Dcom.sun.management.jmxremote.port=8999\n-Dcom.sun.management.jmxremote.ssl=false\n-Dcom.sun.management.jmxremote.authenticate=false\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:HeapDumpPath=/Users/anchor/Downloads/dump/\n\nB.开启 Jvisualvm 监控，应用中开启下发业务，获取监控数据：\n如下图所示可以看到，本地程序在运行一段时间后已经处于假死状态，GC 回收活动频繁，可堆内存基本未见有效回收，CPU 过山车式的起伏，很快内存溢出了，至此可以得出结论我们找对了入手点：\n\n\n\n\n\n修改溢出\n加断点分析下发业务发现，下发业务存在大量 for 循环引发大量数据库查询操作，且该操作参数不重复，也就导致了 Mybatis 的一级缓存一直无法命中，所以正好验证我们的猜测，在一次下发请求中 Mybatis 创建了海量的缓存数据，改部分数据在下发业务完成之前是无法释放的，占用了大量的内存资源，如果此时刚好服务器内存有限很容易引发 GC overhead limit exceded 错误，进而造成服务假死内存溢出：\n\n\n\n  结合项目实际情况针对一级缓存的可利用率实在过低，由于参数一直变动，缓存命中几率极低，从 MyBatis 一级缓存来看，它以单纯的 HashMap 做缓存，没有容量控制，而一次 SqlSession 中通常来说并不会有大量的查询操作，因此只适用于一次 SqlSession，且项目中已开启二级缓存，所以我们考虑修改一级缓存规则：\n  &lt;!-设置一级缓存模式为STATEMENT，默认为SESSION，SESSION为会话级别，STATEMENT为SQL级别-&gt;\n&lt;setting name&#x3D;&quot;localCacheScope&quot; value&#x3D;&quot;STATEMENT&quot;&#x2F;&gt;\n&lt;!-PS：一级缓存的范围有SESSION和STATEMENT两种，默认是SESSION，如果我们不需要使用一级缓存，那么我们可以把一级缓存的范围指定为STATEMENT，这样每次执行完一个Mapper语句后都会将一级缓存清除。如果需要更改一级缓存的范围，请在Mybatis的配置文件中，在&lt;settings&gt;下通过localCacheScope指定。-&gt;\n\n\n\n再次验证\n启动项目，开启下发业务，打开监控，效果如下：\n\n\n\n  818 家门店下发业务正常完成，期间堆内存回收稳定，无溢出情况出现（坡度较陡是因为本地 JVM 内存设置较低，为提高内存利用率，GC 回收频繁）。\n4、总结\n疑问：既然一级缓存会导致内存溢出，为什么 Mybatis 还如此设计？\nMyBatis 这样设计也有它自己的理由：\n\n\n\n\n\n\n\n\n\na.一般而言 SqlSession 的生存时间很短。一般情况下使用一个 SqlSession 对象执行的操作不会太多，执行完就会消亡；\n\n\n\n\n\n\n\n\n\nb.对于某一个 SqlSession 对象而言，只要执行 update 操作（update、insert、delete），都会将这个 SqlSession 对象中对应的一级缓存清空掉，所以一般情况下不会出现缓存过大，影响 JVM 内存空间的问题；\n\n\n\n\n\n\n\n\n\nc.可以手动地释放掉 SqlSession 对象中的缓存。\n\n收获：Mybatis 一级缓存的存储流程\n\n\n\n\n\n\n\n\n\na.MyBatis 的一级缓存是 SqlSession 级别的，但是它并不定义在 SqlSessio 接口的实现类 DefaultSqlSession 中，而是定义在 DefaultSqlSession 的成员变量 Executor 中，Executor 是在 openSession 的时候被实例化出来的，它的默认实现为 SimpleExecutor。\n\n\n\n\n\n\n\n\n\nb.MyBatis 中的一级缓存，与有没有配置无关，只要 SqlSession 存在，MyBastis 一级缓存就存在，localCache 的类型是 PerpetualCache，它其实很简单，一个 id 属性+一个 HashMap 属性而已，id 是一个名为”localCache”的字符串，HashMap 用于存储数据，Key 为 CacheKey，Value 为查询结果。\n\n\n\n\n\n\n\n\n\nc.MyBatis 的一级缓存查询的时候默认都是会先尝试从一级缓存中获取数据的，即想每次查询都走 DB 也行，将&lt;select&gt;标签中的 flushCache 属性设置为 true 即可，这意味着每次查询的时候都会清理一遍 PerpetualCache，PerpetualCache 中没数据，自然只能走 DB。\n\n\n","slug":"Java/Mybatis一级缓存导致的内存溢出","date":"2018-09-29T12:06:29.000Z","categories_index":"JAVA","tags_index":"JVM,OOM,Mybatis","author_index":"Anchor"},{"id":"9736882d32005a945dbd1b55fb5920ee","title":"Druid监控导致的内存溢出问题定位处理","content":"0、起因  一台部署于商户私有云中的应用频繁宕机，经查为 OOM，周期大约一周一次，较规律，所谓千里之堤毁于蚁穴，初步怀疑是轻微的内存泄漏不断积累导致的内存溢出，所以再次宕机出现时果断 dump 内存镜像开始分析\n1、内存溢出原理\n常见内存溢出：\n相信通过写 java 程序讨生活的人对内存溢出并不陌生，先看三张图：\n\n\n\nHeap space（堆空间）\n\nPermgen（永久代）\n\n元空间（Metaspace）\n\nJVM 内存模型\n\n\n  Java 应用程序在启动时会指定所需要的内存大小，它被分割成两个不同的区域：Heap space（堆空间）和Permgen（永久代）。\n  java.lang.OutOfMemoryError\n\n  正如字面意思，当应用程序试图向这两个空间添加更多的数据，但却没有足够的空间来容纳这些数据时，将会触发java.lang.OutOfMemoryError。\n\n内存溢出原因分析\n1、java.lang.OutOfMemoryError: PermGen space\nPermGen space的全称是Permanent Generation space,是指内存的永久保存区域, 这块内存主要是被 JVM 存放 Class 和 Meta 信息的,Class 在被 Load 时就会被放到PermGen space中, 同时 GC(Garbage Collection)不会在主程序运行期对 PermGen space进行清理。\n所以如果你的应用中有很多 CLASS 的话,就很可能出现 PermGen space 错误。\n通过上面的描述就可以得出：如果要加载的 class 与 jar 文件大小超过-XX:MaxPermSize 就有可能会产生 java.lang.OutOfMemoryError: PermGen space 。\n换句话说-XX:MaxPermSize 的大小要超过 class 与 jar 的大小。\n2、java.lang.OutOfMemoryError: Java heap space\n虽然各种 java 虚拟机的实现机制不一,但是heap space内存溢出产生的原因相同：那就是堆内存不够虚拟机分配了。\n由于内存的分配机制与 GC 是有联系的，也就是说内存不够用时有部分内存 GC 肯定无法释放，而我们要找的就是为什么 GC 释放不了堆内存。\n所以当产生heap space内存溢出时，堆内存中对象数量过多的就可能是问题的根源了。例外的情况是，程序确实需要那么多内存，这时就要考虑增大堆内存。\n\n\n2、内存溢出时应该做什么\n收集案发现场数据，尽快恢复系统\n获取内存快照，根据适用场景有以下三种方式：\n1、使用 jmap 命令在案发现场手动生成 dump 文件\njmap -dump:format=b,file=heap.dump \\`pid of java\\`\n2、使用 JVM 参数自动在案发当场获取 dump 文件\n-XX:+HeapDumpOnOutOfMemoryError\n3、使用其它工具获取 dump 文件，主要针对本地开发环境：\n分析 Heap Dump 的工具都可以获取 Heap Dump 文件。比如：jdk 自带的工具 jvisualvm。其它工具：Eclipse memory analyzer（jmat）、JProfiler 等。\n\n本地复现之 jvisualvm 的使用\n无论是为了再现案发场景还是验证修复效果，都需要我们在本地环境中监控 JVM 的运行情况，SO 以我熟悉的jvisualvm为例，简单说下使用方法\n\n\n\n\n\n\n\n\n\nVisualVM 提供在 Java 虚拟机 (Java Virutal Machine, JVM) 上运行的 Java 应用程序的详细信息。在 VisualVM 的图形用户界面中，您可以方便、快捷地查看多个 Java 应用程序的相关信息。（摘自官方）简单说来，VisualVM 是一种集成了多个 JDK 命令行工具的可视化工具，它能为您提供强大的分析能力。所有这些都是免费的！它囊括的命令行工具包括 jstat, JConsole, jstack, jmap 和 jinfo，这些工具与 JDK 的标准版本是一致的。 可以使用 VisualVM 生成和分析海量数据、跟踪内存泄漏、监控垃圾回收器、执行内存和 CPU 分析。尽管 VisualVM 自身要在 JDK6 这个版本上运行，但是 JDK1.4 以上版本的程序它都能监控。VisualVM 的一个最大好处就是，它已经在你的 JDK bin 目录里了，只要你使用的是 JDK1.6 Update7 之后的版本。点击一下 jvisualvm.exe 图标它就可以运行了，也可以终端或者 CMD 中使用 jvisualvm 命令启动。\nJvisualvm 本地联调的两种常用方法：\n1、Jvisualvm与IDEA集成，Intelij Idea -&gt; Preferences -&gt; Plugins -&gt;Browers Repositrories，搜索visualvm，选择install：安装成功后会添加visualvm的启动选项，启动 Tomcat 的同时会打开一个VisualVM的窗口。\n\n2、不通过插件直接启动，与本地 Tomcat 联调，需要配置一下 Tomcat，添加参数：\n-Dcom.sun.management.jmxremote.port&#x3D;8999\n-Dcom.sun.management.jmxremote.ssl&#x3D;false\n-Dcom.sun.management.jmxremote.authenticate&#x3D;false\n\n3、自造案发现场\n\n\n\n\n\n\n\n\n为了快速验证我们的工具以及加深对 OOM 的理解，我们自造几种内存溢出场景，代码我已准备妥当，可以直接复制运行验证，开始前记得根据示例调整 JVM 参数~\n\nPermGen OOM\n/**\n * @program: jvisualvmDemo\n * @description: jdk1.7永久区内存溢出\n * -XX:MaxPermSize=5m\n * -XX:+HeapDumpOnOutOfMemoryError\n * -XX:HeapDumpPath=/Users/anchor/Downloads/dump/\n * @author: Anchor\n * @create: 2018-07-31\n **/\npublic class PermGenOOM &#123;\n    public static void main(String[] args) &#123;\n        while (true) &#123;\n            Enhancer enhancer = new Enhancer();\n            enhancer.setSuperclass(MetaOOM.OOMObject.class);\n            enhancer.setUseCache(false);\n            enhancer.setCallback(new MethodInterceptor() &#123;\n                public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;\n                    return proxy.invokeSuper(obj, args);\n                &#125;\n            &#125;);\n            //无限创建动态代理，生成Class对象\n            enhancer.create();\n        &#125;\n    &#125;\n    static class OOMObject &#123;\n\n    &#125;\n&#125;\n\n\nMetaOOM\n/**\n * @program: jvisualvmDemo\n * @description: 方法区内存异常\n * -XX:MetaspaceSize=8m\n * -XX:MaxMetaspaceSize=8m\n * -XX:+HeapDumpOnOutOfMemoryError\n * -XX:HeapDumpPath=/Users/anchor/Downloads/dump/\n * @author: Anchor\n * @create: 2018-07-27\n **/\npublic class MetaOOM &#123;\n\n    public static void main(String[] args) &#123;\n        while (true) &#123;\n            Enhancer enhancer = new Enhancer();\n            enhancer.setSuperclass(OOMObject.class);\n            enhancer.setUseCache(false);\n            enhancer.setCallback(new MethodInterceptor() &#123;\n                public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;\n                    return proxy.invokeSuper(obj, args);\n                &#125;\n            &#125;);\n            //无限创建动态代理，生成Class对象\n            enhancer.create();\n        &#125;\n    &#125;\n\n    static class OOMObject &#123;\n\n    &#125;\n&#125;\n\nHeapOOM\n/**\n * @program: jvisualvmDemo\n * @description: 堆内存异常\n * VM Args:\n *     //这两个参数保证了堆中的可分配内存固定为20M\n *     -Xms20m\n *     -Xmx20m\n *     -XX:+HeapDumpOnOutOfMemoryError\n *     -XX:HeapDumpPath=/Users/anchor/Downloads/dump/\n * @author: Anchor\n * @create: 2018-07-27\n **/\npublic class HeapOOM &#123;\n    //创建一个内部类用于创建对象使用\n    static class OOMObject &#123;\n    &#125;\n    public static void main(String[] args) &#123;\n        List&lt;OOMObject> list = new ArrayList&lt;OOMObject>();\n        //无限创建对象，在堆中\n        while (true) &#123;\n            list.add(new OOMObject());\n        &#125;\n    &#125;\n&#125;\n\nJavaVMStackSOF\n/**\n * @program: jvisualvmDemo\n * @description: 栈内存异常\n * VM Args：\n *     //设置栈容量为160K，默认1M\n *    -Xss160k\n * @author: Anchor\n * @create: 2018-07-27\n **/\npublic class JavaVMStackSOF &#123;\n    private int stackLength = 1;\n    public void stackLeak() &#123;\n        stackLength++;\n        //递归调用，触发异常\n        stackLeak();\n    &#125;\n\n    public static void main(String[] args) throws Throwable &#123;\n        JavaVMStackSOF oom = new JavaVMStackSOF();\n        try &#123;\n            oom.stackLeak();\n        &#125; catch (Throwable e) &#123;\n            System.out.println(\"stack length:\" + oom.stackLength);\n            throw e;\n        &#125;\n    &#125;\n&#125;\n\n4、案例分析\n\n\n\n\n\n\n\n\n啰里啰嗦这么终于要进入正题了 😹\n准备环境，测试脚本\n根据本地机器性能配置 JVM 参数：\n-server -XX:PermSize&#x3D;256M -XX:MaxPermSize&#x3D;256m -Xms300M -Xmx300M\n-Dcom.sun.management.jmxremote.port&#x3D;8999\n-Dcom.sun.management.jmxremote.ssl&#x3D;false\n-Dcom.sun.management.jmxremote.authenticate&#x3D;false\n\n准备测试脚本：\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom multiprocessing import Process,Pool\nimport os,time\nimport requests\n\ndef run_proc(name):\n    for i in range(30000):\n        postdata = &#123;'code': i&#125;\n        r = requests.post(\"http://localhost:8080/OOM.do\", data=postdata)\n\nif __name__ =='__main__':\n    print('Run the main process (%s).' % (os.getpid()))\n    mainStart = time.time()\n    p = Pool(8)\n    for i in range(16):\n        p.apply_async(run_proc,args=('Process'+str(i),))\n\n    print('Waiting for all subprocesses done ...')\n    p.close()\n    p.join()\n    print('All subprocesses done')\n    mainEnd = time.time()\n    print ('All process ran %0.2f seconds.' % (mainEnd-mainStart))\n\n内存快照分析\n快照导入 visualvm，简单翻了一下很快发现问题，内存中存在大量 SQL 片段未回收，如图：\n\n为何内存会被大量 SQL 片段占领，莫非？？？果断开启断言（瞎猜）模式，我们要复现问题！\n\n\n\n\n\n\n\n\n\n假设 A：使用了静态变量定义 SQL 片段，导致资源未回收翻代码确认，发现 SQL 使用 String 对象拼接，非静态变量，但是该 SQL 进行了上百次的拼接必然造成资源浪费加重 GC 负担,有优化空间改 StringBuild，测试之。\n脚本跑起来~ Emm~~ 貌似没啥效果\n\n\n\n\n\n\n\n\n\n假设 B：连接池不够用？\n翻代码确认，发现配置正常，改小连接池大小，测试之，无效。\n\n\n\n\n\n\n\n\n\n假设 C：数据库有死锁？\n但是与运维确认每次内存溢出只需重启应用即可恢复，数据库无需操作，PASS\n\n\n\n\n\n\n\n\n\n假设 D：。。。。。\n\n\n\n\n\n\n\n\n\n假设 X：难道 Druid 连接池会导致内存溢出？\n检查 Druid 配置，发现代码中除了使用了连接池还配置了 SQL 监控，URL 监控，那么监控数据存储在哪里了？难道默认是内存中？百度 Google 无果，直接动手压测，模拟 50W 请求，得到如下数据：成功的看到了内存溢出。\n\n对比生产机内存快照，发现有戏！组成结果基本一致，可是没道理啊，难度 Druid 还有这种大坑？不行不敢确定，那么我们反向验证下，如果我关掉 Druid 的监控呢？说干就干，再跑 50W 请求：\n\n欧克，果然有点意思，OOM 消失了(๑•̀ㅂ•́)و✧\n既然问题找到了，那么就要分析为啥会出现这种大坑，先从官网入手，翻下 Druid 的 lssues 发现竟然有前辈已经问过该类问题\n\nbut，官方并未回复，那么看起来这个问题太 low？\nEmm…. 那自己研究下好了\n进一步扩展\n翻阅官方文档， 在 SQL 合并配置 ，发现如下内容：\n\n\n\n\n\n\n\n\n\n当你程序中存在没有参数化的 sql 执行时，sql 统计的效果会不好。比如：select _ from t where id &#x3D; 1select _ from t where id &#x3D; 2select _ from t where id &#x3D; 3在统计中，显示为 3 条 sql，这不是我们希望要的效果。StatFilter 提供合并的功能，能够将这 3 个 SQL 合并为如下的 SQLselect _ from t where id &#x3D; ?\n问题到此已经基本明了，不规范的入参导致StatFilter未能成功合并 SQL，Druid 成功记录了所有的执行语句。。。。。。。\n大家可以自行体会下这两种写法的区别：\n\n5、内存溢出排查总结\n\n\n\n\n\n\n\n\n导致 OutOfMemoryError 异常的常见原因有以下几种：\n   - 内存中加载的数据量过于庞大，如一次从数据库取出过多数据；\n   - 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；\n   - 代码中存在死循环或循环产生过多重复的对象实体；\n   - 使用的第三方软件中的BUG；\n   - 启动参数内存值设定的过小；\n   - 编码不规范的隐患；\n\n","slug":"Java/Druid监控导致的内存溢出问题定位处理","date":"2018-08-06T06:03:15.000Z","categories_index":"JAVA","tags_index":"JVM,OOM,Druid","author_index":"Anchor"},{"id":"c498ccbc5dc4c0c1651c7cd1edb0e954","title":"浪浪山打工人旅游指南（一）Java 面试题【汇总篇】","content":"\n\n\n\n\n\n\n\n\n2023年1月份最新基础汇总篇，Java开发技术栈知识点都有涉及，主要面向1-2年修为的浪浪山小妖，温故而知新旅游前读这一篇就够了\n一、基础篇\n\n\n\n\n\n\n\n\n基础篇可搭配Java 技术栈（基础篇） 食用。\n1.1.Java语言有哪些特点\n简单易学、有丰富的类库\n面向对象（Java最重要的特性，让程序耦合度更低，内聚性更高）\n与平台无关性（JVM是Java跨平台使用的根本）\n可靠安全\n支持多线程\n\n1.2.面向对象和面向过程的区别面向过程：是分析解决问题的步骤，然后用函数把这些步骤一步一步地实现，然后在使用的时候一一调用则可。性能较高，所以单片机、嵌入式开发等一般采用面向过程开发。面向对象：是把构成问题的事务分解成各个对象，而建立对象的目的也不是为了完成一个个步骤，而是为了描述某个事物在解决整个问题的过程中所发生的行为。面向对象有封装、继承、多态的特性，所以易维护、易复用、易扩展。可以设计出低耦合的系统。 但是性能上来说，比面向过程要低。\n1.3.八种基本数据类型的大小，以及他们的封装类\n\n\n基本类型\n大小（字节）\n默认值\n封装类\n\n\n\nbyte\n1\n(byte)0\nByte\n\n\nshort\n2\n(short)0\nShort\n\n\nint\n4\n0\nInteger\n\n\nlong\n8\n0L\nLong\n\n\nfloat\n4\n0.0f\nFloat\n\n\ndouble\n8\n0.0d\nDouble\n\n\nboolean\n-\nfalse\nBoolean\n\n\nchar\n2\n\\u0000(null)\nCharacter\n\n\n\nint是基本数据类型，Integer是int的封装类，是引用类型。int默认值是0，而Integer默认值是null，所以Integer能区分出0和null的情况。一旦java看到null，就知道这个引用还没有指向某个对象，再任何引用使用前，必须为其指定一个对象，否则会报错。\n基本数据类型在声明时系统会自动给它分配空间，而引用类型声明时只是分配了引用空间，必须通过实例化开辟数据空间之后才可以赋值。数组对象也是一个引用对象，将一个数组赋值给另一个数组时只是复制了一个引用，所以通过某一个数组所做的修改在另一个数组中也看的见。\n\n虽然定义了boolean这种数据类型，但是只对它提供了非常有限的支持。在Java虚拟机中没有任何供boolean值专用的字节码指令，Java语言表达式所操作的boolean值，在编译之后都使用Java虚拟机中的int数据类型来代替，而boolean数组将会被编码成Java虚拟机的byte数组，每个元素boolean元素占8位。这样我们可以得出boolean类型占了单独使用是4个字节，在数组中又是1个字节。使用int的原因是，对于当下32位的处理器（CPU）来说，一次处理数据是32位（这里不是指的是32&#x2F;64位系统，而是指CPU硬件层面），具有高效存取的特点。\n1.4.标识符的命名规则标识符的含义：是指在程序中，我们自己定义的内容，譬如，类的名字，方法名称以及变量名称等等，都是标识符。命名规则：（硬性要求）标识符可以包含英文字母，0-9的数字，$以及_标识符不能以数字开头标识符不是关键字命名规范：（非硬性要求）类名规范：首字符大写，后面每个单词首字母大写（大驼峰式）。变量名规范：首字母小写，后面每个单词首字母大写（小驼峰式）。方法名规范：同变量名。\n1.5.instanceof 关键字的作用instanceof 严格来说是Java中的一个双目运算符，用来测试一个对象是否为一个类的实例，用法为：\nboolean result = obj instanceof Class\n其中 obj 为一个对象，Class 表示一个类或者一个接口，当 obj 为 Class 的对象，或者是其直接或间接子类，或者是其接口的实现类，结果result 都返回 true，否则返回false。注意：编译器会检查 obj 是否能转换成右边的class类型，如果不能转换则直接报错，如果不能确定类型，则通过编译，具体看运行时定。\nint i = 0;\nSystem.out.println(i instanceof Integer);//编译不通过 i必须是引用类型，不能是基本类型\nSystem.out.println(i instanceof Object);//编译不通过\nInteger integer = new Integer(1);\nSystem.out.println(integer instanceof  Integer);//true\n//false ,在 JavaSE规范 中对 instanceof 运算符的规定就是：如果 obj 为 null，那么将返回false。\nSystem.out.println(null instanceof Object);\n1.6.Java自动装箱与拆箱装箱就是自动将基本数据类型转换为包装器类型（int–&gt;Integer）；调用方法：Integer的valueOf(int) 方法拆箱就是自动将包装器类型转换为基本数据类型（Integer–&gt;int）。调用方法：Integer的intValue方法在Java SE5之前，如果要生成一个数值为10的Integer对象，必须这样进行：\nInteger i = new Integer(10);\n而在从Java SE5开始就提供了自动装箱的特性，如果要生成一个数值为10的Integer对象，只需要这样就可以了：\nInteger i = 10;\n面试题1： 以下代码会输出什么？\npublic class Main &#123;\n  public static void main(String[] args) &#123;\n   \n    Integer i1 = 100;\n    Integer i2 = 100;\n    Integer i3 = 200;\n    Integer i4 = 200;\n   \n    System.out.println(i1==i2);\n    System.out.println(i3==i4);\n &#125;\n&#125;\n运行结果:\ntrue\nfalse\n为什么会出现这样的结果？输出结果表明i1和i2指向的是同一个对象，而i3和i4指向的是不同的对象。此时只需一看源码便知究竟，下面这段代码是Integer的valueOf方法的具体实现：\npublic static Integer valueOf(int i) &#123;\n    if(i >= -128 &amp;&amp; i &lt;= IntegerCache.high)\n    return IntegerCache.cache[i + 128];\nelse\n    return new Integer(i);\n&#125;\n其中IntegerCache类的实现为：\nprivate static class IntegerCache &#123;\n    static final int high;\n    static final Integer cache[];\n    static &#123;\n      final int low = -128;\n      // high value may be configured by property\n      int h = 127;\n      if (integerCacheHighPropValue != null) &#123;\n        // Use Long.decode here to avoid invoking methods that\n        // require Integer's autoboxing cache to be initialized\n        int i = Long.decode(integerCacheHighPropValue).intValue();\n        i = Math.max(i, 127);\n        // Maximum array size is Integer.MAX_VALUE\n        h = Math.min(i, Integer.MAX_VALUE - -low);\n     &#125;\n      high = h;\n      cache = new Integer[(high - low) + 1];\n      int j = low;\n      for(int k = 0; k &lt; cache.length; k++)\n        cache[k] = new Integer(j++);\n   &#125;\n    private IntegerCache() &#123;&#125;\n &#125;\n从这2段代码可以看出，在通过valueOf方法创建Integer对象的时候，如果数值在[-128,127]之间，便返回指向IntegerCache.cache中已经存在的对象的引用；否则创建一个新的Integer对象。上面的代码中i1和i2的数值为100，因此会直接从cache中取已经存在的对象，所以i1和i2指向的是同一个对象，而i3和i4则是分别指向不同的对象。面试题2：以下代码输出什么？\npublic class Main &#123;\n  public static void main(String[] args) &#123;\n   \n    Double i1 = 100.0;\n    Double i2 = 100.0;\n    Double i3 = 200.0;\n    Double i4 = 200.0;\n   \n    System.out.println(i1==i2);\n    System.out.println(i3==i4);\n &#125;\n&#125;\n运行结果：\nfalse\nfalse\n原因： 在某个范围内的整型数值的个数是有限的，而浮点数却不是。\n1.7.重载和重写的区别重写(Override)从字面上看，重写就是重新写一遍的意思。其实就是在子类中把父类本身有的方法重新写一遍。子类继承了父类原有的方法，但有时子类并不想原封不动的继承父类中的某个方法，所以在方法名，参数列表，返回类型(除过子类中方法的返回值是父类中方法返回值的子类时)都相同的情况下， 对方法体进行修改或重写，这就是重写。但要注意子类函数的访问修饰权限不能少于父类的。\npublic class Father &#123;\n  public static void main(String[] args) &#123;\n    // TODO Auto-generated method stub\n    Son s = new Son();\n    s.sayHello();\n &#125;\n  public void sayHello() &#123;\n    System.out.println(\"Hello\");\n &#125;\n&#125;\nclass Son extends Father&#123;\n  @Override\n  public void sayHello() &#123;\n    // TODO Auto-generated method stub\n    System.out.println(\"hello by \");\n &#125;\n&#125;\n重写总结\n发生在父类与子类之间\n方法名，参数列表，返回类型（除过子类中方法的返回类型是父类中返回类型的子类）必须相同\n访问修饰符的限制一定要大于被重写方法的访问修饰符(public&gt;protected&gt;default&gt;private)\n重写方法一定不能抛出新的检查异常或者比被重写方法申明更加宽泛的检查型异常\n\n重载（Overload）在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同甚至是参数顺序不同）则视为重载。同时，重载对返回类型没有要求，可以相同也可以不同，但不能通过返回类型是否相同来判断重载。\npublic class Father &#123;\n  public static void main(String[] args) &#123;\n    // TODO Auto-generated method stub\n    Father s = new Father();\n    s.sayHello();\n    s.sayHello(\"wintershii\");\n &#125;\n  public void sayHello() &#123;\n    System.out.println(\"Hello\");\n &#125;\n  public void sayHello(String name) &#123;\n    System.out.println(\"Hello\" + \" \" + name);\n &#125;\n&#125;\n重载总结\n重载Overload是一个类中多态性的一种表现\n重载要求同名方法的参数列表不同(参数类型，参数个数甚至是参数顺序)\n重载的时候，返回值类型可以相同也可以不相同。无法以返回型别作为重载函数的区分标准\n\n1.8.equals与&#x3D;&#x3D;的区别&#x3D;&#x3D;&#x3D;&#x3D; 比较的是变量(栈)内存中存放的对象的(堆)内存地址，用来判断两个对象的地址是否相同，即是否是指相同一个对象。比较的是真正意义上的指针操作。\n\n比较的是操作符两端的操作数是否是同一个对象。\n两边的操作数必须是同一类型的（可以是父子类之间）才能编译通过。\n比较的是地址，如果是具体的阿拉伯数字的比较，值相等则为true，如：int a&#x3D;10 与 long b&#x3D;10L 与 double c&#x3D;10.0都是相同的（为true），因为他们都指向地址为10的堆。\n\nequalsequals用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是&#x3D;&#x3D;的判断。\n总结所有比较是否相等时，都是用equals 并且在对常量相比较时，把常量写在前面，因为使用object的equals object可能为null 则空指针在阿里的代码规范中只使用equals ，阿里插件默认会识别，并可以快速修改，推荐安装阿里插件来排查老代码使用“&#x3D;&#x3D;”，替换成equals\n1.9.Hashcode的作用java的集合有两类，一类是List，还有一类是Set。前者有序可重复，后者无序不重复。当我们在set中插入的时候怎么判断是否已经存在该元素呢，可以通过equals方法。但是如果元素太多，用这样的方法就会比较满。于是有人发明了哈希算法来提高集合中查找元素的效率。 这种方式将集合分成若干个存储区域，每个对象可以计算出一个哈希码，可以将哈希码分组，每组分别对应某个存储区域，根据一个对象的哈希码就可以确定该对象应该存储的那个区域。hashCode方法可以这样理解：它返回的就是根据对象的内存地址换算出的一个值。这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。\n1.10.String、String StringBuffer 和 StringBuilder 的区别是什么?String是只读字符串，它并不是基本数据类型，而是一个对象。从底层源码来看是一个final类型的字符数组，所引用的字符串不能被改变，一经定义，无法再增删改。每次对String的操作都会生成新的String对象。\nprivate final char value[];\n每次+操作 ： 隐式在堆上new了一个跟原字符串相同的StringBuilder对象，再调用append方法 拼接+后面的字符。StringBuffer和StringBuilder他们两都继承了AbstractStringBuilder抽象类，从AbstractStringBuilder抽象类中我们可以看到\n/**\n  * The value is used for character storage.\n  */\n  char[] value;\n他们的底层都是可变的字符数组，所以在进行频繁的字符串操作时，建议使用StringBuffer和StringBuilder来进行操作。 另外StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。\n1.11.ArrayList和linkedList的区别Array（数组）是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的。Array获取数据的时间复杂度是O(1),但是要删除数据却是开销很大，因为这需要重排数组中的所有数据,(因为删除数据以后, 需要把后面所有的数据前移)缺点: 数组初始化必须指定初始化的长度, 否则报错，例如:\nint[] a = new int[4];//推介使用int[] 这种方式初始化\nint c[] = &#123;23,43,56,78&#125;;//长度：4，索引范围：[0,3]\nList—是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式，它继承Collection。List有两个重要的实现类：ArrayList和LinkedListArrayList: 可以看作是能够自动增长容量的数组ArrayList的toArray方法返回一个数组ArrayList的asList方法返回一个列表ArrayList底层的实现是Array, 数组扩容实现LinkList是一个双链表,在添加和删除元素时具有比ArrayList更好的性能.但在get与set方面弱于ArrayList.当然,这些对比都是指数据量很大或者操作很频繁。\n1.12.HashMap和HashTable的区别\n两者父类不同\n\nHashMap是继承自AbstractMap类，而Hashtable是继承自Dictionary类。不过它们都实现了同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口。\n\n对外提供的接口不同\n\nHashtable比HashMap多提供了elments() 和contains() 两个方法。elments() 方法继承自Hashtable的父类Dictionnary。elements() 方法用于返回此Hashtable中的value的枚举。contains()方法判断该Hashtable是否包含传入的value。它的作用与containsValue()一致。事实上，contansValue() 就只是调用了一下contains() 方法。\n\n对null的支持不同\n\nHashtable：key和value都不能为null。HashMap：key可以为null，但是这样的key只能有一个，因为必须保证key的唯一性；可以有多个key值对应的value为null。\n\n安全性不同\n\nHashMap是线程不安全的，在多线程并发的环境下，可能会产生死锁等问题，因此需要开发人员自己处理多线程的安全问题。Hashtable是线程安全的，它的每个方法上都有synchronized 关键字，因此可直接用于多线程中。虽然HashMap是线程不安全的，但是它的效率远远高于Hashtable，这样设计是合理的，因为大部分的使用场景都是单线程。当需要多线程操作的时候可以使用线程安全的ConcurrentHashMap。ConcurrentHashMap虽然也是线程安全的，但是它的效率比Hashtable要高好多倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。\n\n初始容量大小和每次扩充容量大小不同\n计算hash值的方法不同\n\n1.13.Collection包结构，与Collections的区别Collection是集合类的上级接口，子接口有 Set、List、LinkedList、ArrayList、Vector、Stack、Set；Collections是集合类的一个帮助类， 它包含有各种有关集合操作的静态多态方法，用于实现对各种集合的搜索、排序、线程安全化等操作。此类不能实例化，就像一个工具类，服务于Java的Collection框架。\n1.14. Java的四种引用，强弱软虚强引用强引用是平常中使用最多的引用，强引用在程序内存不足（OOM）的时候也不会被回收，使用方式：\nString str = new String(\"str\");\n软引用软引用在程序内存不足时，会被回收，使用方式：\n// 注意：wrf这个引用也是强引用，它是指向SoftReference这个对象的，\n// 这里的软引用指的是指向new String(\"str\")的引用，也就是SoftReference类中T\nSoftReference&lt;String> wrf = new SoftReference&lt;String>(new String(\"str\"));\n可用场景： 创建缓存的时候，创建的对象放进缓存中，当内存不足时，JVM就会回收早先创建的对象。\n弱引用弱引用就是只要JVM垃圾回收器发现了它，就会将之回收，使用方式：\nWeakReference&lt;String> wrf = new WeakReference&lt;String>(str);\n可用场景： Java源码中的 java.util.WeakHashMap 中的 key 就是使用弱引用，我的理解就是，一旦我不需要某个引用，JVM会自动帮我处理它，这样我就不需要做其它操作。\n虚引用虚引用的回收机制跟弱引用差不多，但是它被回收之前，会被放入ReferenceQueue 中。注意哦，其它引用是被JVM回收后才被传入ReferenceQueue 中的。由于这个机制，所以虚引用大多被用于引用销毁前的处理工作。还有就是，虚引用创建的时候，必须带有 ReferenceQueue ，使用例子：\nPhantomReference&lt;String> prf = new PhantomReference&lt;String>(new String(\"str\"), new ReferenceQueue&lt;>());\n可用场景： 对象销毁前的一些操作，比如说资源释放等。Object.finalize() 虽然也可以做这类动作，但是这个方式即不安全又低效上诉所说的几类引用，都是指对象本身的引用，而不是指 Reference 的四个子类的引用( SoftReference 等)。\n1.15.泛型常用特点泛型是Java SE 1.5之后的特性， 《Java 核心技术》中对泛型的定义是：“泛型” 意味着编写的代码可以被不同类型的对象所重用。“泛型”，顾名思义，“泛指的类型”。我们提供了泛指的概念，但具体执行的时候却可以有具体的规则来约束，比如我们用的非常多的ArrayList就是个泛型类，ArrayList作为集合可以存放各种元素，如Integer, String，自定义的各种类型等，但在我们使用的时候通过具体的规则来约束，如我们可以约束集合中只存放Integer类型的元素，如：\nList&lt;Integer> iniData = new ArrayList&lt;>();\n使用泛型的好处？以集合来举例，使用泛型的好处是我们不必因为添加元素类型的不同而定义不同类型的集合，如整型集合类，浮点型集合类，字符串集合类，我们可以定义一个集合来存放整型、浮点型，字符串型数据，而这并不是最重要的，因为我们只要把底层存储设置了Object即可，添加的数据全部都可向上转型为Object。 更重要的是我们可以通过规则按照自己的想法控制存储的数据类型。\n1.16.Java创建对象有几种方式？java中提供了以下四种创建对象的方式:\n\nnew创建新对象\n通过反射机制\n采用clone机制\n通过序列化机制\n\n1.17.有没有可能两个不相等的对象有相同的hashcode有可能.在产生hash冲突时,两个不相等的对象就会有相同的 hashcode 值.当hash冲突产生时,一般有以下几种方式来处理:\n\n拉链法:每个哈希表节点都有一个next指针,多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表进行存储.\n开放定址法:一旦发生了冲突,就去寻找下一个空的散列地址,只要散列表足够大,空的散列地址总能找到,并将记录存入\n再哈希:又叫双哈希法,有多个不同的Hash函数.当发生冲突时,使用第二个,第三个….等哈希函数计算地址,直到无冲突.\n\n1.18.深拷贝和浅拷贝的区别是什么?\n浅拷贝:被复制对象的所有变量都含有与原来的对象相同的值,而所有的对其他对象的引用仍然指向原来的对象.换言之,浅拷贝仅仅复制所考虑的对象,而不复制它所引用的对象.\n深拷贝:被复制对象的所有变量都含有与原来的对象相同的值.而那些引用其他对象的变量将指向被复制过的新对象.而不再是原有的那些被引用的对象.换言之.深拷贝把要复制的对象所引用的对象都复制了一遍.\n\n1.19.final有哪些用法?final也是很多面试喜欢问的地方,但我觉得这个问题很无聊,通常能回答下以下5点就不错了:\n\n被final修饰的类不可以被继承\n被final修饰的方法不可以被重写\n被final修饰的变量不可以被改变.如果修饰引用,那么表示引用不可变,引用指向的内容可变.\n被final修饰的方法,JVM会尝试将其内联,以提高运行效率\n被final修饰的常量,在编译阶段会存入常量池中.\n\n除此之外,编译器对final域要遵守的两个重排序规则更好:\n\n在构造函数内对一个final域的写入,与随后把这个被构造对象的引用赋值给一个引用变量,这两个操作之间不能重排序\n初次读一个包含final域的对象的引用,与随后初次读这个final域,这两个操作之间不能重排序。\n\n1.20.static都有哪些用法?所有的人都知道static关键字这两个基本的用法:静态变量和静态方法.也就是被static所修饰的变量&#x2F;方法都属于类的静态资源,类实例所共享.除了静态变量和静态方法之外,static也用于静态块,多用于初始化操作:\npublic calss PreCache&#123;\n  static&#123;\n    //执行相关操作\n &#125;\n&#125;\n此外static也多用于修饰内部类,此时称之为静态内部类.最后一种用法就是静态导包,即 import static .import static是在JDK 1.5之后引入的新特性,可以用来指定导入某个类中的静态资源,并且不需要使用类名,可以直接使用资源名,比如:\nimport static java.lang.Math.*;\npublic class Test&#123;\n  public static void main(String[] args)&#123;\n    //System.out.println(Math.sin(20));传统做法\n    System.out.println(sin(20));\n &#125;\n&#125;\n1.21.3*0.1&#x3D;&#x3D;0.3返回值是什么false,因为有些浮点数不能完全精确的表示出来\n1.22.a&#x3D;a+b与a+&#x3D;b有什么区别吗?+&#x3D; 操作符会进行隐式自动类型转换,此处a+&#x3D;b隐式的将加操作的结果类型强制转换为持有结果的类型,而a&#x3D;a+b则不会自动进行类型转换.如：\nbyte a = 127;\nbyte b = 127;\nb = a + b; // 报编译错误:cannot convert from int to byte\nb += a;\n以下代码是否有错,有的话怎么改？\nshort s1= 1;\ns1 = s1 + 1;\n有错误.short类型在进行运算时会自动提升为int类型,也就是说 s1+1 的运算结果是int类型,而s1是short类型,此时编译器会报错。正确写法：\nshort s1= 1;\ns1 += 1;\n+&#x3D;操作符会对右边的表达式结果强转匹配左边的数据类型,所以没错。\n1.23.try catch finally，try里有return，finally还执行么？执行，并且finally的执行早于try里面的return结论：\n\n不管有木有出现异常，finally块中代码都会执行；\n当try和catch中有return时，finally仍然会执行；\nfinally是在return后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在finally执行前确定的；\nfinally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值\n\n1.24.Excption与Error包结构Java可抛出(Throwable)的结构分为三种类型：被检查的异常(CheckedException)，运行时异常(RuntimeException)，错误(Error)。\n运行时异常定义:RuntimeException及其子类都被称为运行时异常。特点:Java编译器不会检查它。也就是说，当程序中可能出现这类异常时，倘若既”没有通过throws声明抛出它”，也”没有用try-catch语句捕获它”，还是会编译通过。例如，除数为零时产生的ArithmeticException异常，数组越界时产生的IndexOutOfBoundsException异常，fail-fast机制产生的ConcurrentModificationException异常（java.util包下面的所有的集合类都是快速失败的，“快速失败”也就是fail-fast，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出ConcurrentModificationException 异常，从而产生fail-fast机制，这个错叫并发修改异常。Fail-safe，java.util.concurrent包下面的所有的类都是安全失败的，在遍历过程中，如果已经遍历的数组上的内容变化了，迭代器不会抛出ConcurrentModificationException异常。如果未遍历的数组上的内容发生了变化，则有可能反映到迭代过程中。这就是ConcurrentHashMap迭代器弱一致的表现。ConcurrentHashMap的弱一致性主要是为了提升效率，是一致性与效率之间的一种权衡。要成为强一致性，就得到处使用锁，甚至是全局锁，这就与Hashtable和同步的HashMap一样了。）等，都属于运行时异常。常见的五种运行时异常：\n\nClassCastException（类转换异常）\nIndexOutOfBoundsException（数组越界）\nNullPointerException（空指针异常）\nArrayStoreException（数据存储异常，操作数组是类型不一致）\nBufferOverflowException\n\n被检查异常定义:Exception类本身，以及Exception的子类中除了”运行时异常”之外的其它子类都属于被检查异常。特点: Java编译器会检查它。 此类异常，要么通过throws进行声明抛出，要么通过try-catch进行捕获处理，否则不能通过编译。例如，CloneNotSupportedException就属于被检查异常。当通过clone()接口去克隆一个对象，而该对象对应的类没有实现Cloneable接口，就会抛出CloneNotSupportedException异常。被检查异常通常都是可以恢复的。如：IOExceptionFileNotFoundExceptionSQLException被检查的异常适用于那些不是因程序引起的错误情况，比如：读取文件时文件不存在引发的FileNotFoundException 。然而，不被检查的异常通常都是由于糟糕的编程引起的，比如：在对象引用时没有确保对象非空而引起的NullPointerException 。\n错误定义: Error类及其子类。特点: 和运行时异常一样，编译器也不会对错误进行检查。当资源不足、约束失败、或是其它程序无法继续运行的条件发生时，就产生错误。程序本身无法修复这些错误的。例如，VirtualMachineError就属于错误。出现这种错误会导致程序终止运行。OutOfMemoryError、ThreadDeath。Java虚拟机规范规定JVM的内存分为了好几块，比如堆，栈，程序计数器，方法区等\n1.25.OOM你遇到过哪些情况，SOF你遇到过哪些情况OutOfMemoryError异常除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生OutOfMemoryError(OOM)异常的可能。Java Heap 溢出：一般的异常信息：java.lang.OutOfMemoryError:Java heap spacess。java堆用于存储对象实例，我们只要不断的创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，就会在对象数量达到最大堆容量限制后产生内存溢出异常。出现这种异常，一般手段是先通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出来的堆转存快照进行分析，重点是确认内存中的对象是否是必要的，先分清是因为内存泄漏(Memory Leak)还是内存溢出(Memory Overflow)。如果是内存泄漏，可进一步通过工具查看泄漏对象到GCRoots的引用链。于是就能找到泄漏对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收。如果不存在泄漏，那就应该检查虚拟机的参数(-Xmx与-Xms)的设置是否适当。\n虚拟机栈和本地方法栈溢出如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常这里需要注意当栈的大小越大可分配的线程数就越少。\n运行时常量池溢出异常信息：java.lang.OutOfMemoryError:PermGenspace如果要向运行时常量池中添加内容，最简单的做法就是使用String.intern()这个Native方法。该方法的作用是：如果池中已经包含一个等于此String的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。由于常量池分配在方法区内，我们可以通过-XX:PermSize和-XX:MaxPermSize限制方法区的大小，从而间接限制其中常量池的容量。\n方法区溢出方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。也有可能是方法区中保存的class对象没有被及时回收掉或者class信息占用的内存超过了我们配置。异常信息：java.lang.OutOfMemoryError:PermGenspace方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，判定条件是很苛刻的。在经常动态生成大量Class的应用中，要特别注意这点。\nSOF（堆栈溢出StackOverflow）StackOverflowError 的定义：当应用程序递归太深而发生堆栈溢出时，抛出该错误。因为栈一般默认为1-2m，一旦出现死循环或者是大量的递归调用，在不断的压栈过程中，造成栈容量超过1m而导致溢出。栈溢出的原因：递归调用，大量循环或死循环，全局变量是否过多，数组、List、map数据过大。\n1.26.简述线程、程序、进程的基本概念。以及他们之间关系是什么?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如 CPU 时间，内存空间，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。 线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。\n1.27.线程有哪些基本状态？这些状态是如何定义的?\n新建(new)：新创建了一个线程对象。\n\n可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu的使用权。\n\n运行(running)：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。\n\n阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有 机会再次获得cpu timeslice转到运行(running)状态。\n\n\n\n\n\n\n\n\n\n阻塞的情况分三种：(一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放 入等待队列(waitting queue)中。(二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。(三). 其他阻塞: 运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I&#x2F;O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时join()等待线程终止或者超时、或者I&#x2F;O处理完毕时，线程重新转入可运行(runnable)状态。\n\n死亡(terminated)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。\n\n\n\n1.28.Java 中 IO 流Java 中 IO 流分为几种?\n\n按照流的流向分，可以分为输入流和输出流；\n按照操作单元划分，可以划分为字节流和字符流；\n按照流的角色划分为节点流和处理流。\n\nJava Io 流共涉及 40 多个类，这些类看上去很杂乱，但实际上很有规则，而且彼此之间存在非常紧密的联系， Java I0 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。InputStream&#x2F;Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。OutputStream&#x2F;Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。按操作方式分类结构图：按操作对象分类结构图：\n1.29.java反射的作用于原理什么是反射？反射机制是在运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意个对象，都能够调用它的任意一个方法。在java中，只要给定类的名字，就可以通过反射机制来获得类的所有信息。这种动态获取的信息以及动态调用对象的方法的功能称为Java语言的反射机制。\n哪里会用到反射机制？jdbc就是典型的反射Class.forName(‘com.mysql.jdbc.Driver.class’);&#x2F;&#x2F;加载MySQL的驱动类这就是反射。如hibernate，struts等框架使用反射实现的。\n反射的实现方式获取Class对象，有4中方法：\n\nClass.forName(“类的路径”)；\n类名.class\n对象名.getClass()\n基本类型的包装类，可以调用包装类的Type属性来获得该包装类的Class对象\n\n实现Java反射的类\nClass：表示正在运行的Java应用程序中的类和接口（注意： 所有获取对象的信息都需要Class类来实现）。\nField：提供有关类和接口的属性信息，以及对它的动态访问权限。\nConstructor：提供关于类的单个构造方法的信息以及它的访问权限\nMethod：提供类或接口中某个方法的信息\n\n反射机制的优缺点优点\n能够运行时动态获取类的实例，提高灵活性；\n与动态编译结合\n\n缺点\n使用反射性能较低，需要解析字节码，将内存中的对象进行解析。\n\n\n\n\n\n\n\n\n\n解决方案：1、通过setAccessible(true)关闭JDK的安全检查来提升反射速度；2、多次创建一个类的实例时，有缓存会快很多3、ReflectASM工具类，通过字节码生成的方式加快反射速度\n\n相对不安全，破坏了封装性（因为通过反射可以获得私有方法和属性）\n\n\n1.30.说说List,Set,Map三者的区别？List(对付顺序的好帮手): List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。\n二、JVM篇2.1.知识点汇总JVM是Java运行基础,面试时一定会遇到JVM的有关问题,内容相对集中,但对只是深度要求较高。由于脑图内容实在过于庞大，这里就不展开了，详情可见：JVM知识点。\n2.2.知识点详解JVM内存模型线程独占:栈,本地方法栈,程序计数器线程共享:堆,方法区\n栈又称方法栈,线程私有的,线程执行方法是都会创建一个栈阵,用来存储局部变量表,操作栈,动态链接,方法出口等信息.调用方法时执行入栈,方法返回式执行出栈.\n本地方法栈与栈类似,也是用来保存执行方法的信息.执行Java方法是使用栈,执行Native方法时使用本地方法栈.\n程序计数器保存着当前线程执行的字节码位置,每个线程工作时都有独立的计数器,只为执行Java方法服务,执行Native方法时,程序计数器为空.\n堆JVM内存管理最大的一块,对被线程共享,目的是存放对象的实例,几乎所欲的对象实例都会放在这里,当堆没有可用空间时,会抛出OOM异常.根据对象的存活周期不同,JVM把对象进行分代管理,由垃圾回收器进行垃圾的回收管理\n方法区又称非堆区,用于存储已被虚拟机加载的类信息,常量,静态变量,即时编译器优化后的代码等数据.1.7的永久代和1.8的元空间都是方法区的一种实现\nJVM 内存可见性JMM是定义程序中变量的访问规则,线程对于变量的操作只能在自己的工作内存中进行,而不能直接对主内存操作.由于指令重排序,读写的顺序会被打乱,因此JMM需要提供原子性,可见性,有序性保证\n2.3.类加载与卸载类加载过程JVM类加载过程分为：加载 、链接 、初始化 、使用 、卸载 这五个阶段，其中链接阶段又包括： 验证 、 准备 、 解析 。加载 ：通过类的完全限定名，查找此类的二进制字节码文件，通过该字节码文件创建Class对象。链接 ：包含 验证 、 准备 、 解析 三个阶段：\n\n验证 ：确保Class文件复合虚拟机规定的Class文件格式，包含文件格式验证、元数据验证、字节码验证、引用符号验证。\n准备 ：为类的静态变量分配内存并设置初始化值，注：这里不包含final修饰的静态变量，因为final修饰的静态变量是在编译期分配。\n解析 ：将常量池的间接引用转换为直接引用，解析包含字段解析、接口解析、方法解析。\n\n初始化 ：初始化静态变量和静态块，先初始化父类，再初始化当前类，只有对类主动时才会初始化。使用 ：程序代码执行时使用，new出对象程序中使用。卸载 ：程序代码退出、异常、结束等，执行垃圾回收。\n类加载时机\n创建类的实例，也就是new一个对象。\n访问类的静态方法或者静态变量（包含静态变量赋值）。\n使用Class.forName()反射类。\n子类初始化的时候。\nJVM启动时标明的启动类。\n\n类加载器类加载器包括启动类加载器、扩展类加载器、系统类加载器、自定义类加载器四种加载器。\n启动类加载器（Bootstrap ClassLoader）：负责加载Java类的核心类，是用原生代码实现。下面代码可以获得启动类加载器所加载的Java核心类库。\nURL[] urLs = Launcher.getBootstrapClassPath().getURLs();\nfor(URL url : urLs)&#123;\n    System.out.println(url.toExternalForm());\n&#125;\n\n扩展类加载器（Extensions ClassLoader）：负责加载JRE的扩展目录lib&#x2F;ext或者由java.ext.dirs系统属性指定的目录中的JAR包的类。由Java语言实现，父类加载器为Null。\n系统类加载器（System Class Loader）：负责在JVM启动时加载来自Java命令的-classpath选项、java.class.path系统属性。可以通过ClassLoader.getSystemClassLoader()方法获取当前系统类加载器，一般情况是自定义类加载器的父加载器。由Java语言实现，父类加载器为扩展类加载器。\nSystem.out.println(ClassLoader.getSystemClassLoader());\nSystem.out.println(ClassLoader.getSystemClassLoader().getParent());\n\n自定义类加载器（Custom ClassLoader）：用户可以通过继承ClassLoader类实现自定义类加载器。由Java语言实现，自定义类加载器的父类是系统类加载器。\n类加载机制JVM的类加载机制主要有全盘负责、双亲委派、缓存机制三种加载机制。\n\n全盘负责：当一个类加载器加载某个Class时，该Class所依赖和引用其他Class也会由该类加载器负责加载，除非指定了使用其他类加载器加载。\n双亲委派：先让父类加载器加载该Class，只有在父类加载器无法加载该类时才尝试使用自己的类加载器加载。通俗的讲就是在某个特定的类加载器接到加载类请求时，先寄托给父加载器加载，依次递归，如果父加载器可以加载时则成功返回，如果不可以加载就自己去加载。\n缓存机制：缓存机制会确保所有加载过的Class都被会缓存，当程序中需要某个Class时，类加载器先从缓存区中搜索该Class，只有缓存区中不存在该Class对象时，系统才会读取该类的二进制数据，并将其转换为Class对象，存入缓存区。这就是为什么我们修改Class文件之后，必须重启JVM才会生效的原因。\n\n其中双亲委派机制优势：\n\n父类加载器成功加载则返回，子类加载器不会再加载，防止了重复加载。\n防止核心API库被随意篡改。比如有一个要加载java.lang.Integer类的请求，通过双亲委派进制加载传递到启动类加载器，在在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，可以防止核心API被随意篡改。\n\n回收算法G1算法1.9后默认的垃圾回收算法,特点保持高回收率的同时减少停顿.采用每次只清理一部分,而不是清理全部的增量式清理,以保证停顿时间不会过长。其取消了年轻代与老年代的物理划分,但仍属于分代收集器,算法将堆分为若干个逻辑区域(region),一部分用作年轻代,一部分用作老年代,还有用来存储巨型对象的分区。同CMS相同,会遍历所有对象,标记引用情况,清除对象后会对区域进行复制移动,以整合碎片空间。年轻代回收:并行复制采用复制算法,并行收集,会StopTheWorld.老年代回收:会对年轻代一并回收初始标记完成堆root对象的标记,会StopTheWorld.并发标记 GC线程和应用线程并发执行.最终标记完成三色标记周期,会StopTheWorld.复制&#x2F;清楚会优先对可回收空间加大的区域进行回收\nZGC算法高效垃圾回收算法,针对大堆内存设计,可以处理TB级别的堆,可以做到10ms以下的回收停顿时间\n\n\n\n\n\n\n\n\n\n着色指针读屏障并发处理基于region内存压缩(整理)\nroots标记：标记root对象,会StopTheWorld。并发标记：利用读屏障与应用线程一起运行标记,可能会发生StopTheWorld。清除会清理标记为不可用的对象。roots重定位：是对存活的对象进行移动,以腾出大块内存空间,减少碎片产生。重定位最开始会StopTheWorld,却决于重定位集与对象总活动集的比例。并发重定位与并发标记类似。\n2.4.简述一下JVM的内存模型JVM定义了不同运行时数据区，他们是用来执行应用程序的。某些区域随着JVM启动及销毁，另外一些区域的数据是线程性独立的，随着线程创建和销毁。\n线程私有区程序计数器当同时进行的线程数超过CPU数或其内核数时，就要通过时间片轮询分派CPU的时间资源，不免发生线程切换。这时，每个线程就需要一个属于自己的计数器来记录下一条要运行的指令。如果执行的是JAVA方法，计数器记录正在执行的java字节码地址，如果执行的是native方法，则计数器为空。\n虚拟机栈线程私有的，与线程在同一时间创建。管理JAVA方法执行的内存模型。每个方法执行时都会创建一个桢栈来存储方法的的变量表、操作数栈、动态链接方法、返回值、返回地址等信息。栈的大小决定了方法调用的可达深度（递归多少层次，或嵌套调用多少层其他方法，-Xss参数可以设置虚拟机栈大小）。栈的大小可以是固定的，或者是动态扩展的。如果请求的栈深度大于最大可用深度，则抛出stackOverflowError；如果栈是可动态扩展的，但没有内存空间支持扩展，则抛出OutofMemoryError。\n本地方法栈与虚拟机栈作用相似。但它不是为Java方法服务的，而是本地方法（C语言）。由于规范对这块没有强制要求，不同虚拟机实现方法不同。\n线程共享区方法区线程共享的，用于存放被虚拟机加载的类的元数据信息，如常量、静态变量和即时编译器编译后的代码。若要分代，算是永久代（老年代），以前类大多“static”的，很少被卸载或收集，现回收废弃常量和无用的类。其中运行时常量池存放编译生成的各种常量。（如果hotspot虚拟机确定一个类的定义信息不会被使用，也会将其回收。回收的基本条件至少有：所有该类的实例被回收，而且装载该类的ClassLoader被回收）\n堆存放对象实例和数组，是垃圾回收的主要区域，分为新生代和老年代。刚创建的对象在新生代的Eden区中，经过GC后进入新生代的S0区中，再经过GC进入新生代的S1区中，15次GC后仍存在就进入老年代。这是按照一种回收机制进行划分的，不是固定的。若堆的空间不够实例分配，则OutOfMemoryError。\n2.5.堆和栈的区别栈是运行时单位，代表着逻辑，内含基本数据类型和堆中对象引用，所在区域连续，没有碎片；堆是存储单位，代表着数据，可被多个栈共享（包括成员中基本数据类型、引用和引用对象），所在区域不连续，会有碎片。1、功能不同栈内存用来存储局部变量和方法调用，而堆内存用来存储Java中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中。2、共享性不同栈内存是线程私有的。堆内存是所有线程共有的。3、异常错误不同如果栈内存或者堆内存不足都会抛出异常。栈空间不足：java.lang.StackOverFlowError。堆空间不足：java.lang.OutOfMemoryError。4、空间大小栈的空间大小远远小于堆的\n2.6.什么时候会触发FullGC除直接调用System.gc外，触发Full GC执行的情况有如下四种。\n\n旧生代空间不足\n\n\n\n\n\n\n\n\n\n旧生代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：java.lang.OutOfMemoryError: Java heap space为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。\n\nPermanet Generation空间满\n\n\n\n\n\n\n\n\n\nPermanetGeneration中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息：java.lang.OutOfMemoryError: PermGen space为避免Perm Gen占满造成Full GC现象，可采用的方法为增大Perm Gen空间或转为使用CMS GC。\n\nCMS GC时出现promotion failed和concurrent mode failure\n\n\n\n\n\n\n\n\n\n对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。promotionfailed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。应对措施为：增大survivorspace、旧生代空间或调低触发并发GC的比率，但在JDK 5.0+、6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime&#x3D;5（单位为ms）来避免。\n\n统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间\n\n\n\n\n\n\n\n\n\n这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。当新生代采用PSGC时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。除了以上4种状况外，对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java Dsun.rmi.dgc.client.gcInterval&#x3D;3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。\n\n\n2.7.什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？Java虚拟机是一个可以执行Java字节码的虚拟机进程。Java源文件被编译成能被Java虚拟机执行的字节码文件。 Java被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。Java虚拟机让这个变为可能，因为它知道底层硬件平台的指令长度和其他特性。\n2.8.Java内存结构方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。Java堆（Heap）,是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。方法区（Method Area）,方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。\n2.9.对象分配规则对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。\n2.10.Java对象创建过程\nJVM遇到一条新建对象的指令时首先去检查这个指令的参数是否能在常量池中定义到一个类的符号引用。然后加载这个类（类加载过程在后边讲）\n为对象分配内存。一种办法“指针碰撞”、一种办法“空闲列表”，最终常用的办法“本地线程缓冲分配(TLAB)”\n将除对象头外的对象内存空间初始化为0\n对对象头进行必要设置\n\n2.11.类的生命周期类的生命周期包括这几个部分，加载、连接、初始化、使用和卸载，其中前三部是类的加载的过程加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象连接，连接又包含三块内容：验证、准备、初始化。\n2.12.简述Java的对象结构Java对象由三个部分组成：对象头、实例数据、对齐填充。对象头由两部分组成，第一部分存储对象自身的运行时数据：哈希码、GC分代年龄、锁标识状态、线程持有的锁、偏向线程ID（一般占32&#x2F;64 bit）。第二部分是指针类型，指向对象的类元数据类型（即对象代表哪个类）。如果是数组对象，则对象头中还有一部分用来记录数组长度。实例数据用来存储对象真正的有效信息（包括父类继承下来的和自己定义的）对齐填充：JVM要求对象起始地址必须是8字节的整数倍（8字节对齐）\n2.13.如何判断对象可以被回收？判断对象是否存活一般有两种方式：引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。\n2.14.JVM的永久代中会发生垃圾回收么？垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。请参考下Java8：从永久代到元数据区 (注：Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区)\n2.15.垃圾收集算法GC最基础的算法有三种： 标记 -清除算法、复制算法、标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。标记 -清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。\n2.16.调优命令有哪些？Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfojps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。jmap，JVM Memory Map命令用于生成heap dump文件jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP&#x2F;HTML服务器，生成dump的分析结果后，可以在浏览器中查看jstack，用于生成java虚拟机当前时刻的线程快照。jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。\n2.17.调优工具常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗GChisto，一款专业分析gc日志的工具\n2.18.Minor GC与Full GC分别在什么时候发生？新生代内存不够用时候发生MGC也叫YGC，JVM内存不够的时候发生FGC\n2.19.你知道哪些JVM性能调优设定堆内存大小\n-Xmx：堆内存最大限制。\n设定新生代大小。 新生代不宜太小，否则会有大量对象涌入老年代\n-XX:NewSize：新生代大小\n-XX:NewRatio 新生代和老生代占比\n-XX:SurvivorRatio：伊甸园空间和幸存者空间的占比\n设定垃圾回收器 年轻代用 -XX:+UseParNewGC 年老代用-XX:+UseConcMarkSweepGC\n2.20.简述Java垃圾回收机制?在Java中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行。在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收\n2.21.什么是类加载器，类加载器有哪些?实现通过类的权限定名获取该类的二进制字节流的代码块叫做类加载器。主要有一下四种类加载器:**启动类加载器(Bootstrap ClassLoader)**用来加载java核心类库，无法被java程序直接引用。扩展类加载器(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。系统类加载器（system class loader）：它根据 Java 应用的类路径(CLASSPATH）来加载 Java类。一般来说，Java 应用的类都是由它来完成加载的。可以通过ClassLoader.getSystemClassLoader()来获取它。用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现。\n2.22.你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理 过程中有哪些收获？常见的原因:内存加载的数据量太大：一次性从数据库取太多数据；集合类中有对对象的引用，使用后未清空，GC不能进行回收；代码中存在循环产生过多的重复对象；启动参数堆内存值小。\n2.23.JDK 1.8之后Perm Space有哪些变动? MetaSpace⼤⼩默认是⽆限的么? 还是你们会通过什么⽅式来指定⼤⼩?JDK 1.8后用元空间替代了 Perm Space；字符串常量存放到堆内存中。MetaSpace大小默认没有限制，一般根据系统内存的大小。JVM会动态改变此值。-XX:MetaspaceSize：分配给类元数据空间（以字节计）的初始大小（Oracle逻辑存储上的初始高水位，the initial high-water-mark）。此值为估计值，MetaspaceSize的值设置的过大会延长垃圾回收时间。垃圾回收过后，引起下一次垃圾回收的类元数据空间的大小可能会变大。-XX:MaxMetaspaceSize：分配给类元数据空间的最大值，超过此值就会触发Full GC，此值默认没有限制，但应取决于系统内存的大小。JVM会动态地改变此值。\n三、多线程&amp;并发篇3.1.Java中实现多线程有几种方法\n继承Thread类；\n实现Runnable接口；\n实现Callable接口通过FutureTask包装器来创建Thread线程；\n使用ExecutorService、Callable、Future实现有返回结果的多线程（也就是使用了ExecutorService来管理前面的三种方式）\n\n3.2.如何停止一个正在运行的线程\n使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。\n使用stop方法强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。\n使用interrupt方法中断线程。class MyThread extends Thread &#123;\n    volatile boolean stop = false;\n    public void run() &#123;\n        while (!stop) &#123;\n            System.out.println(getName() + \" is running\");\n            try &#123;\n                sleep(1000);\n            &#125; catch (InterruptedException e) &#123;\n                System.out.println(\"week up from blcok...\");\n                stop = true; // 在异常处理代码中修改共享变量的状态\n            &#125;\n        &#125;\n        System.out.println(getName() + \" is exiting...\");\n    &#125;\n&#125;\nclass InterruptThreadDemo3 &#123;\n    public static void main(String[] args) throws InterruptedException &#123;\n        MyThread m1 = new MyThread();\n        System.out.println(\"Starting thread...\");\n        m1.start();\n        Thread.sleep(3000);\n        System.out.println(\"Interrupt thread...: \" + m1.getName());\n        m1.stop = true; // 设置共享变量为true\n        m1.interrupt(); // 阻塞时退出阻塞状态\n        Thread.sleep(3000); // 主线程休眠3秒以便观察线程m1的中断情况\n        System.out.println(\"Stopping application...\");\n    &#125;\n&#125;\n\n3.3.notify()和notifyAll()有什么区别？notify可能会导致死锁，而notifyAll则不会，任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行synchronized 中的代码使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。wait() 应配合while循环使用，不应使用if，务必在wait()调用前后都检查条件，如果不满足，必须调用notify()唤醒另外的线程来处理，自己继续wait()直至条件满足再往下执行。notify() 是对notifyAll()的一个优化，但它有很精确的应用场景，并且要求正确使用。不然可能导致死锁。正确的场景应该是 WaitSet中等待的是相同的条件，唤醒任一个都能正确处理接下来的事项，如果唤醒的线程无法正确处理，务必确保继续notify()下一个线程，并且自身需要重新回到WaitSet中。\n3.4.sleep()和wait() 有什么区别？对于sleep()方法，我们首先要知道该方法是属于Thread类中的。而wait()方法，则是属于Object类中的。sleep()方法导致了程序暂停执行指定的时间，让出cpu给其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。在调用sleep()方法的过程中，线程不会释放对象锁。当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备，获取对象锁进入运行状态。\n3.5.volatile 是什么?可以保证有序性吗?一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：\n\n\n\n\n\n\n\n\n\n\n保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的,volatile关键字会强制将修改的值立即写入主存。\n禁止进行指令重排序。\n\nvolatile 不是原子性操作什么叫保证部分有序性?当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；\nx = 2;     //语句1\ny = 0;     //语句2\nflag = true;  //语句3\nx = 4;     //语句4\ny = -1;    //语句5\n由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。使用 Volatile 一般用于状态标记量和单例模式的双检锁\n3.6.Thread 类中的start() 和 run() 方法有什么区别？start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。\n3.7.为什么wait, notify 和 notifyAll这些方法不在thread类里面？明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。\n3.8.为什么wait和notify方法要在同步块中调用？\n只有在调用线程拥有某个对象的独占锁时，才能够调用该对象的wait(),notify()和notifyAll()方法。\n如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。\n还有一个原因是为了避免wait和notify之间产生竞态条件。\n\nwait()方法强制当前线程释放对象锁。这意味着在调用某对象的wait()方法之前，当前线程必须已经获得该对象的锁。因此，线程必须在某个对象的同步方法或同步代码块中才能调用该对象的wait()方法。在调用对象的notify()和notifyAll()方法之前，调用线程必须已经得到该对象的锁。因此，必须在某个对象的同步方法或同步代码块中才能调用该对象的notify()或notifyAll()方法。调用wait()方法的原因通常是，调用线程希望某个特殊的状态(或变量)被设置之后再继续执行。调用notify()或notifyAll()方法的原因通常是，调用线程希望告诉其他等待中的线程:“特殊状态已经被设置”。这个状态作为线程间通信的通道，它必须是一个可变的共享状态(或变量)。\n3.9.Java中interrupted 和 isInterruptedd方法的区别？interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其它线程调用中断来改变。\n3.10.Java中synchronized 和 ReentrantLock 有什么不同？相似点这两种同步方式有很多相似之处，它们都是加锁方式同步，而且都是阻塞式的同步，也就是说当如果一个线程获得了对象锁，进入了同步块，其他访问该同步块的线程都必须阻塞在同步块外面等待，而进行线程阻塞和唤醒的代价是比较高的.区别这两种方式最大区别就是对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try&#x2F;finally语句块来完成。Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：\n\n等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。\n公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。\n锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。\n\n3.11.有三个线程T1,T2,T3,如何保证顺序执行？在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。实际上先启动三个线程中哪一个都行，因为在每个线程的run方法中用join方法限定了三个线程的执行顺序\npublic class JoinTest2 &#123;\n  // 1.现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行\n  public static void main(String[] args) &#123;\n    final Thread t1 = new Thread(new Runnable() &#123;\n      @Override\n      public void run() &#123;\n        System.out.println(\"t1\");\n     &#125;\n   &#125;);\n    final Thread t2 = new Thread(new Runnable() &#123;\n      @Override\n      public void run() &#123;\n        try &#123;\n          // 引用t1线程，等待t1线程执行完\n          t1.join();\n       &#125; catch (InterruptedException e) &#123;\n          e.printStackTrace();\n       &#125;\n        System.out.println(\"t2\");\n     &#125;\n   &#125;);\n    Thread t3 = new Thread(new Runnable() &#123;\n      @Override\n      public void run() &#123;\n        try &#123;\n          // 引用t2线程，等待t2线程执行完\n          t2.join();\n       &#125; catch (InterruptedException e) &#123;\n          e.printStackTrace();\n       &#125;\n        System.out.println(\"t3\");\n     &#125;\n     &#125;);\n    t3.start();//这里三个线程的启动顺序可以任意，大家可以试下！\n    t2.start();\n    t1.start();\n &#125;\n&#125;\n3.12.SynchronizedMap和ConcurrentHashMap有什么区别？SynchronizedMap()和Hashtable一样，实现上在调用map所有方法时，都对整个map进行同步。而ConcurrentHashMap的实现却更加精细，它对map中的所有桶加了锁。所以，只要有一个线程访问map，其他线程就无法进入map，而如果一个线程在访问ConcurrentHashMap某个桶时，其他线程，仍然可以对map执行某些操作。所以，ConcurrentHashMap在性能以及安全性方面，明显比Collections.synchronizedMap()更加有优势。同时，同步操作精确控制到桶，这样，即使在遍历map时，如果其他线程试图对map进行数据修改，也不会抛出ConcurrentModificationException。\n3.13.什么是线程安全线程安全就是说多线程访问同一代码，不会产生不确定的结果。在多线程环境中，当各线程不共享数据的时候，即都是私有（private）成员，那么一定是线程安全的。但这种情况并不多见，在多数情况下需要共享数据，这时就需要进行适当的同步控制了。线程安全一般都涉及到synchronized， 就是一段代码同时只能有一个线程来操作 不然中间过程可能会产生不可预制的结果。如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。\n3.14.Thread类中的yield方法有什么作用？Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行\n3.15.Java线程池中submit() 和 execute()方法有什么区别？两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。\n3.16.说一说自己对于 synchronized 关键字的了解synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。\n3.17.说说自己是怎么使用 synchronized 关键字，在项目中用到了吗？synchronized关键字最主要的三种使用方式：\n\n修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁\n修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。\n修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。\n\n\n\n\n\n\n\n\n总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能\n\n\n3.18.什么是线程安全？Vector是一个线程安全类吗？如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量 的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。\n3.19.volatile关键字的作用？一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：\n\n保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。\n禁止进行指令重排序。\n\n\n\n\n\n\n\n\nvolatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。volatile仅能实现变量的修改可见性，并不能保证原子性；synchronized则可以保证变量的修改可见性和原子性。volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。\n\n\nvolatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。\n3.20.常用的线程池有哪些？newSingleThreadExecutor：创建一个单线程的线程池，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。newFixedThreadPool：创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。newCachedThreadPool：创建一个可缓存的线程池，此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。newScheduledThreadPool：创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。newSingleThreadExecutor：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。\n3.21.简述一下你对线程池的理解（如果问到了这样的问题，可以展开的说一下线程池如何用、线程池的好处、线程池的启动策略）合理利用线程池能够带来三个好处。\n\n降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n提高响应速度：当任务到达时，任务可以不需要等到线程创建就能立即执行。\n提高线程的可管理性：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n3.22.说说自己是怎么使用 synchronized 关键字，在项目中用到了吗synchronized关键字最主要的三种使用方式：\n\n修饰实例方法：作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁\n修饰静态方法：作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 。也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static表明这是该类的一个静态资源，不管new了多少个对象，只有一份，所以对该类的所有对象都加了锁）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。\n修饰代码块：指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 和synchronized 方法一样，synchronized(this)代码块也是锁定当前对象的。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。\n\n\n\n\n\n\n\n\n这里再提一下：synchronized关键字加到非 static 静态方法上是给对象实例上锁。另外需要注意的是：尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓冲功能！\n\n\n下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单利模式的原理！”双重校验锁实现对象单例（线程安全）\npublic class Singleton &#123;\n    private volatile static Singleton uniqueInstance;\n    private Singleton() &#123;\n    &#125;\n    public static Singleton getUniqueInstance() &#123;\n        //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) &#123;\n            //类对象加锁\n            synchronized (Singleton.class) &#123;\n                if (uniqueInstance == null) &#123;\n                    uniqueInstance = new Singleton();\n                &#125;\n            &#125;\n        &#125;\n        return uniqueInstance;\n    &#125;\n&#125;\n另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance &#x3D; new Singleton(); 这段代码其实是分为三步执行：\n\n为 uniqueInstance 分配内存空间\n初始化 uniqueInstance\n将 uniqueInstance 指向分配的内存地址\n\n但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出先问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回uniqueInstance，但此时 uniqueInstance 还未被初始化。使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。\n3.23.讲一下 synchronized 关键字的底层原理synchronized 关键字底层原理属于 JVM 层面。\nsynchronized 同步语句块的情况public class SynchronizedDemo &#123;\n\tpublic void method() &#123;\n\t\tsynchronized (this) &#123;\n\t\t\tSystem.out.println(\"synchronized 代码块\");\n\t\t&#125;\n\t&#125;\n&#125;\n通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行** javap -c -s -v -l SynchronizedDemo.class **。从上面我们可以看出：synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\nsynchronized 修饰方法的的情况public class SynchronizedDemo &#123;\n\tpublic synchronized void method() &#123;\n\t\tSystem.out.println(\"synchronized 方法\");\n\t&#125;\n&#125;\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n3.24.为什么要用线程池？线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。\n\n降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。\n提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n3.25.实现Runnable接口和Callable接口的区别如果想让线程池执行任务的话需要实现的Runnable接口或Callable接口。 Runnable接口或Callable接口实现类都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。两者的区别在于Runnable 接口不会返回结果但是 Callable 接口可以返回结果。备注： 工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。( Executors.callable（Runnable task） 或 Executors.callable(Runnable task，Object resule))。\n3.26.执行execute()方法和submit()方法的区别是什么呢？\nexecute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；\nsubmit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit） 方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。\n\n3.27.如何创建线程池\n通过构造方法实现\n通过Executor 框架的工具类Executors来实现，我们可以创建三种类型的ThreadPoolExecutor：\n\n\n\n\n\n\n\n\nFixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。SingleThreadExecutor： 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n\n\n四、Spring篇4.1.Spring的IOC和AOP机制？我们是在使用Spring框架的过程中，其实就是为了使用IOC，依赖注入，和AOP，面向切面编程，这两个是Spring的灵魂主要用到的设计模式有工厂模式和代理模式。IOC就是典型的工厂模式，通过sessionfactory去注入实例。AOP就是典型的代理模式的体现。代理模式是常用的java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。spring的IOC容器是spring的核心，spring AOP是spring框架的重要组成部分。在传统的程序设计中，当调用者需要被调用者的协助时，通常由调用者来创建被调用者的实例。但在spring里创建被调用者的工作不再由调用者来完成，因此控制反转（IOC）；创建被调用者实例的工作通常由spring容器来完成，然后注入调用者，因此也被称为依赖注入（DI），依赖注入和控制反转是同一个概念。面向方面编程（AOP)是以另一个角度来考虑程序结构，通过分析程序结构的关注点来完善面向对象编程（OOP）。OOP将应用程序分解成各个层次的对象，而AOP将程序分解成多个切面。spring AOP 只实现了方法级别的连接点，在J2EE应用中，AOP拦截到方法级别的操作就已经足够。在spring中，未来使IOC方便地使用健壮、灵活的企业服务，需要利用spring AOP实现为IoC和企业服务之间建立联系。IOC:控制反转也叫依赖注入。利用了工厂模式将对象交给容器管理，你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类（假设这个类名是A），分配的方法就是调用A的setter方法来注入，而不需要你在A里面new这些bean了。spring IOC初始化流程:AOP:面向切面编程。（Aspect-Oriented Programming）AOP可以说是对OOP的补充和完善。OOP引入封装、继承和多态性等概念来建立一种对象层次结构，用以模拟公共行为的一个集合。当我们需要为分散的对象引入公共行为的时候，OOP则显得无能为力。也就是说，OOP允许你定义从上到下的关系，但并不适合定义从左到右的关系。例如日志功能。日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。将程序中的交叉业务逻辑（比如安全，日志，事务等），封装成一个切面，然后注入到目标对象（具体业务逻辑）中去。实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。\n4.2.Spring中Autowired和Resource关键字的区别？@Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。\n共同点两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。\n不同点@Autowired@Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。\npublic class TestServiceImpl &#123;\n  // 下面两种@Autowired只要使用一种即可\n  @Autowired\n  private UserDao userDao; // 用于字段上\n \n  @Autowired\n  public void setUserDao(UserDao userDao) &#123; // 用于属性的方法上\n    this.userDao = userDao;\n &#125;\n&#125;\n@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。如下：\n@Resource@Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。\npublic class TestServiceImpl &#123;\n  // 下面两种@Resource只要使用一种即可\n  @Resource(name=\"userDao\")\n  private UserDao userDao; // 用于字段上\n \n  @Resource(name=\"userDao\")\n  public void setUserDao(UserDao userDao) &#123; // 用于属性的setter方法上\n    this.userDao = userDao;\n &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n注：最好是将@Resource放在setter方法上，因为这样更符合面向对象的思想，通过set、get去操作属性，而不是直接去操作属性。\n@Resource装配顺序：\n\n如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。\n如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。\n如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。\n如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。@Resource的作用相当于@Autowired，只不过@Autowired按照byType自动注入。\n\n4.3.依赖注入的方式有几种，各是什么?\n构造器注入将被依赖对象通过构造函数的参数注入给依赖对象，并且在初始化对象的时候注入。优点：对象初始化完成后便可获得可使用的对象。缺点：当需要注入的对象很多时，构造器参数列表将会很长；不够灵活。若有多种注入方式，每种方式只需注入指定几个依赖，那么就需要提供多个重载的构造函数，麻烦。\nsetter方法注入IoC Service Provider通过调用成员变量提供的setter函数将被依赖对象注入给依赖类。优点：灵活。可以选择性地注入需要的对象。缺点：依赖对象初始化完成后由于尚未注入被依赖对象，因此还不能使用。\n接口注入依赖类必须要实现指定的接口，然后实现该接口中的一个函数，该函数就是用于依赖注入。该函数的参数就是要注入的对象。优点：接口注入中，接口的名字、函数的名字都不重要，只要保证函数的参数是要注入的对象类型即可。缺点：侵入行太强，不建议使用。\n\n\n\n\n\n\n\n\nPS：什么是侵入行？如果类A要使用别人提供的一个功能，若为了使用这功能，需要在自己的类中增加额外的代码，这就是侵入性。\n\n\n4.4.讲一下什么是SpringSpring是一个轻量级的IoC和AOP容器框架。是为Java应用程序提供基础性服务的一套框架，目的是用于简化企业应用程序的开发，它使得开发者只需要关心业务需求。常见的配置方式有三种：基于XML的配置、基于注解的配置、基于Java的配置。主要由以下几个模块组成：Spring Core：核心类库，提供IOC服务；Spring Context：提供框架式的Bean访问方式，以及企业级功能（JNDI、定时任务等）；Spring AOP：AOP服务；Spring DAO：对JDBC的抽象，简化了数据访问异常的处理；Spring ORM：对现有的ORM框架的支持；Spring Web：提供了基本的面向Web的综合特性，例如多方文件上传；Spring MVC：提供面向Web应用的Model-View-Controller实现。\n4.5.Spring MVC流程执行前；当一个请求发来时先进服务器（Tomcat）,在服务器中会有拦截器，过滤器啊，等这些功能走完之后，才真正的进入了框架中。\n\n用户发来一个请求，首先进入的是前端控制器DispatcherServlet\n前端控制器将（DispacherServlet）用户发来的请求发送给处理器映射器（HandlerMapping）\n处理器映射器根据前端控制器发来的用户的请求找到对应符合的控制器（Handler）,并且将其封装成处理器执行链，返回给前端控制器。\n处理器适配器接收到来自前端控制器的执行链后，找到对应执行此执行链的处理器适配器（HandlerAdapter）来调用的具体的控制器（就是说其对应的方法或者逻辑）\n控制器执行完成后，会返回一个ModelAndView对象给处理器适配器\n处理器适配器将返回来的ModelAndView对象返回给前端控制器(到这里所有的业务处理过程就要完了，接下就是将结果以页面的的形式相应给用户)\n前端控制器将返回回来的ModelAndView对象交给视图解析器（ViewResolver），视图解析器根据传过里的View对象解析成对应的页面对象，然后将页面对象和Model对象返回给前端控制器。\n前端控制器再将返回回来的对象交给视图（View）,视图根据传过来的Model对象再一次的对页面进行渲染，然后在返回给前端控制器。\n前端控制器将完成的结果响应给浏览器，然后浏览器在展现给用户。\n\n组件说明：以下组件通常使用框架提供实现：DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。\n4.6.SpringMVC怎么样设定重定向和转发的？转发：在返回值前面加”forward:“，譬如”forward:user.do?name&#x3D;alihai5”重定向：在返回值前面加”redirect:”，如”redirect:https://www.alihai5.com“\n4.7.SpringMVC常用的注解有哪些？@RequestMapping：用于处理请求 url 映射的注解，可用于类或方法上。用于类上，则表示类中的所有响应请求的方法都是以该地址作为父路径。@RequestBody：注解实现接收http请求的json数据，将json转换为java对象。@ResponseBody：注解实现将conreoller方法返回对象转化为json对象响应给客户\n4.8.Spring的AOP理解：OOP面向对象，允许开发者定义纵向的关系，但并适用于定义横向的关系，导致了大量代码的重复，而不利于各个模块的重用。AOP，一般称为面向切面，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，同时提高了系统的可维护性。可用于权限认证、日志、事务处理。AOP实现的关键在于 代理模式，AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。\n\nAspectJ是静态代理的增强，所谓静态代理，就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ(切面)织入到Java字节码中，运行的时候就是增强之后的AOP对象。\nSpring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。\n静态代理与动态代理区别在于生成AOP代理对象的时机不同，相对来说AspectJ的静态代理方式具有更好的性能，但是AspectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理。\n\n\n\n\n\n\n\n\nSpring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理：\n\nJDK动态代理只提供接口的代理，不支持类的代理。核心InvocationHandler接口和Proxy类，InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy利用 InvocationHandler动态创建一个符合某一接口的的实例, 生成目标类的代理对象。\n如果代理类没有实现 InvocationHandler 接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。\n\n\n\n4.9.Spring的IOC理解\nIOC就是控制反转，是指创建对象的控制权的转移，以前创建对象的主动权和时机是由自己把控的，而现在这种权力转移到Spring容器中，并由容器根据配置文件去创建实例和管理各个实例之间的依赖关系，对象与对象之间松散耦合，也利于功能的复用。DI依赖注入，和控制反转是同一个概念的不同角度的描述，即 应用程序在运行时依赖IoC容器来动态注入对象需要的外部资源。\n最直观的表达就是，IOC让对象的创建不用去new了，可以由spring自动生产，使用java的反射机制，根据配置文件在运行时动态的去创建对象以及管理对象，并调用对象的方法的。\nSpring的IOC有三种注入方式 ：构造器注入、setter方法注入、根据注解注入。IoC让相互协作的组件保持松散的耦合，而AOP编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件。\n\n4.10.解释一下spring bean的生命周期首先说一下Servlet的生命周期：实例化，初始init，接收请求service，销毁destroy；Spring上下文中的Bean生命周期也类似，如下：\n\n实例化Bean：对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。对于ApplicationContext容器，当容器启动结束后，通过获取BeanDefinition对象中的信息，实例化所有的bean。\n\n设置对象属性（依赖注入）：实例化后的对象被封装在BeanWrapper对象中，紧接着，Spring根据BeanDefinition中的信息 以及 通过BeanWrapper提供的设置属性的接口完成依赖注入。\n\n处理Aware接口：接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean：\n\n\n\n\n\n\n\n\n\n①如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，此处传递的就是Spring配置文件中Bean的id值；②如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()方法，传递的是Spring工厂自身。③如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；\n\nBeanPostProcessor：如果想对Bean进行一些自定义的处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用postProcessBeforeInitialization(Object obj, String s)方法。\n\nInitializingBean 与 init-method：如果Bean在Spring配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。\n\n如果这个Bean实现了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法；由于这个方法是在Bean初始化结束时调用的，所以可以被应用于内存或缓存技术。\n\n\n以上几个步骤完成后，Bean就已经被正确创建了，之后就可以使用这个Bean了。\n\nDisposableBean：当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法。\ndestroy-method：最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。\n\n4.11.解释Spring支持的几种bean的作用域。Spring容器中的bean可以分为5个范围：\n\nsingleton：默认，每个容器中只有一个bean的实例，单例的模式由BeanFactory自身来维护。\nprototype：为每一个bean请求提供一个实例。\nrequest：为每一个网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收。\nsession：与request范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效。\nglobal-session：全局作用域，global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。全局作用域与Servlet中的session作用域效果相同。\n\n4.12. Spring基于xml注入bean的几种方式：\nSet方法注入；\n构造器注入：\n通过index设置参数的位置；\n通过type设置参数类型；\n\n\n静态工厂注入；\n实例工厂；\n\n4.13.Spring框架中都用到了哪些设计模式？\n工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例；\n单例模式：Bean默认为单例模式。\n代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；\n模板方法：用来解决代码重复的问题。比如RestTemplate,JmsTemplate, JpaTemplate。\n观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener.\n\n五、MyBatis篇5.1.什么是MyBatis\nMybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。程序员直接编写原生态sql，可以严格控制sql执行性能，灵活度高。\nMyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。\n通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。\n\n5.2.MyBatis的优点和缺点优点\n\n基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用。\n与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接；\n很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持）。\n能够与Spring很好的集成；\n提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护。\n\n缺点\n\nSQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。\nSQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。\n\n5.3.#{}和${}的区别是什么？#{}是预编译处理，$ {}是字符串替换。Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；Mybatis在处理$ {}时，就是把$ {}替换成变量的值。使用#{}可以有效的防止SQL注入，提高系统安全性。\n5.4.当实体类中的属性名和表中的字段名不一样 ，怎么办 ？第1种： 通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。\n&lt;select id=\"selectorder\" parametertype=\"int\"\n  resultetype=\"me.gacl.domain.order\">\n  select order_id id, order_no orderno ,order_price price form orders where\n  order_id=#&#123;id&#125;;\n&lt;/select>\n第2种： 通过来映射字段名和实体类属性名的一一对应的关系。\n&lt;select id=\"getOrder\" parameterType=\"int\" resultMap=\"orderresultmap\">\n  select * from orders where order_id=#&#123;id&#125;\n&lt;/select>\n&lt;resultMap type=\"me.gacl.domain.order\" id=\"orderresultmap\">\n  &lt;!–用id属性来映射主键字段–>\n  &lt;id property=\"id\" column=\"order_id\">\n    &lt;!–用result属性来映射非主键字段，property为实体类属性名，column为数据表中的属性–>\n    &lt;result property = \"orderno\" column =\"order_no\"/>\n      &lt;result property=\"price\" column=\"order_price\" />\n&lt;/reslutMap>\n5.5.Mybatis是如何进行分页的？分页插件的原理是什么？Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。\n5.6.Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？第一种是使用标签，逐一定义数据库列名和对象属性名之间的映射关系。第二种是使用sql列的别名功能，将列的别名书写为对象属性名。有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。\n5.7.如何执行批量插入？首先,创建一个简单的insert语句:\n&lt;insert id=\"insertname\">\n  insert into names (name) values (#&#123;value&#125;)\n&lt;/insert>\n\n然后在java代码中像下面这样执行批处理插入:\nlist&lt;string> names = new arraylist();\nnames.add(“fred”);\nnames.add(“barney”);\nnames.add(“betty”);\nnames.add(“wilma”);\n// 注意这里 executortype.batch\nsqlsession sqlsession = sqlsessionfactory.opensession(executortype.batch);\ntry &#123;\n    namemapper mapper = sqlsession.getmapper(namemapper.class);\n    for (string name : names) &#123;\n        mapper.insertname(name);\n    &#125;\n    sqlsession.commit();\n&#125;catch(Exception e)&#123;\n    e.printStackTrace();\n    sqlSession.rollback();\n    throw e;\n&#125;\nfinally &#123;\n    sqlsession.close();\n&#125;\n5.8.MyBatis实现一对一有几种方式?具体怎么操作的？有联合查询和嵌套查询,联合查询是几个表联合查询,只查询一次, 通过在resultMap里面配置association节点配置一对一的类就可以完成；嵌套查询是先查一个表，根据这个表里面的结果的 外键id，去再另外一个表里面查询数据,也是通过association配置，但另外一个表的查询通过select属性配置。\n5.9.Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled&#x3D;true|false。它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理。当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的\n5.10.Mybatis的一级、二级缓存:\n一级缓存: 基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存。\n二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口(可用来保存对象的状态),可在它的映射文件中配置 ；\n对于缓存数据更新机制，当某一个作用域(一级缓存 Session&#x2F;二级缓存Namespaces)的进行了C&#x2F;U&#x2F;D操作后，默认该作用域下所有 select 中的缓存将被 clear 掉并重新更新，如果开启了二级缓存，则只根据配置判断是否刷新。\n\n六、SpringBoot篇6.1.什么是SpringBoot？为什么要用SpringBoot用来简化spring应用的初始搭建以及开发过程 使用特定的方式来进行配置（properties或yml文件）创建独立的spring引用程序 main方法运行嵌入的Tomcat 无需部署war文件简化maven配置自动配置spring添加对应功能starter自动化配置spring boot来简化spring应用开发，约定大于配置，去繁从简，just run就能创建一个独立的，产品级别的应用Spring Boot 优点非常多，如：一、独立运行Spring Boot而且内嵌了各种servlet容器，Tomcat、Jetty等，现在不再需要打成war包部署到容器中，Spring Boot只要打成一个可执行的jar包就能独立运行，所有的依赖包都在一个jar包内。二、简化配置spring-boot-starter-web启动器自动依赖其他组件，简少了maven的配置。三、自动配置Spring Boot能根据当前类路径下的类、jar包来自动配置bean，如添加一个spring-boot-starter-web启动器就能拥有web的功能，无需其他配置。四、无代码生成和XML配置Spring Boot配置过程中无代码生成，也无需XML配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的，这也是Spring4.x的核心功能之一。五、应用监控Spring Boot提供一系列端点可以监控服务及应用，做健康检测。\n6.2.Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下3 个注解：@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude &#x3D; { DataSourceAutoConfiguration.class })。@ComponentScan：Spring组件扫描。\n6.3.运行Spring Boot有哪几种方式？\n打包用命令或者放到容器中运行\n用 Maven&#x2F;Gradle 插件运行\n直接执行 main 方法运行\n\n6.4.如何理解 Spring Boot 中的 Starters？\n\n\n\n\n\n\n\n\nStarters是什么：Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成Spring及其他技术，而不需要到处找示例代码和依赖包。如你想使用Spring JPA访问数据库，只要加入spring-boot-starter-data-jpa启动器依赖就能使用了。Starters包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。Starters命名：Spring Boot官方的启动器都是以spring-boot-starter-命名的，代表了一个特定的应用类型。第三方的启动器不能以spring-boot开头命名，它们都被Spring Boot官方保留。一般一个第三方的应该这样命名，像mybatis的mybatis-spring-boot-starter。\nStarters分类：\n\nSpring Boot应用类启动器\n\n\n\n启动器名称\n功能描述\n\n\n\nspring-boot-starter\n包含自动配置、日志、YAML的支持。\n\n\nspring-boot-starter-web\n使用Spring MVC构建web 工程，包含restful，默认使用Tomcat容器。\n\n\n……\n…..\n\n\n\nSpring Boot生产启动器\n\n\n\n启动器名称\n功能描述\n\n\n\nspring-boot-starter-actuator\n提供生产环境特性，能监控管理应用。\n\n\n\nSpring Boot技术类启动器\n\n\n\n启动器名称\n功能描述\n\n\n\nspring-boot-starter-json\n提供对JSON的读写支持。\n\n\nspring-boot-starter-logging\n默认的日志启动器，默认使用Logback。\n\n\n……\n…..\n\n\n\n其他第三方启动器\n\n\n6.5.如何在Spring Boot启动的时候运行一些特定的代码？如果你想在Spring Boot启动的时候运行一些特定的代码，你可以实现接口ApplicationRunner或者CommandLineRunner，这两个接口实现方式一样，它们都只提供了一个run方法。CommandLineRunner：启动获取命令行参数\n6.6.Spring Boot 需要独立的容器运行吗？可以不需要，内置了 Tomcat&#x2F; Jetty 等容器。\n6.7. Spring Boot中的监视器是什么？Spring boot actuator是spring启动框架中的重要功能之一。Spring boot监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为HTTP URL访问的REST端点来检查状态\n6.8. 如何使用Spring Boot实现异常处理？Spring提供了一种使用ControllerAdvice处理异常的非常有用的方法。 我们通过实现一个ControlerAdvice类，来处理控制器类抛出的所有异常\n6.9.你如何理解 Spring Boot 中的 Starters？Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring及其他技术，而不需要到处找示例代码和依赖包。如你想使用 Spring JPA 访问数据库，只要加入spring-boot-starter-data-jpa 启动器依赖就能使用了\n6.10. springboot常用的starter有哪些spring-boot-starter-web 嵌入tomcat和web开发需要servlet与jsp支持spring-boot-starter-data-jpa 数据库支持spring-boot-starter-data-redis redis数据库支持spring-boot-starter-data-solr solr支持mybatis-spring-boot-starter 第三方的mybatis集成starter\n6.11.SpringBoot 实现热部署有哪几种方式？主要有两种方式：\n\nSpring Loaded\nSpring-boot-devtools\n\n6.12.如何理解 Spring Boot 配置加载顺序？在 Spring Boot 里面，可以使用以下几种方式来加载配置。\n\nproperties文件；\nYAML文件；\n系统环境变量；\n命令行参数；等等……\n\n6.13.Spring Boot 的核心配置文件有哪几个？它们的区别是什么？spring Boot 的核心配置文件是 application 和 bootstrap 配置文件。application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置。bootstrap 配置文件有以下几个应用场景：\n\n使用 Spring Cloud Config 配置中心时，这时需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息；\n一些固定的不能被覆盖的属性；\n一些加密&#x2F;解密的场景；\n\n6.14.如何集成 Spring Boot 和 ActiveMQ？对于集成 Spring Boot 和 ActiveMQ，我们使用spring-boot-starter-activemq依赖关系。 它只需要很少的配置，并且不需要样板代码。\n6.15.如何重新加载Spring Boot上的更改，而无需重新启动服务器？这可以使用DEV工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat将重新启动。Spring Boot有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力。Java开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。开发人员可以重新加载Spring Boot上的更改，而无需重新启动服务器。这将消除每次手动部署更改的需要。Spring Boot在发布它的第一个版本时没有这个功能。这是开发人员最需要的功能。DevTools模块完全满足开发人员的需求。该模块将在生产环境中被禁用。\n6.16.Spring Boot、Spring MVC 和 Spring 有什么区别？SpringSpring最重要的特征是依赖注入。所有 SpringModules 不是依赖注入就是 IOC 控制反转。当我们恰当的使用 DI 或者是 IOC 的时候，我们可以开发松耦合应用。松耦合应用的单元测试可以很容易的进行。Spring MVCSpring MVC 提供了一种分离式的方法来开发 Web 应用。通过运用像 DispatcherServelet，MoudlAndView 和 ViewResolver 等一些简单的概念，开发 Web 应用将会变的非常简单。SpringBootSpring 和 SpringMVC 的问题在于需要配置大量的参数。Spring Boot 通过一个自动配置和启动的项来目解决这个问题。为了更快的构建产品就绪应用程序，Spring Boot 提供了一些非功能性特征。\n6.17.pring Boot 还提供了其它的哪些 Starter Project Options？Spring Boot 也提供了其它的启动器项目包括，包括用于开发特定类型应用程序的典型依赖项。spring-boot-starter-web-services - SOAP Web Services；spring-boot-starter-web - Web 和 RESTful 应用程序；spring-boot-starter-test - 单元测试和集成测试；spring-boot-starter-jdbc - 传统的 JDBC；spring-boot-starter-hateoas - 为服务添加 HATEOAS 功能；spring-boot-starter-security - 使用 SpringSecurity 进行身份验证和授权；spring-boot-starter-data-jpa - 带有 Hibeernate 的 Spring Data JPA；spring-boot-starter-data-rest - 使用 Spring Data REST 公布简单的 REST 服务；\n七、MySQL篇7.1.数据库的三范式是什么第一范式：列不可再分第二范式：行可以唯一区分，主键约束第三范式：表的非主属性不能依赖与其他表的非主属性 外键约束且三大范式是一级一级依赖的，第二范式建立在第一范式上，第三范式建立第一第二范式上。\n7.2.数据库引擎有哪些如何查看mysql提供的所有存储引擎\nmysql> show engines;\nmysql常用引擎包括：MYISAM、Innodb、Memory、MERGEMYISAM：全表锁，拥有较高的执行速度，不支持事务，不支持外键，并发性能差，占用空间相对较小，对事务完整性没有要求，以select、insert为主的应用基本上可以使用这引擎Innodb：行级锁，提供了具有提交、回滚和崩溃回复能力的事务安全，支持自动增长列，支持外键约束，并发能力强，占用空间是MYISAM的2.5倍，处理效率相对会差一些Memory：全表锁，存储在内容中，速度快，但会占用和数据量成正比的内存空间且数据在mysql重启时会丢失，默认使用HASH索引，检索效率非常高，但不适用于精确查找，主要用于那些内容变化不频繁的代码表MERGE：是一组MYISAM表的组合\n7.3.InnoDB与MyISAM的区别\nInnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；\nInnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败；\nInnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。\nInnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；\nInnodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高；\n\n如何选择引擎？如果没有特别的需求，使用默认的 Innodb 即可。MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统\n7.4.数据库的事务什么是事务？： 多条sql语句，要么全部成功，要么全部失败。事务的特性：数据库事务特性：原子性(Atomic)、一致性(Consistency)、隔离性(Isolation)、持久性(Durabiliy)。简称ACID。原子性：组成一个事务的多个数据库操作是一个不可分割的原子单元，只有所有操作都成功，整个事务才会提交。任何一个操作失败，已经执行的任何操作都必须撤销，让数据库返回初始状态。一致性：事务操作成功后，数据库所处的状态和它的业务规则是一致的。即数据不会被破坏。如A转账100元给B，不管操作是否成功，A和B的账户总额是不变的。隔离性：在并发数据操作时，不同的事务拥有各自的数据空间，它们的操作不会对彼此产生干扰持久性：一旦事务提交成功，事务中的所有操作都必须持久化到数据库中。\n7.5.索引问题索引是对数据库表中一个或多个列的值进行排序的结构，建立索引有助于快速获取信息。你也可以这样理解：索引就是加快检索表中数据的方法。数据库的索引类似于书籍的索引。在书籍中，索引允许用户不必翻阅完整个书就能迅速地找到所需要的信息。在数据库中，索引也允许数据库程序迅速地找到表中的数据，而不必扫描整个数据库。mysql 有4种不同的索引：主键索引（PRIMARY）数据列不允许重复，不允许为NULL，一个表只能有一个主键。唯一索引（UNIQUE）数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引普通索引（INDEX）可以通过 ALTER TABLE table_name ADD INDEX index_name (column); 创建普通索引可以通过 ALTER TABLE table_name ADD INDEX index_name(column1,column2,column3); 创建组合索引全文索引（FULLTEXT）可以通过 ALTER TABLE table_name ADD FULLTEXT (column); 创建全文索引索引并非是越多越好，创建索引也需要耗费资源，一是增加了数据库的存储空间，二是在插入和删除时要花费较多的时间维护索引\n\n\n\n\n\n\n\n\n\n索引加快数据库的检索速度索引降低了插入、删除、修改等维护任务的速度唯一索引可以确保每一行数据的唯一性通过使用索引，可以在查询的过程中使用优化隐藏器，提高系统的性能索引需要占物理和数据空间\n7.6.SQL优化\n查询语句中不要使用select *\n尽量减少子查询，使用关联查询（left join,right join,inner join）替代\n减少使用IN或者NOT IN ,使用exists，not exists或者关联查询语句替代\nor 的查询尽量用 union或者union all 代替(在确认没有重复数据或者不用剔除重复数据时，union all会更好)\n应尽量避免在 where 子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。\n应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num&#x3D;0\n\n7.7.简单说一说drop、delete与truncate的区别SQL中的drop、delete、truncate都表示删除，但是三者有一些差别delete和truncate只删除表的数据不删除表的结构速度,一般来说: drop&gt; truncate &gt;deletedelete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效;如果有相应的trigger,执行的时候将被触发. truncate,drop是ddl, 操作立即生效,原数据不放到rollback segment中,不能回滚. 操作不触发trigger。\n7.8.什么是视图视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。\n7.9.什么是内联接、左外联接、右外联接？\n内联接（Inner Join）：匹配2张表中相关联的记录。\n左外联接（Left Outer Join）：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。\n右外联接（Right Outer Join）：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。在判定左表和右表时，要根据表名出现在Outer Join的左右位置关系。\n\n7.10.并发事务带来哪些问题?在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A&#x3D;20，事务2也读取A&#x3D;20，事务1修改A&#x3D;A-1，事务2也修改A&#x3D;A-1，最终结果A&#x3D;19，事务1的修改被丢失。不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。\n\n\n\n\n\n\n\n\n\n不可重复读和幻读区别：不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。\n7.11.事务隔离级别有哪些?MySQL的默认隔离级别是?SQL 标准定义了四个隔离级别：READ-UNCOMMITTED(读取未提交) ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。READ-COMMITTED(读取已提交) ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。REPEATABLE-READ(可重复读) ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。SERIALIZABLE(可串行化) ： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。\n\n\n\n隔离级别\n脏读\n不可重复读\n幻影读\n\n\n\nREAD-UNCOMMITTED\n√\n√\n√\n\n\nREAD-COMMITTED\n×\n√\n√\n\n\nREPEATABLE-READ\n×\n×\n√\n\n\nSERIALIZABLE\n×\n×\n×\n\n\nMySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation; 命令来查看\nmysql> SELECT @@tx_isolation;\n+-----------------+\n| @@tx_isolation |\n+-----------------+\n| REPEATABLE-READ |\n+-----------------+\n\n\n\n\n\n\n\n\n\n这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEAaTABLE-READ（可重读） 并不会有任何性能损失。InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。\n7.12.大表如何优化？当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下:\n\n限定数据的范围务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；\n读&#x2F;写分离经典的数据库拆分方案，主库负责写，从库负责读；\n垂直分区根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I&#x2F;O次数。此外，垂直分区可以简化表的结构，易于维护。垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；\n水平分区保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。水平拆分能够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I&#x2F;O。\n\n\n\n\n\n\n\n\n下面补充一下数据库分片的两种常见方案：客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。中间件代理： 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。\n\n\n7.13.分库分表之后,id 主键如何处理？因为要是分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全局唯一的 id 来支持。生成全局 id 有下面这几种方式：UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。数据库自增 id : 两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。利用 redis 生成 id : 性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。Twitter的snowflake算法 ：Github 地址：snowflake。美团的Leaf分布式ID生成系统 ：Leaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。美团技术团队的一篇文章：leaf 。\n7.14.mysql有关权限的表都有哪几个MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。db权限表：记录各个帐号在各个数据库上的操作权限。table_priv权限表：记录数据表级的操作权限。columns_priv权限表：记录数据列级的操作权限。host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。\n7.15.mysql有哪些数据类型\n\n\n\n\n\n\n\n\n可搭配MySQL 常用函数&amp;数据类型 食用。\n整数类型包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。长度：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。例子，假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。\n实数类型包括FLOAT、DOUBLE、DECIMAL。DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。\n字符串类型包括VARCHAR、CHAR、TEXT、BLOBVARCHAR用于存储可变长字符串，它比定长类型更节省空间。VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。VARCHAR存储的内容超出设置的长度时，内容会被截断。CHAR是定长的，根据定义的字符串长度分配足够的空间。CHAR会根据需要使用空格进行填充方便比较。CHAR适合存储很短的字符串，或者所有值都接近同一个长度。CHAR存储的内容超出设置的长度时，内容同样会被截断。使用策略：对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。尽量避免使用TEXT&#x2F;BLOB类型，查询时会使用临时表，导致严重的性能开销。\n枚举类型（ENUM）把不重复的数据存储为一个预定义的集合。有时可以使用ENUM代替常用的字符串类型。ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。ENUM在内部存储时，其实存的是整数。尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。排序是按照内部存储的整数\n日期和时间类型尽量使用timestamp，空间效率高于datetime，用整数保存时间戳通常不方便处理。如果需要存储微妙，可以使用bigint存储。\n7.16.创建索引的三种方式，删除索引创建索引第一种方式：在执行CREATE TABLE时创建索引\nCREATE TABLE user_index2 (\n  id INT auto_increment PRIMARY KEY,\n  first_name VARCHAR (16),\n  last_name VARCHAR (16),\n  id_card VARCHAR (18),\n  information text,\n  KEY name (first_name, last_name),\n  FULLTEXT KEY (information),\n  UNIQUE KEY (id_card)\n);\n第二种方式：使用ALTER TABLE命令去增加索引\nALTER TABLE table_name ADD INDEX index_name (column_list);\n\n\n\n\n\n\n\n\n\nALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。\n第三种方式：使用CREATE INDEX命令创建\nCREATE INDEX index_name ON table_name (column_list);\nCREATE INDEX可对表增加普通索引或UNIQUE索引。（但是，不能创建PRIMARY KEY索引）\n删除索引根据索引名删除普通索引、唯一索引、全文索引： alter table 表名 drop KEY 索引名\nalter table user_index drop KEY name;\nalter table user_index drop KEY id_card;\nalter table user_index drop KEY information;\n删除主键索引： alter table 表名 drop primary key （因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）：\n[SQLjalter table user index drop primary key\n[Err] 1075 Incorrect table definition; there can be only one auto column and it must be defined as a key\n需要取消自增长再行删除：\nalter table user_index\n-- 重新定义字段\nMODIFY id int,\ndrop PRIMARY KEY\n但通常不会删除主键，因为设计主键一定与业务逻辑无关。\n八、Redis篇8.1.Redis持久化机制Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。实现：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。RDB：Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）AOF：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。\n8.2.缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。解决方案：大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开。\n缓存穿透缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。解决方案：最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。\n缓存预热缓存预热这个应该是一个比较常见的概念，就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决方案：\n\n直接写个缓存刷新页面，上线时手工操作下；\n数据量不大，可以在项目启动的时候自动进行加载；\n定时刷新缓存；\n\n缓存更新除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：\n\n定时去清理过期的缓存；\n当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。\n\n两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。\n缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。以参考日志级别设置预案：\n\n一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；\n警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；\n错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；\n严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。\n\n服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。\n8.3.热点数据和冷数据是什么所谓热点数据就是经常被大量访问的数据所谓冷数据就是频繁被修改的数据或者访问次数少之又少的数据\n\n\n\n\n\n\n\n\n\n经常被访问的数据可以直接进行缓存，这样做可以避免高并发情况下大量请求访问数据库，造成数据库压力瞬间增大，只有数据在更新前至少被读取两次的才进行缓存，对于频繁被更改并且频繁被访问的数据也可以进行缓存，减少数据库的压力（点赞数、分享数、收藏数）。\n8.4.Memcache与Redis的区别都有哪些？\n存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据\n数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储\n使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。\nvalue 值大小不同：Redis 最大可以达到 1gb；memcache 只有 1mb。\nredis的速度比memcached快很多\nRedis支持数据的备份，即master-slave模式的数据备份\n\n8.5.单线程的redis为什么这么快\n纯内存操作\n单线程操作，避免了频繁的上下文切换\n采用了非阻塞I&#x2F;O多路复用机制\n\n8.6.redis的数据类型，以及每种数据类型的使用场景回答：一共五种\n\nString这个其实没啥好说的，最常规的set&#x2F;get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存\nhash这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。\nlist使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。\nset因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。\nsorted setsorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。\n\n8.7.redis的过期策略以及内存淘汰机制redis采用的是定期删除+惰性删除策略。为什么不用定时删除策略?定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.定期删除+惰性删除是如何工作的呢?定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置\nmaxmemory-policy volatile-lru\n该配置就是配内存淘汰策略的volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰no-enviction（驱逐）：禁止驱逐数据，新写入操作会报错\n\n\n\n\n\n\n\n\n\n如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。\n8.8.Redis 为什么是单线程的官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）Redis利用队列技术将并发访问变为串行访问。\n8.9.Redis 常见性能问题和解决方案？\nMaster 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件\n如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次\n为了主从复制的速度和连接的稳定性， Master 和 Slave 最好在同一个局域网内\n尽量避免在压力很大的主库上增加从库\n主从复制不要用图状结构，用单向链表结构更为稳定，即： Master &lt;- Slave1 &lt;- Slave2 &lt;-Slave3…\n\n8.10.为什么Redis的操作是原子性的，怎么保证原子性的？对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。Redis的操作之所以是原子性的，是因为Redis是单线程的。Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。\n\n\n\n\n\n\n\n\n\n多个命令在并发中也是原子性的吗？不一定， 将get和set改成单命令操作，incr 。使用Redis的事务，或者使用Redis+Lua&#x3D;&#x3D;的方式实现.\n8.11.Redis事务Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的\n\nMULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。\nEXEC：执行事务中的所有操作命令。\nDISCARD：取消事务，放弃执行事务块中的所有命令。\nWATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。\nUNWATCH：取消WATCH对所有key的监视。\n\n九、SpringCloud篇9.1.什么是SpringCloud？Spring cloud 流应用程序启动器是基于 Spring Boot 的 Spring 集成应用程序，提供与外部系统的集成。Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。\n9.2.什么是微服务微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小的服务，每个服务运行在其独立的自己的进程中，服务之间相互协调、互相配合，为用户提供最终价值。服务之间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）,每个服务都围绕着具体的业务进行构建，并且能够被独立的构建在生产环境、类生产环境等。另外，应避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。\n9.3.SpringCloud有什么优势使用 Spring Boot 开发分布式微服务时，我们面临以下问题\n\n与分布式系统相关的复杂性-这种开销包括网络问题，延迟开销，带宽问题，安全问题。\n服务发现-服务发现工具管理群集中的流程和服务如何查找和互相交谈。它涉及一个服务目录，在该目录中注册服务，然后能够查找并连接到该目录中的服务。\n冗余-分布式系统中的冗余问题。\n负载平衡 –负载平衡改善跨多个计算资源的工作负荷，诸如计算机，计算机集群，网络链路，中央处理单元，或磁盘驱动器的分布。\n性能-问题 由于各种运营开销导致的性能问题。\n部署复杂性-Devops 技能的要求。\n\n9.4.什么是服务熔断？什么是服务降级？熔断机制是应对雪崩效应的一种微服务链路保护机制。当某个微服务不可用或者响应时间太长时，会进行服务降级，进而熔断该节点微服务的调用，快速返回“错误”的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现，Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内调用20次，如果失败，就会启动熔断机制。服务降级，一般是从整体负荷考虑。就是当某个服务熔断之后，服务器将不再被调用，此时客户端可以自己准备一个本地的fallback回调，返回一个缺省值。这样做，好歹可用，比直接挂掉强。\n\n\n\n\n\n\n\n\n\nHystrix相关注解@EnableHystrix：开启熔断@HystrixCommand(fallbackMethod&#x3D;”XXX”)：声明一个失败回滚处理函数XXX，当被注解的方法执行超时（默认是1000毫秒），就会执行fallback函数，返回错误提示。\n9.5.ureka和zookeeper都可以提供服务注册与发现的功能，有何区别？Zookeeper保证了CP（C：一致性，P：分区容错性），Eureka保证了AP（A：高可用）\n\n当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的信息，但不能容忍直接down掉不可用。也就是说，服务注册功能对高可用性要求比较高，但zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新选leader。问题在于，选取leader时间过长，30 ~ 120s，且选取期间zk集群都不可用，这样就会导致选取期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够恢复，但是漫长的选取时间导致的注册长期不可用是不能容忍的。\nEureka保证了可用性，Eureka各个节点是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点仍然可以提供注册和查询服务。而Eureka的客户端向某个Eureka注册或发现时发生连接失败，则会自动切换到其他节点，只要有一台Eureka还在，就能保证注册服务可用，只是查到的信息可能不是最新的。除此之外，Eureka还有自我保护机制，如果在15分钟内超过85%的节点没有正常的心跳，那么Eureka就认为客户端与注册中心发生了网络故障，此时会出现以下几种情况：\nEureka不在从注册列表中移除因为长时间没有收到心跳而应该过期的服务。\nEureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上（即保证当前节点仍然可用）\n当网络稳定时，当前实例新的注册信息会被同步到其他节点。\n\n\n\n因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像Zookeeper那样使整个微服务瘫痪。\n9.6.SpringBoot和SpringCloud的区别？SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系.SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。\n9.7.负载平衡的意义什么？负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。\n9.8.什么是Hystrix？它如何实现容错？Hystrix是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。通常对于使用微服务架构开发的系统，涉及到许多微服务。这些微服务彼此协作。\n9.9.什么是Hystrix断路器？我们需要它吗？断路器&amp;&amp;hystrix简介断路器代理了服务调用方对提供方的请求。监控最近请求的失败和超时次数，在下游服务因为过载或者故障无法提供响应时，断路器中请求失败率会大大提升，超过一定阈值后，断路器会打开，切断服务调用方和提供方的联系，此时调用者会执行失败逻辑或者直接返回异常。同时断路器还有检测恢复机制，允许服务调用者尝试调用服务提供者以检测它是否恢复正常，若恢复正常则关闭断路器，恢复正常调用。断路器的三态关闭状态：程序正常运行时，大多数都处于此状态，服务调用者正常访问服务提供者。断路器会统计周期时间内的请求总次数和失败数的比例。打开状态：最近失败频率超过了预设的阈值以后，断路器进入打开状态，服务调用者对服务提供者的调用失效，服务调用进入失败逻辑或者返回异常。半开状态：断路器在进入打开状态时候会启动一个超时定时器，在定时器到达时，它会进入到半开状态，此时执行“恢复检测机制”，即调用者尝试对服务提供者发起少量调用请求。如果这些请求都成功执行，那么断路器就认为服务提供者已恢复正常，断路器则关闭，失败计数器复位。如果这些请求失败，断路器返回到打开状态，并重新启动超时定时器，重新进行检测恢复。hystrixhystrix是一个延迟和容错的库。作用于隔离三方系统，服务，第三方库之间的调用，防止级联故障。并且在分布式系统中实现故障出现后的复原能力。git地址：hystrix\nhystrix执行流程\n9.10.说说 RPC 的实现原理RPC（Remote Procedure Call）：远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的思想。RPC 是一种技术思想而非一种规范或协议，常见 RPC 技术和框架有：\n\n应用级的服务框架：阿里的 Dubbo&#x2F;Dubbox、Google gRPC、Spring Boot&#x2F;Spring Cloud。\n远程通信协议：RMI、Socket、SOAP(HTTP XML)、REST(HTTP JSON)。\n通信框架：MINA 和 Netty。\n\n目前流行的开源 RPC 框架还是比较多的，有阿里巴巴的 Dubbo、Facebook 的 Thrift、Google 的 gRPC、Twitter 的 Finagle 等。下面重点介绍三种：\n\ngRPC：是 Google 公布的开源软件，基于最新的 HTTP 2.0 协议，并支持常见的众多编程语言。RPC 框架是基于 HTTP 协议实现的，底层使用到了 Netty 框架的支持。\nThrift：是 Facebook 的开源 RPC 框架，主要是一个跨语言的服务开发框架。 用户只要在其之上进行二次开发就行，应用对于底层的 RPC 通讯等都是透明的。不过这个对于用户来说需要学习特定领域语言这个特性，还是有一定成本的。\nDubbo：是阿里集团开源的一个极为出名的 RPC 框架，在很多互联网公司和企业应用中广泛使用。协议和序列化框架都可以插拔是极其鲜明的特色。\n\n完整的 RPC 框架在一个典型 RPC 的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中“RPC 协议”就指明了程序如何进行网络传输和序列化。\n十、Nginx篇10.1.简述一下什么是Nginx，它有什么优势和功能？Nginx是一个web服务器和方向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议。因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。\n\n\n\n\n\n\n\n\n\nNginx—Ngine X，是一款免费的、自由的、开源的、高性能HTTP服务器和反向代理服务器；也是一个IMAP、POP3、SMTP代理服务器；Nginx以其高性能、稳定性、丰富的功能、简单的配置和低资源消耗而闻名。也就是说Nginx本身就可以托管网站（类似于Tomcat一样），进行Http服务处理，也可以作为反向代理服务器 、负载均衡器和HTTP缓存。Nginx 解决了服务器的C10K（就是在一秒之内连接客户端的数目为10k即1万）问题。它的设计不像传统的服务器那样使用线程处理请求，而是一个更加高级的机制—事件驱动机制，是一种异步事件驱动结构。\n优点：\n\n更快\n\n\n\n\n\n\n\n\n这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的响应；另一方面，在高峰期（如有数以万计的并发请求），Nginx可以比其他Web服务器更快地响应请求。\n\n高扩展性，跨平台\n\n\n\n\n\n\n\n\nNginx的设计极具扩展性，它完全是由多个不同功能、不同层次、不同类型且耦合度极低的模块组成。因此，当对某一个模块修复Bug或进行升级时，可以专注于模块自身，无须在意其他。而且在HTTP模块中，还设计了HTTP过滤器模块：一个正常的HTTP模块在处理完请求后，会有一串HTTP过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的HTTP模块时，不但可以使用诸如HTTP核心模块、events模块、log模块等不同层次或者不同类型的模块，还可以原封不动地复用大量已有的HTTP过滤器模块。这种低耦合度的优秀设计，造就了Nginx庞大的第三方模块，当然，公开的第三方模块也如官方发布的模块一样容易使用。Nginx的模块都是嵌入到二进制文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模块一样具备极其优秀的性能，充分利用Nginx的高并发特性，因此，许多高流量的网站都倾向于开发符合自己业务特性的定制模块。\n\n高可靠性：用于反向代理，宕机的概率微乎其微\n\n\n\n\n\n\n\n\n高可靠性是我们选择Nginx的最基本条件，因为Nginx的可靠性是大家有目共睹的，很多家高流量网站都在核心服务器上大规模使用Nginx。Nginx的高可靠性来自于其核心框架代码的优秀设计、模块设计的简单性；另外，官方提供的常用模块都非常稳定，每个worker进程相对独立，master进程在1个worker进程出错时可以快速“拉起”新的worker子进程提供服务。\n\n低内存消耗\n\n\n\n\n\n\n\n\n一般情况下，10000个非活跃的HTTP Keep-Alive连接在Nginx中仅消耗2.5MB的内存，这是Nginx支持高并发连接的基础。\n\n单机支持10万以上的并发连接\n\n\n\n\n\n\n\n\n这是一个非常重要的特性！随着互联网的迅猛发展和互联网用户数量的成倍增长，各大公司、网站都需要应付海量并发请求，一个能够在峰值期顶住10万以上并发请求的Server，无疑会得到大家的青睐。理论上，Nginx支持的并发连接上限取决于内存，10万远未封顶。当然，能够及时地处理更多的并发请求，是与业务特点紧密相关的。\n\n热部署\n\n\n\n\n\n\n\n\nmaster管理进程与worker工作进程的分离设计，使得Nginx能够提供热部署功能，即可以在7×24小时不间断服务的前提下，升级Nginx的可执行文件。当然，它也支持不停止服务就更新配置项、更换日志文件等功能。\n\n最自由的BSD许可协议\n\n\n\n\n\n\n\n\n这是Nginx可以快速发展的强大动力。BSD许可协议不只是允许用户免费使用Nginx，它还允许用户在自己的项目中直接使用或修改Nginx源码，然后发布。这吸引了无数开发者继续为Nginx贡献自己的智慧。\n\n\n以上7个特点当然不是Nginx的全部，拥有无数个官方功能模块、第三方功能模块使得Nginx能够满足绝大部分应用场景，这些功能模块间可以叠加以实现更加强大、复杂的功能，有些模块还支持Nginx与Perl、Lua等脚本语言集成工作，大大提高了开发效率。这些特点促使用户在寻找一个Web服务器时更多考虑Nginx。选择Nginx的核心理由还是它能在支持高并发请求的同时保持高效的服务。\n10.2.Nginx是如何处理一个HTTP请求的呢？Nginx 是一个高性能的 Web 服务器，能够同时处理大量的并发请求。它结合多进程机制和异步机制 ，异步机制使用的是异步非阻塞方式：\n\n多进程机制\n\n服务器每当收到一个客户端时，就有服务器主进程（ master process ）生成一个子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断 开，该子进程就结束了。使用进程的好处是各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。缺点是操作系统生成一个子进程需要进行内存复制等操作，在资源和时间上会产生一定的开销。当有大量请求时，会导致系统性能下降 。\n\n异步非阻塞机制\n\n每个工作进程使用异步非阻塞方式 ，可以处理多个客户端请求 。当某个工作进程接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去处理其他请求 （即为非阻塞 ）；而客户端在此期间也无需等待响应 ，可以去处理其他事情（即为异步）。当 IO 返回时，就会通知此工作进程 ；该进程得到通知，暂时挂起当前处理的事务去响应客户端请求。\n10.3.列举一些Nginx的特性\n反向代理&#x2F;L7负载均衡器\n嵌入式Perl解释器\n动态二进制升级\n可用于重新编写URL，具有非常好的PCRE支持\n\n10.4.请列举Nginx和Apache 之间的不同点\n\n\n序号\nNginx\nApache\n\n\n\n1\nNginx基于Web服务器\nApache基于流程服务器\n\n\n2\nNginx所有请求都由一个线程来处理\nApache单线程处理单个请求\n\n\n3\nNginx避免子进程的概念\nApache基于子进程\n\n\n4\nNginx类似于速度\nApache类似于功率\n\n\n5\nNginx在内存消耗和连接方面有优势\nApache在内存消耗和连接方面有待提高\n\n\n6\nNginx在负载均衡方面表现较好\nApache当流量达到进程极限时，Apache将拒绝新的连接\n\n\n7\nNginx性能和可伸缩性不依赖于硬件\nApache依赖于CPU和内存等硬件\n\n\n10.5.在Nginx中，如何使用未定义的服务器名称来阻止处理请求？只需将请求删除的服务器就可以定义为：\nServer&#123;\n  listen 80;\n  server_name \"\";\n  return 444;\n&#125;\n\n\n\n\n\n\n\n\n\n服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接。\n10.6.请解释Nginx服务器上的Master和Worker进程分别是什么?当启动nginx以后，使用ps命令查看nginx进程， 会发现nginx进程不只有一个，默认情况下， 你会看到至少两个nginx进程，如下\n[root@VM-8-6-centos ~]# ps -ef|grep nginx\nroot     2634220 2634143  0 Jan11 ?        00:00:00 nginx: master process /opt/gitlab/embedded/sbin/nginx -p /var/opt/gitlab/nginx\nnobody   2634318 2634220  0 Jan11 ?        00:00:16 nginx: worker process\nMaster进程：master进程负责管理worker进程，并负责读取配置文件和判断文件语法的工作；是主进程，有且只有一个。Worker进程：worker进程有多个，它负责处理请求；worker的进程数量由管理员自己定义；编译安装nginx后，默认情况下worker进程是以”nobody”用户的身份运行的，如果我们想要指定worker进程的运行用户，则可以使用”user”指令。\n10.7.解释Nginx用途Nginx服务器的最佳用法是在网络上部署动态HTTP内容，使用SCGI、WSGI应用程序服务器、用于脚本的FastCGI处理程序。它还可以作为负载均衡器。\n十一、Zookeeper篇11.1.ZooKeeper 是什么？ZooKeeper 是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。分布式应用程序可以基于 Zookeeper 实现诸如数据发布&#x2F;订阅、负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和分布式队列等功能。Zookeeper 保证了如下分布式一致性特性：\n\n顺序一致性\n原子性\n单一视图\n可靠性\n实时性（最终一致性）\n\n客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的 zookeeper 机器来处理。对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为 zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper 最新的 zxid。\n11.2.ZooKeeper 提供了什么？\n文件系统\n通知机制\n\n11.3.Zookeeper 文件系统Zookeeper 提供一个多层级的节点命名空间（节点称为 znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为1M。\n11.4.ZAB 协议？ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。ZAB 协议包括两种基本的模式：崩溃恢复和消息广播。当整个 zookeeper 集群刚刚启动或者 Leader 服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有进程（服务器）进入崩溃恢复模式，首先选举产生新的 Leader服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步，当集群中超过半数机器与该 Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。\n11.5.四种类型的数据节点 ZnodePERSISTENT-持久节点：除非手动删除，否则节点一直存在于 Zookeeper 上EPHEMERAL-临时节点：临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。PERSISTENT_SEQUENTIAL-持久顺序节点：基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。EPHEMERAL_SEQUENTIAL-临时顺序节点：基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。\n11.6. Zookeeper Watcher 机制 – 数据变更通知Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据Watcher 通知状态和事件类型做出业务上的改变。工作机制：客户端注册 watcher -&gt; 服务端处理 watcher -&gt; 客户端回调 watcherWatcher 特性总结：\n\n一次性，无论是服务端还是客户端，一旦一个 Watcher 被 触 发 ，Zookeeper 都会将其从相应的存储中移除。这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是服务端的压力都非常大。\n客户端串行执行，客户端 Watcher 回调的过程是一个串行同步的过程。\n轻量，Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。客户端向服务端注册 Watcher 的时候，并不会把客户端真实的 Watcher 对象实体传递到服务端，仅仅是在客户端请求中使用 boolean 类型属性进行了标记。\n只能保证最终的一致性，而无法保证强一致性，watcher event 异步发送 watcher 的通知事件从 server 发送到 client 是异步的，这就存在一个问题，不同的客户端和服务器之间通过 socket 进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper 本身提供了 ordering guarantee，即客户端监听事件后，才会感知它所监视 znode发生了变化。所以我们使用 Zookeeper 不能期望能够监控到节点每次的变化。\n注册 watcher getData、exists、getChildren\n触发 watcher create、delete、setData\n当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到 watch 的。而当 client 重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch 可能会丢失：对于一个未创建的 znode的 exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个 watch 事件可能会被丢失。\n\n11.7.客户端注册 Watcher 实现\n调用 getData()&#x2F;getChildren()&#x2F;exist()三个 API，传入 Watcher 对象\n标记请求 request，封装 Watcher 到 WatchRegistration\n封装成 Packet 对象，发服务端发送 request\n收到服务端响应后，将 Watcher 注册到 ZKWatcherManager 中进行管理\n请求返回，完成注册。\n\n11.8.服务端处理 Watcher 实现\n服务端接收 Watcher 并存储\n\n\n\n\n\n\n\n\n接收到客户端请求，处理请求判断是否需要注册 Watcher，需要的话将数据节点的节点路径和ServerCnxn（ServerCnxn 代表一个客户端和服务端的连接，实现了 Watcher 的 process 接口，此时可以看成一个 Watcher 对象）存储在WatcherManager 的 WatchTable 和 watch2Paths 中去。\n\nWatcher 触发\n\n\n\n\n\n\n\n\n以服务端接收到 setData() 事务请求触发 NodeDataChanged 事件为例：     1. 封装 WatchedEvent：将通知状态（SyncConnected）、事件类型（NodeDataChanged）以及节点路径封装成一个WatchedEvent 对象     2. 查询 Watcher：从 WatchTable 中根据节点路径查找 Watcher     3. 没找到：说明没有客户端在该数据节点上注册过 Watcher     4. 找到：提取并从 WatchTable 和 Watch2Paths 中删除对应 Watcher（从这里可以看出 Watcher 在服务端是一次性的，触发一次就失效了）\n\n调用 process 方法来触发 Watcher\n\n\n\n\n\n\n\n\n这里 process 主要就是通过 ServerCnxn 对应的 TCP 连接发送 Watcher 事件通知。\n\n\n11.9.客户端回调 Watcher客户端 SendThread 线程接收事件通知，交由 EventThread 线程回调 Watcher。客户端的 Watcher 机制同样是一次性的，一旦被触发后，该 Watcher 就失效了。\n11.10.ACL 权限控制机制\n\n\n\n\n\n\n\n\nUGO（User&#x2F;Group&#x2F;Others）目前在 Linux&#x2F;Unix 文件系统中使用，也是使用最广泛的权限控制方式。是一种粗粒度的文件系统权限控制模式。\nACL（Access Control List）访问控制列表包括三个方面：\n\n权限模式（Scheme）\n\n\n\n\n\n\n\n\n\n\nIP：从 IP 地址粒度进行权限控制\nDigest：最常用，用类似于 username:password 的权限标识来进行权限配置，便于区分不同应用来进行权限控制\nWorld：最开放的权限控制方式，是一种特殊的 digest 模式，只有一个权限标识“world:anyone”\nSuper：超级用户\n\n\n授权对象\n\n\n\n\n\n\n\n\n\n授权对象指的是权限赋予的用户或一个指定实体，例如 IP 地址或是机器灯。\n\n权限 Permission\n\n\n\n\n\n\n\n\n\n\nCREATE：数据节点创建权限，允许授权对象在该 Znode 下创建子节\nDELETE：子节点删除权限，允许授权对象删除该数据节点的子节点\nREAD：数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表等\nWRITE：数据节点更新权限，允许授权对象对该数据节点进行更新操作\nADMIN：数据节点管理权限，允许授权对象对该数据节点进行 ACL 相关设置操作\n\n\n\n11.11.Chroot 特性3.2.0 版本后，添加了 Chroot 特性，该特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了 Chroot，那么该客户端对服务器的任何操作，都将会被限制在其自己的命名空间下。通过设置 Chroot，能够将一个客户端应用于 Zookeeper 服务端的一颗子树相对应，在那些多个应用公用一个 Zookeeper 进群的场景下，对实现不同应用间的相互隔离非常有帮助。\n11.12.会话管理分桶策略：将类似的会话放在同一区块中进行管理，以便于 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。分配原则：每个会话的“下次超时时间点”（ExpirationTime）计算公式：\nExpirationTime_ &#x3D; currentTime + sessionTimeout\nExpirationTime &#x3D; (ExpirationTime_ &#x2F; ExpirationInrerval + 1) *\nExpirationInterval , ExpirationInterval 是指 Zookeeper 会话超时检查时间间隔，默认 tickTime\n11.13.服务器角色\nLeader\n\n\n\n\n\n\n\n\n\n事务请求的唯一调度和处理者，保证集群事务处理的顺序性\n集群内部各服务的调度者\n\n\nFollower\n\n\n\n\n\n\n\n\n\n处理客户端的非事务请求，转发事务请求给 Leader 服务器\n参与事务请求 Proposal 的投票\n参与 Leader 选举投票\n\n\nObserver\n\n\n\n\n\n\n\n\n\n3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力\n处理客户端的非事务请求，转发事务请求给 Leader 服务器\n不参与任何形式的投票\n\n\n\n11.14.Zookeeper 下 Server 工作状态服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING。\n\nLOOKING：寻找 Leader 状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。\nFOLLOWING：跟随者状态。表明当前服务器角色是 Follower。\nLEADING：领导者状态。表明当前服务器角色是 Leader。\nOBSERVING：观察者状态。表明当前服务器角色是 Observer\n\n11.15.Zookeeper 是如何保证事务的顺序一致性的？zookeeper 采用了全局递增的事务 Id 来标识，所有的 proposal（提议）都在被提出的时候加上了zxid，zxid 实际上是一个 64 位的数字，高 32 位是 epoch（ 时期; 纪元; 世; 新时代）用来标识 leader周期，如果有新的 leader 产生出来，epoch会自增，低 32 位用来递增计数。当新产生 proposal 的时候，会依据数据库的两阶段过程，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。\n11.16.分布式集群中为什么会有 Master？在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader 选举。\n11.17.Zookeeper 节点宕机如何处理？Zookeeper 本身也是集群，推荐配置不少于 3 个服务器。Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务。如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader。ZK 集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在 ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。\n11.18.Zookeeper 负载均衡和 Nginx 负载均衡区别？zk 的负载均衡是可以调控，nginx 只是能调权重，其他需要可控的都需要自己写插件；但是 nginx 的吞吐量比 zk 大很多，应该说按业务选择用哪种方式。\n11.19.Zookeeper 有哪几种几种部署模式？单机模式、伪集群模式、集群模式\n11.20.集群最少要几台机器，集群规则是怎样的?集群规则为 2N+1 台，N&gt;0，即 3 台。\n11.21.集群支持动态添加机器吗？其实就是水平扩容了，Zookeeper 在这方面不太好。两种方式：全部重启：关闭所有 Zookeeper 服务，修改配置之后启动。不影响之前客户端的会话。逐个重启：在过半存活即可用的原则下，一台机器重启不影响整个集群对外提供服务。这是比较常用的方式。3.5 版本开始支持动态扩容。\n11.22.Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?不是。官方声明：一个 Watch 事件是一个一次性的触发器，当被设置了 Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了 Watch 的客户端，以便通知它们。为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，给网络和服务器造成很大压力。一般是客户端执行 getData(“&#x2F;节点 A”,true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch事件，但是在之后节点 A 又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送。在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，只要最新的数据即可。\n11.23.Zookeeper 的 java 客户端都有哪些？java 客户端：zk 自带的 zkclient 及 Apache 开源的 Curator。\n11.24.chubby 是什么，和 zookeeper 比你怎么看？chubby 是 google 的，完全实现 paxos 算法，不开源。zookeeper 是 chubby的开源实现，使用 zab协议，paxos 算法的变种。\n11.25.说几个 zookeeper 常用的命令。常用命令：ls get set create delete 等\n11.26.Zookeeper 的典型应用场景Zookeeper 是一个典型的发布&#x2F;订阅模式的分布式数据管理与协调框架，开发人员可以使用它来进行分布式数据的发布和订阅。通过对 Zookeeper 中丰富的数据节点进行交叉使用，配合 Watcher 事件通知机制，可以非常方便的构建一系列分布式应用中年都会涉及的核心功能，如：\n\n数据发布&#x2F;订阅\n负载均衡\n命名服务\n分布式协调&#x2F;通知\n集群管理\nMaster 选举\n分布式锁\n分布式队列\n\n十二、Kafka篇12.1.如何获取 topic 主题的列表bin/kafka-topics.sh --list --zookeeper localhost:2181\n12.2.生产者和消费者的命令行是什么？生产者在主题上发布消息：\nbin/kafka-console-producer.sh --broker-list 192.168.1.2:9092 --topicHello-Kafka\n注意这里的 IP 是 server.properties 中的 listeners 的配置。接下来每个新行就是输入一条新消息。消费者接受消息：\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topicHello-Kafka --from-beginning\n12.3.consumer 是推还是拉？Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从broker 拉取消息。\n12.4.讲一下主从同步Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topci配置副本的数量。Kafka会自动在每个副本上备份数据，所以当一个节点down掉时数据依然是可用的。Kafka的副本功能不是必须的，你可以配置只有一个副本，这样其实就相当于只有一份数据。\n12.5.为什么需要消息系统，mysql 不能满足需求吗？\n解耦\n\n\n\n\n\n\n\n\n\n允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。\n\n冗余\n\n\n\n\n\n\n\n\n\n消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。\n\n扩展性\n\n\n\n\n\n\n\n\n\n因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。\n\n灵活性 &amp; 峰值处理能力\n\n\n\n\n\n\n\n\n\n在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。\n\n可恢复性\n\n\n\n\n\n\n\n\n\n系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。\n\n顺序保证\n\n\n\n\n\n\n\n\n\n在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）\n\n缓冲\n\n\n\n\n\n\n\n\n\n有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。\n\n异步通信\n\n\n\n\n\n\n\n\n\n很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。\n\n\n12.6.Zookeeper 对于 Kafka 的作用是什么？Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用。Zookeeper 主要用于在集群中不同节点之间进行通信在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取除此之外，它还执行其他活动，如: leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。\n12.7.Kafka数据传输的事务定义有哪些？和 MQTT 的事务定义一样都是 3 种：\n\n最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输\n最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.\n精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输一次而且仅仅被传输一次，这是大家所期望的\n\n12.8.Kafka 判断一个节点是否还活着有那两个条件？\n节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接\n如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久\n\n12.9.Kafka 与传统 MQ 消息系统之间有三个关键区别\nKafka 持久化日志，这些日志可以被重复读取和无限期保留\nKafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性\nKafka 支持实时的流式处理\n\n12.10.讲一讲 kafka 的 ack 的三种机制request.required.acks 有三个值 0 1 -1(all)0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据。1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader挂掉后他不确保是否复制完成新 leader 也会导致数据丢失。-1(all) ：服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的ack，这样数据不会丢失\n12.11.消费者如何不自动提交偏移量，由应用提交？将 auto.commit.offset 设为 false，然后在处理一批消息后 commitSync() 或者异步提交commitAsync()\nConsumerRecords&lt;> records = consumer.poll();\nfor (ConsumerRecord&lt;> record : records)&#123;\n    ...\n    tyr&#123;\n        consumer.commitSync()\n    &#125;\n    ...\n\n12.12.如何控制消费的位置kafka 使用 seek(TopicPartition, long)指定新的消费位置。用于查找服务器保留的最早和最新的 offset的特殊的方法也可用（seekToBeginning(Collection) 和seekToEnd(Collection)）\n12.13.kafka 分布式（不是单机）的情况下，如何保证消息的顺序消费?Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织，所以可以保证 FIFO的顺序。不同 partition 之间不能保证顺序。但是绝大多数用户都可以通过 message key 来定义，因为同一个 key 的 message 可以保证只发送到同一个 partition。Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同 1个 partition，就是有序的。并且在消费端，Kafka 保证，1 个 partition 只能被1 个 consumer 消费。或者你指定 key（ 比如 order id），具有同 1 个 key的所有消息，会发往同 1 个 partition。\n12.14.kafka 的高可用机制是什么？这个问题比较系统，回答出 kafka 的系统特点，leader 和 follower 的关系，消息读写的顺序即可\n12.15.kafka 如何不消费重复数据？为什么会出现重复消费？\nkafka是通过offset来标记消费的。默认情况下，消费完成后会自动提交offset，避免重复消费。Kafka消费端的自动提交逻辑有一个默认的5秒间隔，也就是说在5秒之后的下一次向Broker拉取消息的时候提交。所以在Consumer消费的过程中，应用程序被强制kill掉或者宕机，可能会导致Offset没提交，从而产生重复提交的问题。\nKafka里面有一个Partition Balance机制，就是把多个Partition均衡的分配给多个消费者。Consumer端会从分配的Partition里面去消费消息，如果Consumer在默认的5分钟内没办法处理完这一批消息。就会触发Kafka的Rebalance机制，从而导致Offset自动提交失败。而在重新Rebalance之后，Consumer还是会从之前没提交的Offset位置开始消费，也会导致消息重复消费的问题。\n\n如何避免\n提高消费端的处理性能避免触发Balance，比如可以用异步的方式来处理消息，缩短单个消息消费的市场。或者还可以调整消息处理的超时时间。还可以减少一次性从Broker上拉取数据的条数。\n可以针对消息生成md5然后保存到mysql或者redis里面，在处理消息之前先去mysql或者redis里面判断是否已经消费过。这个方案其实就是利用幂等性的思想。\n\n十三、MQ篇13.1.为什么使用MQ核心：解耦、异步、削峰\n\n\n\n\n\n\n\n\n\n解耦：A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果C 系统现在不需要了呢？A 系统负责人几乎崩溃…A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦。异步：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 +200 &#x3D; 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求。如果使用MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 &#x3D; 8ms。削峰：减少高峰时期对服务器压力。\n13.2.MQ优缺点优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：\n\n系统可用性降低\n\n系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩溃，你不就完了？\n\n系统复杂度提高\n\n硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？问题一大堆。\n\n一致性问题\n\nA 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。\n13.3.Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别？\n\n\n特性\nActiveMQ\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n单机吞吐量\n万级，比 RocketMQ、Kafka 低一个数量级\n同 ActiveMQ\n10 万级，支撑高吞吐\n10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\n\n\ntopic 数量对吞吐量的影响\n\n\ntopic 可以达到几百&#x2F;几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic\ntopic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n\n\n时效性\nms 级\n微秒级，这是 RabbitMQ 的一大特点，延迟最低\nms 级\n延迟在 ms 级以内\n\n\n可用性\n高，基于主从架构实现高可用\n同 ActiveMQ\n非常高，分布式架构\n非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n\n\n消息可靠性\n有较低的概率丢失数据\n基本不丢\n经过参数优化配置，可以做到 0 丢失\n同 RocketMQ\n\n\n功能支持\nMQ 领域的功能极其完备\n基于 erlang 开发，并发能力很强，性能极好，延时很低\nMQ 功能较为完善，还是分布式的，扩展性好\n功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n\n\n\n\n\n\n\n\n\n\n对于吞吐量来说kafka和RocketMQ支撑高吞吐，ActiveMQ和RabbitMQ比他们低一个数量级。对于延迟量来说RabbitMQ是最低的。RabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上， RabbitMq 胜于 Kafka （理论上）。另外，Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以如果业务方面还是建议选择RabbitMq 。还有就是，Kafka 的性能（吞吐量、TPS ）比RabbitMq 要高出来很多。\n","slug":"浪浪山打工人/浪浪山打工人旅游指南（一）Java 面试题【汇总篇】","date":"2023-01-16T13:58:28.000Z","categories_index":"浪浪山打工人","tags_index":"JAVA,Java基础,Java面试题,2023汇总篇","author_index":"Anchor"},{"id":"b778d1ad8e59c9ee0ece8d1989b81254","title":"SpringBoot集成TrueLicense实现授权管理","content":"前言之前做低代码平台，为了保护平台知识产权，需要对低代码平台增加授权管理功能。功能已经实现好久了，最近梳理总结。所谓授权（License）就是对软件使用时间及使用范围进行管控，初步想法是校验部署机器特征码并添加时间范围校验，调研许久发现TrueLicense方案比较成熟，SO 安排~\n一、公钥、私钥及证书在互联网通信中，为了保证信息传输的安全，通常使用对称秘钥、非对称秘钥以及密码散列函数的方式对通信信息进行加密以及通信身份进行验证。对称秘钥即通信双方使用相同的秘钥对通信内容进行加密，这种方式应该是比较老旧的通信加密方式，通信安全程度较低。现在使用的较多的应该是非对称加密，每个人有自己的私钥，然后拥有授权的公钥。每人可以利用自己的私钥对要发送的信息进行加密，然后接受者通过发送者的公钥对信息进行解密。可以类比信箱，拥有公钥的人，可以向 信箱投送信件，拥有私钥的人可以打开信箱，读取信件。在这种通信方式中，可能存在C偷偷将B持有的A公钥换成自己的公钥，而B不知道自己拥有的A的公钥已经被替换，那么C就可以冒充A给B发送信息，而B相信此信息来自A。为了解决这个问题，需要对B持有的A的公钥进行认证，从而确定此公钥确实是A的公钥，而不是被别人篡改过的。而认证机构必须是第三方可信赖的机构，就是CA，由此发送过程就变成如下：\n\nA发给B数据的时候，除了要发送签名和数据实体，还要发送CA颁发的证书。\nB接收到A发送过来的数据后，首先用CA的公钥区解密证书，如果能解，表明这个证书里的信息可信赖，从而得到证书里A的公钥，然后B再用到后的公钥去做下一步动作。\n\n综上，我们就有实现思路了：在Truelicense中，license将和公钥一起发送给被授权者，在程序中，使用公钥对license进行解密，并校验其许可信息。\n二、使用Java自带的KeyTool生成公私钥库\n\n\n\n\n\n\n\n\nKeytool 是一个Java 数据证书的管理工具 ,Keytool 将密钥（key）和证书（certificates）存在一个称为keystore的文件中 在keystore里，包含两种数据：密钥条目（Key entity）——密钥（secret key）又或者是私钥和配对公钥（采用非对称加密）可信任的证书实体（trusted certificate entries）——只包含公钥\n1、生成秘钥库anchor@Alihaiwu > ~/Downloads/KeyTool> keytool -genkey -alias privatekeys -keysize 1024 -keystore privateKeys.store -validity 3650 # -alias别名 –validity 3650表示10年有效\n输入密钥库口令:  #密码，注意使用字母+数字，否则后期校验会抛异常\n再次输入新口令: \n您的名字与姓氏是什么?\n  [Unknown]:  Anchor\n您的组织单位名称是什么?\n  [Unknown]:  Alihai5\n您的组织名称是什么?\n  [Unknown]:  阿里孩舞\n您所在的城市或区域名称是什么?\n  [Unknown]:  beijing\n您所在的省/市/自治区名称是什么?\n  [Unknown]:  beijing\n该单位的双字母国家/地区代码是什么?\n  [Unknown]:  cn\nCN=Anchor, OU=Alihai5, O=阿里孩舞, L=beijing, ST=beijing, C=cn是否正确?\n  [否]:  y\n\n输入 &lt;privatekeys> 的密钥口令\n        (如果和密钥库口令相同, 按回车):  #密码，注意使用字母+数字，否则后期校验会抛异常\n再次输入新口令: \n\nWarning:\nJKS 密钥库使用专用格式,建议使用 \"keytool -importkeystore -srckeystore privateKeys.store -destkeystore privateKeys.store -deststoretype pkcs12\" 迁移到行业标准格式 PKCS12\n2、导出证书及私钥# 然后将密钥库中名称为privatekeys的证书条目导出到证书文件certfile.cer中\nkeytool -export -alias privatekeys -file certfile.cer -keystore privateKeys.store\n输入密钥库口令:  #输入第一步创建秘钥库时使用的密码\n存储在文件 &lt;certfile.cer> 中的证书\n\nWarning:\nJKS 密钥库使用专用格式,建议使用 \"keytool -importkeystore -srckeystore privateKeys.store -destkeystore privateKeys.store -deststoretype pkcs12\" 迁移到行业标准格式 PKCS12\n3、导出公钥anchor@Alihaiwu > ~/Downloads/KeyTool> keytool -import -alias publicCerts -file certfile.cer -keystore publicCerts.store\n输入密钥库口令:  #输入秘钥密码\n再次输入新口令: \n所有者: CN=Anchor, OU=Alihai5, O=阿里孩舞, L=beijing, ST=beijing, C=cn\n发布者: CN=Anchor, OU=Alihai5, O=阿里孩舞, L=beijing, ST=beijing, C=cn\n序列号: 731c7b1b\n有效期为 Wed Jan 04 13:08:18 CST 2023 至 Sat Jan 01 13:08:18 CST 2033\n证书指纹:\n         MD5:  E2:7E:AE:07:6C:74:50:CD:08:BF:68:74:79:84:27:66\n         SHA1: C9:52:ED:A6:A2:97:FC:4A:23:97:0B:C2:85:42:D3:3A:60:E5:D5:83\n         SHA256: 88:A7:0C:5E:78:1B:B1:3E:7B:6F:F9:93:99:FE:24:5F:4F:21:C7:8D:FB:2D:49:F2:FB:92:F6:2A:B4:80:C9:3D\n签名算法名称: SHA256withDSA\n主体公共密钥算法: 1024 位 DSA 密钥\n版本: 3\n\n扩展: \n\n#1: ObjectId: 2.5.29.14 Criticality=false\nSubjectKeyIdentifier [\nKeyIdentifier [\n0000: 57 25 93 29 B5 7D 87 0B   BA F8 B3 A4 CE 25 51 82  W%.).........%Q.\n0010: 58 BD 29 C4                                        X.).\n]\n]\n\n是否信任此证书? [否]:  y\n证书已添加到密钥库中\n按以上步骤执行完成后，会在当前目录下生成3个文件：\nanchor@Alihaiwu > ~/Downloads/KeyTool> ll\ntotal 24\n-rw-r--r--  1 anchor  staff   827B Jan  4 13:14 certfile.cer #此为临时文件可以删除\n-rw-r--r--  1 anchor  staff   1.3K Jan  4 13:08 privateKeys.store #此为私钥，用于生成License文件\n-rw-r--r--  1 anchor  staff   895B Jan  4 13:16 publicCerts.store #此为公钥，用于解密License文件并校验其许可信息\n三、TrueLicenseTrueLicense是一个开源的证书管理引擎，使用trueLicense来做软件产品的保护，基于TrueLicense实现产品License验证功能,给产品加上License验证功能，进行试用期授权，在试用期过后，产品不再可用。其实现原理：\n\n生成秘钥对，使用Keytool生成公私钥证书库。\n授权者保留私钥，使用私钥对包含授权信息（如使用截止日期，MAC地址等）的license进行数字签名。\n公钥给使用者（放在验证的代码中使用），用于验证license是否符合使用条件。\n\n四、SpringBoot集成TrueLicense实现先上整体代码结构，因为使用场景是为低代码开发平台增加授权，所以整个授权逻辑为平台中的一个模块，此处仅介绍授权模块的实现，了解原理后可自行扩展集成入其他框架中：\n\nlicense-boot-start 模块为授权验证模块，兼具授权文件生成接口功能，内部使用\nlicense-core 模块为授权校验核心处理模块\nlicense-creator 模块为授权License生成模块\nlicense-verify 模块为授权校验模块\n\n在此之前先在项目中引入TrueLicense包：\n&lt;!-- truelicense的依赖配置-->\n&lt;dependency>\n    &lt;groupId>de.schlichtherle.truelicense&lt;/groupId>\n    &lt;artifactId>truelicense-core&lt;/artifactId>\n    &lt;version>1.33&lt;/version>\n&lt;/dependency>\n1、license-core还是先上代码结构，由于creator与verify模块license生成与校验逻辑一致，所以抽取出来作为core模块使用，注释比较详细，直接看代码：\nconfig\nLicenseCoreAutoConfigure\n/**\n* @program: groot-license\n* @description:自动装填配置类\n* @author: Anchor\n* @create: 2021-09-01\n**/\n@Configuration\n    @ComponentScan(basePackages = &#123;\"com.alihai5.license.core\"&#125;)\n    public class LicenseCoreAutoConfigure &#123;\n\n    &#125;\n\n\ncontroller\nHardWareInfoController\n/**\n * @program: groot-license\n * @description: 服务器硬件信息获取\n * @author: Anchor\n * @create: 2021-09-01\n **/\n@CrossOrigin\n@RestController\n@RequestMapping(\"/license\")\npublic class HardWareInfoController &#123;\n\n    @RequestMapping(value = \"/getServerInfos\")\n    public AjaxResult getServerInfos(@RequestParam(value = \"osName\",required = false) String osName) throws LicenseContentException &#123;\n        return AjaxResult.success(AServerInfos.getServer(osName).getServerInfos());\n    &#125;\n&#125;\n\n\nhelper\nParamInitHelper\n/**\n * @Description\n * GxParamInitHelper\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class ParamInitHelper &#123;\n\n    /** 证书的发行者和主体字段信息 */\n    private final static X500Principal DEFAULT_HOLDER_AND_ISSUER = new X500Principal(\"CN=a, OU=a, O=a, L=a, ST=a, C=a\");\n\n    /**\n     * &lt;p>初始化证书生成参数&lt;/p>\n     * @param param GxLicenseCreatorParam 生成证书参数\n     * @return LicenseParam 证书参数\n     */\n    public static LicenseParam initLicenseParam(LicenseCreatorParam param)&#123;\n        Preferences preferences = Preferences.userNodeForPackage(LicenseCreator.class);\n        /** 设置对证书内容加密的秘钥 */\n        CipherParam cipherParam = new DefaultCipherParam(param.getStorePass());\n        KeyStoreParam privateStoreParam = new DefaultKeyStoreParam(LicenseCreator.class\n                ,param.getPrivateKeysStorePath()\n                ,param.getPrivateAlias()\n                ,param.getStorePass()\n                ,param.getKeyPass());\n        return new DefaultLicenseParam(param.getSubject(),preferences,privateStoreParam,cipherParam);\n    &#125;\n\n    /**\n     * &lt;p>初始化证书内容信息对象&lt;/p>\n     * @param param GxLicenseCreatorParam 生成证书参数\n     * @return LicenseContent 证书内容\n     */\n    public static LicenseContent initLicenseContent(LicenseCreatorParam param)&#123;\n        LicenseContent licenseContent = new LicenseContent();\n        licenseContent.setHolder(DEFAULT_HOLDER_AND_ISSUER);\n        licenseContent.setIssuer(DEFAULT_HOLDER_AND_ISSUER);\n        /** 设置证书名称 */\n        licenseContent.setSubject(param.getSubject());\n        /** 设置证书有效期 */\n        licenseContent.setIssued(param.getIssuedTime());\n        /** 设置证书生效日期 */\n        licenseContent.setNotBefore(param.getIssuedTime());\n        /** 设置证书失效日期 */\n        licenseContent.setNotAfter(param.getExpiryTime());\n        /** 设置证书用户类型 */\n        licenseContent.setConsumerType(param.getConsumerType());\n        /** 设置证书用户数量 */\n        licenseContent.setConsumerAmount(param.getConsumerAmount());\n        /** 设置证书描述信息 */\n        licenseContent.setInfo(param.getDescription());\n        /** 设置证书扩展信息（对象 -- 额外的ip、mac、cpu等信息） */\n        licenseContent.setExtra(param.getLicenseCheck());\n        return licenseContent;\n    &#125;\n\n    /**\n     * &lt;p>初始化证书生成参数&lt;/p>\n     * @param param License校验类需要的参数\n     */\n    public static LicenseParam initLicenseParam(LicenseVerifyParam param)&#123;\n        Preferences preferences = Preferences.userNodeForPackage(LicenseVerifyManager.class);\n        CipherParam cipherParam = new DefaultCipherParam(param.getStorePass());\n        KeyStoreParam publicStoreParam = new DefaultKeyStoreParam(LicenseVerifyManager.class\n                /** 公钥库存储路径 */\n                ,param.getPublicKeysStorePath()\n                /** 公匙别名 */\n                ,param.getPublicAlias()\n                /** 公钥库访问密码 */\n                ,param.getStorePass()\n                ,null);\n        return new DefaultLicenseParam(param.getSubject(),preferences,publicStoreParam,cipherParam);\n    &#125;\n&#125;\n\n\nmodel\nLicenseCreatorManager\n/**\n * @Description\n * 系统软件证书生成管理器\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseCreatorManager &#123;\n\n    private static final Logger log = LoggerFactory.getLogger(LicenseCreatorManager.class);\n\n    private LicenseCreatorParam param;\n\n    public LicenseCreatorManager(LicenseCreatorParam param) &#123;\n        this.param = param;\n    &#125;\n\n    /**\n     * &lt;p>生成License证书&lt;/p>\n     * @return GxLicenseResult 证书生成结果\n     */\n    public LicenseResult generateLicense()&#123;\n        try &#123;\n            // 1、根据外部传入的创建Lic的参数信息初始化lic参数（秘钥部分）\n            LicenseParam licenseParam = ParamInitHelper.initLicenseParam(param);\n            // 2、根据外部传入的创建Lic的属性信息初始化lic内容（除了truelicense自带的还包括自己定义的）\n            LicenseContent licenseContent = ParamInitHelper.initLicenseContent(param);\n            // 3、构建Lic管理器\n            LicenseManager licenseManager = new LicenseCustomManager(licenseParam);\n            // 4、根据param传入的lic生成的路径创建空文件\n            File licenseFile = new File(this.param.getLicensePath());\n            // 5、通过Lic管理器，将内容写入Lic文件中\n            licenseManager.store(licenseContent, licenseFile);\n            return new LicenseResult(\"证书生成成功！\",licenseContent);\n        &#125;catch (Exception e)&#123;\n            log.error(e.getMessage());\n            String message = MessageFormat.format(\"证书生成失败！：&#123;0&#125;\", param);\n            log.error(message,e);\n            return new LicenseResult(message,e);\n        &#125;\n    &#125;\n\n    /**\n     * &lt;p>下载License证书&lt;/p>\n     * @return InputStream 证书文件输入流\n     * @throws Exception 证书下载失败\n     */\n    public InputStream download() throws Exception &#123;\n        try &#123;\n            LicenseParam licenseParam = ParamInitHelper.initLicenseParam(param);\n            LicenseContent licenseContent = ParamInitHelper.initLicenseContent(param);\n            LicenseManager licenseManager = new LicenseCustomManager(licenseParam);\n            File licenseFile = new File(param.getLicensePath());\n            licenseManager.store(licenseContent,licenseFile);\n            return new FileInputStream(licenseFile);\n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n            log.error(e.getMessage());\n            log.error(MessageFormat.format(\"证书下载失败：&#123;0&#125;\",param),e);\n            throw new UtilException(\"证书下载失败\",e);\n        &#125;\n    &#125;\n\n&#125;\n\n\n\nLicenseCreatorParam\n/**\n * @Description\n * License创建（生成）需要的参数\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseCreatorParam implements Serializable &#123;\n\n    private static final long serialVersionUID = -7793154252684580872L;\n\n    /**证书主题*/\n    private String subject;\n\n    /**私钥别名*/\n    private String privateAlias;\n\n    /**私钥密码（需要妥善保管，不能让使用者知道*/\n    private String keyPass;\n\n    /**私钥库存储路径*/\n    private String privateKeysStorePath;\n\n    /**访问私钥库的密码*/\n    private String storePass;\n\n    /**证书生成路径*/\n    private String licensePath;\n\n    /** 证书生效时间*/\n    @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\")\n    private Date issuedTime = new Date();\n\n    /** 证书失效时间*/\n    @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\")\n    private Date expiryTime;\n\n    /**用户类型*/\n    private String consumerType = \"user\";\n\n    /**用户数量*/\n    private Integer consumerAmount = 1;\n\n    /**描述信息*/\n    private String description = \"\";\n\n    /**额外的服务器硬件校验信息*/\n    private LicenseExtraParam licenseCheck;\n\n    /**证书下载地址 == 一旦证书create成功，这个值就会填充上*/\n    private String licUrl;\n\n    public LicenseCreatorParam()&#123;\n\n    &#125;\n\n    public static long getSerialVersionUID() &#123;\n        return serialVersionUID;\n    &#125;\n\n    public String getSubject() &#123;\n        return subject;\n    &#125;\n\n    public void setSubject(String subject) &#123;\n        this.subject = subject;\n    &#125;\n\n    public String getPrivateAlias() &#123;\n        return privateAlias;\n    &#125;\n\n    public void setPrivateAlias(String privateAlias) &#123;\n        this.privateAlias = privateAlias;\n    &#125;\n\n    public String getKeyPass() &#123;\n        return keyPass;\n    &#125;\n\n    public void setKeyPass(String keyPass) &#123;\n        this.keyPass = keyPass;\n    &#125;\n\n    public String getStorePass() &#123;\n        return storePass;\n    &#125;\n\n    public void setStorePass(String storePass) &#123;\n        this.storePass = storePass;\n    &#125;\n\n    public String getLicensePath() &#123;\n        return licensePath;\n    &#125;\n\n    public void setLicensePath(String licensePath) &#123;\n        this.licensePath = licensePath;\n    &#125;\n\n    public String getPrivateKeysStorePath() &#123;\n        return privateKeysStorePath;\n    &#125;\n\n    public void setPrivateKeysStorePath(String privateKeysStorePath) &#123;\n        this.privateKeysStorePath = privateKeysStorePath;\n    &#125;\n\n    public Date getIssuedTime() &#123;\n        return issuedTime;\n    &#125;\n\n    public void setIssuedTime(Date issuedTime) &#123;\n        this.issuedTime = issuedTime;\n    &#125;\n\n    public Date getExpiryTime() &#123;\n        return expiryTime;\n    &#125;\n\n    public void setExpiryTime(Date expiryTime) &#123;\n        this.expiryTime = expiryTime;\n    &#125;\n\n    public String getConsumerType() &#123;\n        return consumerType;\n    &#125;\n\n    public void setConsumerType(String consumerType) &#123;\n        this.consumerType = consumerType;\n    &#125;\n\n    public Integer getConsumerAmount() &#123;\n        return consumerAmount;\n    &#125;\n\n    public void setConsumerAmount(Integer consumerAmount) &#123;\n        this.consumerAmount = consumerAmount;\n    &#125;\n\n    public String getDescription() &#123;\n        return description;\n    &#125;\n\n    public void setDescription(String description) &#123;\n        this.description = description;\n    &#125;\n\n    public LicenseExtraParam getLicenseCheck() &#123;\n        return licenseCheck;\n    &#125;\n\n    public void setLicenseCheck(LicenseExtraParam licenseCheck) &#123;\n        this.licenseCheck = licenseCheck;\n    &#125;\n\n    public String getLicUrl() &#123;\n        return licUrl;\n    &#125;\n\n    public void setLicUrl(String licUrl) &#123;\n        this.licUrl = licUrl;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"LicenseCreatorParam&#123;\" +\n                \"subject='\" + subject + '\\'' +\n                \", privateAlias='\" + privateAlias + '\\'' +\n                \", keyPass='\" + keyPass + '\\'' +\n                \", privateKeysStorePath='\" + privateKeysStorePath + '\\'' +\n                \", storePass='\" + storePass + '\\'' +\n                \", licensePath='\" + licensePath + '\\'' +\n                \", issuedTime=\" + issuedTime +\n                \", expiryTime=\" + expiryTime +\n                \", consumerType='\" + consumerType + '\\'' +\n                \", consumerAmount=\" + consumerAmount +\n                \", description='\" + description + '\\'' +\n                \", licenseCheck=\" + licenseCheck +\n                \", licUrl='\" + licUrl + '\\'' +\n                '&#125;';\n    &#125;\n&#125;\n\n\n\nLicenseCustomManager\n/**\n * @Description\n * 自定义LicenseManager，用于增加额外的服务器硬件信息校验\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseCustomManager extends LicenseManager &#123;\n\n    private static final Logger log = LoggerFactory.getLogger(LicenseCustomManager.class);\n\n    /** XML编码 */\n    private static final String XML_CHARSET = \"UTF-8\";\n    /** 默认BUFF_SIZE */\n    private static final int DEFAULT_BUFF_SIZE = 8 * 1024;\n\n    public LicenseCustomManager() &#123;\n    &#125;\n\n    public LicenseCustomManager(LicenseParam param) &#123;\n        super(param);\n    &#125;\n\n    /**\n     * &lt;p>重写LicenseManager的create方法&lt;/p>\n     * @param content LicenseContent 证书信息\n     * @param notary notary 公正信息\n     * @return byte[]\n     * @throws Exception 默认异常\n     */\n    @Override\n    protected synchronized byte[] create(LicenseContent content, LicenseNotary notary) throws Exception &#123;\n        initialize(content);\n        /** 加入自己额外的许可内容信息认证 == 主要友情提示 */\n        this.validateCreate(content);\n        final GenericCertificate certificate = notary.sign(content);\n        return getPrivacyGuard().cert2key(certificate);\n    &#125;\n\n\n    /**\n     * &lt;p>重写install方法&lt;/p>\n     * @param key 密匙\n     * @param notary 公正信息\n     * @return LicenseContent 证书信息\n     * @throws Exception 默认异常\n     */\n    @Override\n    protected synchronized LicenseContent install(final byte[] key, final LicenseNotary notary) throws Exception &#123;\n        final GenericCertificate certificate = getPrivacyGuard().key2cert(key);\n        notary.verify(certificate);\n        final LicenseContent licenseContent = (LicenseContent)this.load(certificate.getEncoded());\n        /** 增加额外的自己的license校验方法，校验ip、mac、cpu序列号等 */\n        this.validate(licenseContent);\n        setLicenseKey(key);\n        setCertificate(certificate);\n        return licenseContent;\n    &#125;\n\n    /**\n     * &lt;p>重写verify方法&lt;/p>\n     * @param notary 公正信息\n     * @return LicenseContent 证书信息\n     * @throws Exception 默认异常\n     */\n    @Override\n    protected synchronized LicenseContent verify(final LicenseNotary notary) throws Exception &#123;\n        final byte[] key = getLicenseKey();\n        if (null == key)&#123;\n            throw new NoLicenseInstalledException(getLicenseParam().getSubject());\n        &#125;\n        GenericCertificate certificate = getPrivacyGuard().key2cert(key);\n        notary.verify(certificate);\n        final LicenseContent content = (LicenseContent)this.load(certificate.getEncoded());\n        /** 增加额外的自己的license校验方法，校验ip、mac、cpu序列号等 */\n        this.validate(content);\n        setCertificate(certificate);\n        return content;\n    &#125;\n\n    /**\n     * &lt;p>校验生成证书的参数信息&lt;/p>\n     * @param content LicenseContent 证书内容\n     * @throws LicenseContentException 证书内容错误异常\n     */\n    protected synchronized void validateCreate(final LicenseContent content) throws LicenseContentException &#123;\n\n        // 当前时间\n        final Date now = new Date();\n        // 生效时间\n        final Date notBefore = content.getNotBefore();\n        // 失效时间\n        final Date notAfter = content.getNotAfter();\n\n        if (null != notAfter &amp;&amp; now.after(notAfter))&#123;\n            String message = \"证书失效时间不能早于当前时间\";\n            log.error(message);\n            throw new LicenseContentException(message);\n        &#125;\n        if (null != notBefore &amp;&amp; null != notAfter &amp;&amp; notAfter.before(notBefore))&#123;\n            String message = \"证书生效时间不能晚于证书失效时间\";\n            log.error(message);\n            throw new LicenseContentException(message);\n        &#125;\n        final String consumerType = content.getConsumerType();\n        if (null == consumerType)&#123;\n            String message = \"用户类型不能为空\";\n            log.error(message);\n            throw new LicenseContentException(message);\n        &#125;\n\n    &#125;\n\n    /**\n     * &lt;p>重写validate方法，增加ip地址、mac地址、cpu序列号等其他信息的校验&lt;/p>\n     * @param content LicenseContent 证书内容\n     */\n    @Override\n    protected synchronized void validate(final LicenseContent content) throws LicenseContentException &#123;\n        // 当前时间\n        final Date now = new Date();\n        final Date notAfter = content.getNotAfter();\n        if(now.after(notAfter))&#123;\n            throw new LicenseContentException(\"系统证书过期，当前时间已超过证书有效期 -- \"+\n                    DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,notAfter));\n        &#125;\n        //1、 首先调用父类的validate方法\n        super.validate(content);\n        //2、 然后校验自定义的License参数 License中可被允许的参数信息\n        LicenseExtraParam expectedCheck = (LicenseExtraParam) content.getExtra();\n        //当前服务器真实的参数信息\n        LicenseExtraParam serverCheckModel = AServerInfos.getServer(null).getServerInfos();\n        if(expectedCheck != null &amp;&amp; serverCheckModel != null)&#123;\n            //校验IP地址\n            if(expectedCheck.isIpCheck() &amp;&amp; !checkIpAddress(expectedCheck.getIpAddress(),serverCheckModel.getIpAddress()))&#123;\n                String message = \"系统证书无效，当前服务器的IP没在授权范围内\";\n                log.error(message);\n                throw new LicenseContentException(message);\n            &#125;\n            //校验Mac地址\n            if(expectedCheck.isMacCheck() &amp;&amp; !checkIpAddress(expectedCheck.getMacAddress(),serverCheckModel.getMacAddress()))&#123;\n                String message = \"系统证书无效，当前服务器的Mac地址没在授权范围内\";\n                log.error(message);\n                throw new LicenseContentException(message);\n            &#125;\n            //校验主板序列号\n            if(expectedCheck.isBoardCheck() &amp;&amp; !checkSerial(expectedCheck.getMainBoardSerial(),serverCheckModel.getMainBoardSerial()))&#123;\n                String message = \"系统证书无效，当前服务器的主板序列号没在授权范围内\";\n                log.error(message);\n                throw new LicenseContentException(message);\n            &#125;\n            //校验CPU序列号\n            if(expectedCheck.isCpuCheck() &amp;&amp; !checkSerial(expectedCheck.getCpuSerial(),serverCheckModel.getCpuSerial()))&#123;\n                String message = \"系统证书无效，当前服务器的CPU序列号没在授权范围内\";\n                log.error(message);\n                throw new LicenseContentException(message);\n            &#125;\n        &#125;else&#123;\n            throw new LicenseContentException(\"不能获取服务器硬件信息\");\n        &#125;\n    &#125;\n\n    /**\n     * &lt;p>重写XMLDecoder解析XML&lt;/p>\n     */\n    private Object load(String encoded)&#123;\n        BufferedInputStream inputStream = null;\n        XMLDecoder decoder = null;\n        try &#123;\n            inputStream = new BufferedInputStream(new ByteArrayInputStream(encoded.getBytes(XML_CHARSET)));\n            decoder = new XMLDecoder(new BufferedInputStream(inputStream, DEFAULT_BUFF_SIZE),null,null);\n            return decoder.readObject();\n        &#125; catch (UnsupportedEncodingException e) &#123;\n            e.printStackTrace();\n        &#125; finally &#123;\n            try &#123;\n                if(decoder != null)&#123;\n                    decoder.close();\n                &#125;\n                if(inputStream != null)&#123;\n                    inputStream.close();\n                &#125;\n            &#125; catch (Exception e) &#123;\n                log.error(\"XMLDecoder解析XML失败\",e);\n            &#125;\n        &#125;\n        return null;\n\n    &#125;\n\n    /**\n     * &lt;p>\n     *     校验当前服务器的IP/Mac地址是否在可被允许的IP范围内&lt;br/>\n     *     如果存在IP在可被允许的IP/Mac地址范围内，则返回true\n     * &lt;/p>\n     *\n     */\n    private boolean checkIpAddress(List&lt;String> expectedList, List&lt;String> serverList)&#123;\n\n        /** 如果期望的IP列表空直接返回false，因为既然验证ip，这一项必须要有元素 */\n        if(CommonUtils.isEmpty(expectedList))&#123;\n            return false ;\n        &#125;\n        /** 如果当前服务器的IP列表空直接返回false，因为服务器不可能获取不到ip，没有的话验证个锤子 */\n        if(CommonUtils.isEmpty(serverList))&#123;\n            return false ;\n        &#125;\n        for(String expected : expectedList)&#123;\n            if(serverList.contains(expected.trim()))&#123;\n                return true;\n            &#125;\n        &#125;\n        return false;\n\n    &#125;\n\n    /**\n     * &lt;p>校验当前服务器硬件（主板、CPU等）序列号是否在可允许范围内&lt;/p>\n     * @param expectedSerial 主板信息\n     * @param serverSerial 服务器信息\n     * @return boolean\n     */\n    private boolean checkSerial(String expectedSerial, String serverSerial)&#123;\n        if(CommonUtils.isNotEmpty(expectedSerial))&#123;\n            if(CommonUtils.isNotEmpty(serverSerial))&#123;\n                return expectedSerial.equals(serverSerial);\n            &#125;\n            return false;\n        &#125;else&#123;\n            return true;\n        &#125;\n    &#125;\n&#125;\n\n\n\nLicenseExtraParam\n/**\n* @Description\n* 自定义需要校验的License参数\n* @author Anchor\n* @Date 2021/9/1\n*/\npublic class LicenseExtraParam implements Serializable &#123;\n\n    private static final long serialVersionUID = 8600137500316662317L;\n\n    /** 是否认证ip*/\n    private boolean isIpCheck ;\n\n    /** 可被允许的IP地址*/\n    private List&lt;String> ipAddress;\n\n    /**是否认证mac*/\n    private boolean isMacCheck ;\n\n    /** 可被允许的mac地址*/\n    private List&lt;String> macAddress;\n\n    /**是否认证cpu序列号*/\n    private boolean isCpuCheck ;\n\n    /** 可被允许的CPU序列号*/\n    private String cpuSerial;\n\n    /** 是否认证主板号*/\n    private boolean isBoardCheck ;\n\n    /**可被允许的主板序列号*/\n    private String mainBoardSerial;\n\n    /** 是否限制注册人数*/\n    private boolean isRegisterCheck;\n\n    /** 限制系统中可注册的人数*/\n    private Long registerAmount;\n\n    /**其他可自行扩展字段*/\n\n    public LicenseExtraParam()&#123;\n\n    &#125;\n\n    public static long getSerialVersionUID() &#123;\n        return serialVersionUID;\n    &#125;\n\n    public List&lt;String> getIpAddress() &#123;\n        return ipAddress;\n    &#125;\n\n    public void setIpAddress(List&lt;String> ipAddress) &#123;\n        this.ipAddress = ipAddress;\n    &#125;\n\n    public List&lt;String> getMacAddress() &#123;\n        return macAddress;\n    &#125;\n\n    public void setMacAddress(List&lt;String> macAddress) &#123;\n        this.macAddress = macAddress;\n    &#125;\n\n    public String getCpuSerial() &#123;\n        return cpuSerial;\n    &#125;\n\n    public void setCpuSerial(String cpuSerial) &#123;\n        this.cpuSerial = cpuSerial;\n    &#125;\n\n    public String getMainBoardSerial() &#123;\n        return mainBoardSerial;\n    &#125;\n\n    public void setMainBoardSerial(String mainBoardSerial) &#123;\n        this.mainBoardSerial = mainBoardSerial;\n    &#125;\n\n    public boolean isIpCheck() &#123;\n        return isIpCheck;\n    &#125;\n\n    public void setIpCheck(boolean ipCheck) &#123;\n        isIpCheck = ipCheck;\n    &#125;\n\n    public boolean isMacCheck() &#123;\n        return isMacCheck;\n    &#125;\n\n    public void setMacCheck(boolean macCheck) &#123;\n        isMacCheck = macCheck;\n    &#125;\n\n    public boolean isCpuCheck() &#123;\n        return isCpuCheck;\n    &#125;\n\n    public void setCpuCheck(boolean cpuCheck) &#123;\n        isCpuCheck = cpuCheck;\n    &#125;\n\n    public boolean isBoardCheck() &#123;\n        return isBoardCheck;\n    &#125;\n\n    public void setBoardCheck(boolean boardCheck) &#123;\n        isBoardCheck = boardCheck;\n    &#125;\n\n    public Long getRegisterAmount() &#123;\n        return registerAmount;\n    &#125;\n\n    public void setRegisterAmount(Long registerAmount) &#123;\n        this.registerAmount = registerAmount;\n    &#125;\n\n    public boolean isRegisterCheck() &#123;\n        return isRegisterCheck;\n    &#125;\n\n    public void setRegisterCheck(boolean registerCheck) &#123;\n        isRegisterCheck = registerCheck;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"LicenseExtraParam&#123;\" +\n            \"ipAddress=\" + ipAddress +\n            \", macAddress=\" + macAddress +\n            \", cpuSerial='\" + cpuSerial + '\\'' +\n            \", mainBoardSerial='\" + mainBoardSerial + '\\'' +\n            \", registerAmount='\" + registerAmount + '\\'' +\n            '&#125;';\n    &#125;\n&#125;\n\n\n\nLicenseResult\n/**\n * @Description\n * License证书验证结果对象\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseResult &#123;\n\n    /** 检验结果 */\n    private Boolean result;\n    /** 附加信息 */\n    private String message;\n    /** 证书内容 */\n    private LicenseContent content;\n    /** 检验失败错误 */\n    private Exception exception;\n\n    public LicenseResult(LicenseContent content) &#123;\n        this.result = true;\n        this.content = content;\n    &#125;\n\n    public LicenseResult(String message, LicenseContent content) &#123;\n        this.result = true;\n        this.message = message;\n        this.content = content;\n    &#125;\n\n    public LicenseResult(Exception exception) &#123;\n        this.result = false;\n        this.exception = exception;\n    &#125;\n\n    public LicenseResult(String message, Exception exception) &#123;\n        this.result = false;\n        this.message = message;\n        this.exception = exception;\n    &#125;\n\n    public LicenseResult(boolean result , String message, Exception exception) &#123;\n        this.result = result;\n        this.message = message;\n        this.exception = exception;\n    &#125;\n\n    public Boolean getResult() &#123;\n        return result;\n    &#125;\n\n    public void setResult(Boolean result) &#123;\n        this.result = result;\n    &#125;\n\n    public String getMessage() &#123;\n        return message;\n    &#125;\n\n    public void setMessage(String message) &#123;\n        this.message = message;\n    &#125;\n\n    public LicenseContent getContent() &#123;\n        return content;\n    &#125;\n\n    public void setContent(LicenseContent content) &#123;\n        this.content = content;\n    &#125;\n\n    public Exception getException() &#123;\n        return exception;\n    &#125;\n\n    public void setException(Exception exception) &#123;\n        this.exception = exception;\n    &#125;\n&#125;\n\n\n\nLicenseVerifyManager\n/**\n * @Description\n * License校验类\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseVerifyManager &#123;\n\n    private static final Logger log = LoggerFactory.getLogger(LicenseVerifyManager.class);\n\n    /**\n     * &lt;p>安装License证书&lt;/p>\n     * @param param License校验类需要的参数\n     */\n    public synchronized LicenseResult install(LicenseVerifyParam param)&#123;\n        try&#123;\n            /** 1、初始化License证书参数 */\n            LicenseParam licenseParam = ParamInitHelper.initLicenseParam(param);\n            /** 2、创建License证书管理器对象 */\n//          LicenseManager licenseManager =new LicenseManager(licenseParam);\n            //走自定义的Lic管理\n            LicenseCustomManager licenseManager = new LicenseCustomManager(licenseParam);\n            /** 3、获取要安装的证书文件 */\n            File licenseFile = ResourceUtils.getFile(param.getLicensePath());\n            /** 4、如果之前安装过证书，先卸载之前的证书 == 给null */\n            licenseManager.uninstall();\n            /** 5、开始安装 */\n            LicenseContent content = licenseManager.install(licenseFile);\n            String message = MessageFormat.format(\"证书安装成功，证书有效期：&#123;0&#125; - &#123;1&#125;\",\n                    DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,content.getNotBefore()),\n                    DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,content.getNotAfter()));\n            log.info(message);\n            return new LicenseResult(message,content);\n        &#125;catch (LicenseContentException contentExc)&#123;\n            String message = contentExc.getMessage();\n            log.error(message);\n            return new LicenseResult(false,message,contentExc);\n        &#125; catch (Exception e)&#123;\n            log.error(e.getMessage(),e);\n            return new LicenseResult(false,e.getMessage(),e);\n        &#125;\n    &#125;\n\n    /**\n     * &lt;p>校验License证书&lt;/p>\n     * @param param License校验类需要的参数\n     */\n    public LicenseResult verify(LicenseVerifyParam param)&#123;\n\n        /** 1、初始化License证书参数 */\n        LicenseParam licenseParam = ParamInitHelper.initLicenseParam(param);\n        /** 2、创建License证书管理器对象 */\n        LicenseManager licenseManager = new LicenseCustomManager(licenseParam);\n        DateFormat format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n\n        /** 3、开始校验证书 */\n        try &#123;\n            LicenseContent licenseContent = licenseManager.verify();\n            String message = MessageFormat.format(\"证书校验通过，证书有效期：&#123;0&#125; - &#123;1&#125;\",\n                    format.format(licenseContent.getNotBefore()),format.format(licenseContent.getNotAfter()));\n            log.info(message);\n            return new LicenseResult(message,licenseContent);\n        &#125;catch (NoLicenseInstalledException ex)&#123;\n            String message = \"证书未安装！\";\n            log.error(message,ex);\n            return new LicenseResult(false,message,ex);\n        &#125;catch (LicenseContentException cex)&#123;\n            log.error(cex.getMessage(),cex);\n            return new LicenseResult(false,cex.getMessage(),cex);\n        &#125; catch (Exception e)&#123;\n            String message = \"证书校验失败！\";\n            log.error(message,e);\n            return new LicenseResult(false,message,e);\n        &#125;\n    &#125;\n\n\n&#125;\n\n\n\nLicenseVerifyParam\n/**\n * @Description\n * License校验类需要的参数\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LicenseVerifyParam &#123;\n\n    /**证书主题*/\n    private String subject;\n\n    /**公钥别名*/\n    private String publicAlias;\n\n    /** 访问公钥库的密码*/\n    private String storePass;\n\n    /**证书生成路径*/\n    private String licensePath;\n\n    /**公钥库存储路径*/\n    private String publicKeysStorePath;\n\n    public LicenseVerifyParam() &#123;\n\n    &#125;\n\n    public LicenseVerifyParam(String subject, String publicAlias, String storePass, String licensePath, String publicKeysStorePath) &#123;\n        this.subject = subject;\n        this.publicAlias = publicAlias;\n        this.storePass = storePass;\n        this.licensePath = licensePath;\n        this.publicKeysStorePath = publicKeysStorePath;\n    &#125;\n\n    public String getSubject() &#123;\n        return subject;\n    &#125;\n\n    public void setSubject(String subject) &#123;\n        this.subject = subject;\n    &#125;\n\n    public String getPublicAlias() &#123;\n        return publicAlias;\n    &#125;\n\n    public void setPublicAlias(String publicAlias) &#123;\n        this.publicAlias = publicAlias;\n    &#125;\n\n    public String getStorePass() &#123;\n        return storePass;\n    &#125;\n\n    public void setStorePass(String storePass) &#123;\n        this.storePass = storePass;\n    &#125;\n\n    public String getLicensePath() &#123;\n        return licensePath;\n    &#125;\n\n    public void setLicensePath(String licensePath) &#123;\n        this.licensePath = licensePath;\n    &#125;\n\n    public String getPublicKeysStorePath() &#123;\n        return publicKeysStorePath;\n    &#125;\n\n    public void setPublicKeysStorePath(String publicKeysStorePath) &#123;\n        this.publicKeysStorePath = publicKeysStorePath;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"LicenseVerifyParam&#123;\" +\n                \"subject='\" + subject + '\\'' +\n                \", publicAlias='\" + publicAlias + '\\'' +\n                \", storePass='\" + storePass + '\\'' +\n                \", licensePath='\" + licensePath + '\\'' +\n                \", publicKeysStorePath='\" + publicKeysStorePath + '\\'' +\n                '&#125;';\n    &#125;\n&#125;\n\n\nservice\nAServerInfos\n/**\n * @Description\n * 服务器硬件信息抽象类 -- 模板方法，将通用的方法抽离到父类中\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic abstract class AServerInfos &#123;\n\n    private static class GxServerInfosContainer &#123;\n        private static List&lt;String> ipAddress = null;\n        private static List&lt;String> macAddress = null;\n        private static String cpuSerial = null;\n        private static String mainBoardSerial = null;\n    &#125;\n\n    /**\n     * @Description\n     * 组装需要额外校验的License参数\n     * @return LicenseExtraParam 自定义校验参数\n     * @author Anchor\n     * @Date 2021/9/1\n    */\n    public LicenseExtraParam getServerInfos() throws LicenseContentException &#123;\n        LicenseExtraParam result = new LicenseExtraParam();\n        try &#123;\n            initServerInfos();\n            result.setIpAddress(GxServerInfosContainer.ipAddress);\n            result.setMacAddress(GxServerInfosContainer.macAddress);\n            result.setCpuSerial(GxServerInfosContainer.cpuSerial);\n            result.setMainBoardSerial(GxServerInfosContainer.mainBoardSerial);\n        &#125; catch (Exception e) &#123;\n            throw new LicenseContentException(\"获取服务器硬件信息失败\");\n        &#125;\n        return result;\n    &#125;\n\n    /**\n     * &lt;p>初始化服务器硬件信息，并将信息缓存到内存&lt;/p>\n     *\n     * @throws Exception 默认异常\n     */\n    private void initServerInfos() throws Exception &#123;\n        if (GxServerInfosContainer.ipAddress == null) &#123;\n            GxServerInfosContainer.ipAddress = this.getIpAddress();\n        &#125;\n        if (GxServerInfosContainer.macAddress == null) &#123;\n            GxServerInfosContainer.macAddress = this.getMacAddress();\n        &#125;\n        if (GxServerInfosContainer.cpuSerial == null) &#123;\n            GxServerInfosContainer.cpuSerial = this.getCPUSerial();\n        &#125;\n        if (GxServerInfosContainer.mainBoardSerial == null) &#123;\n            GxServerInfosContainer.mainBoardSerial = this.getMainBoardSerial();\n        &#125;\n    &#125;\n\n    /**\n     * &lt;p>获取IP地址&lt;/p>\n     *\n     * @return List&lt;String> IP地址\n     * @throws Exception 默认异常\n     */\n    public List&lt;String> getIpAddress() throws Exception &#123;\n        /** 获取所有网络接口 */\n        List&lt;InetAddress> inetAddresses = getLocalAllInetAddress();\n        if (CommonUtils.isNotEmpty(inetAddresses)) &#123;\n            return inetAddresses.stream().map(InetAddress::getHostAddress).distinct().map(String::toLowerCase).collect(Collectors.toList());\n        &#125;\n        return null;\n    &#125;\n\n    /**\n     * &lt;p>获取Mac地址&lt;/p>\n     *\n     * @return List&lt;String> Mac地址\n     * @throws Exception 默认异常\n     */\n    public List&lt;String> getMacAddress() throws Exception &#123;\n        /** 获取所有网络接口 */\n        List&lt;InetAddress> inetAddresses = getLocalAllInetAddress();\n        if (CommonUtils.isNotEmpty(inetAddresses)) &#123;\n            return inetAddresses.stream().map(this::getMacByInetAddress).distinct().collect(Collectors.toList());\n        &#125;\n        return null;\n    &#125;\n\n    /**\n     * &lt;p>获取服务器信息&lt;/p>\n     *\n     * @param osName 系统类型\n     * @return AGxServerInfos 服务信息\n     */\n    public static AServerInfos getServer(String osName) &#123;\n        if (\"\".equals(osName) || osName == null) &#123;\n            osName = System.getProperty(\"os.name\").toLowerCase();\n        &#125;\n        AServerInfos abstractServerInfos;\n        //根据不同操作系统类型选择不同的数据获取方法\n        if (osName.startsWith(OsType.WINDOWS.getCode())) &#123;\n            abstractServerInfos = new WindowsServerInfos();\n        &#125; else if (osName.startsWith(OsType.LINUX.getCode())) &#123;\n            abstractServerInfos = new LinuxServerInfos();\n        &#125; else if (osName.startsWith(OsType.MACOS.getCode()))&#123;\n            abstractServerInfos = new MacintoshServerInfos();\n        &#125; else &#123;//其他服务器类型\n            abstractServerInfos = new LinuxServerInfos();\n        &#125;\n        return abstractServerInfos;\n    &#125;\n\n    /**\n     * &lt;p>获取CPU序列号&lt;/p>\n     *\n     * @return String 主板序列号\n     * @throws Exception 默认异常\n     */\n    protected abstract String getCPUSerial() throws Exception;\n\n    /**\n     * &lt;p>获取主板序列号&lt;/p>\n     *\n     * @return String 主板序列号\n     * @throws Exception 默认异常\n     */\n    protected abstract String getMainBoardSerial() throws Exception;\n\n    /**\n     * &lt;p>获取当前服务器所有符合条件的网络地址&lt;/p>\n     *\n     * @return List&lt;InetAddress> 网络地址列表\n     * @throws Exception 默认异常\n     */\n    private List&lt;InetAddress> getLocalAllInetAddress() throws Exception &#123;\n        List&lt;InetAddress> result = new ArrayList&lt;>(4);\n        // 遍历所有的网络接口\n        for (Enumeration networkInterfaces = NetworkInterface.getNetworkInterfaces(); networkInterfaces.hasMoreElements(); ) &#123;\n            NetworkInterface ni = (NetworkInterface) networkInterfaces.nextElement();\n            // 在所有的接口下再遍历IP\n            for (Enumeration addresses = ni.getInetAddresses(); addresses.hasMoreElements(); ) &#123;\n                InetAddress address = (InetAddress) addresses.nextElement();\n                //排除LoopbackAddress、SiteLocalAddress、LinkLocalAddress、MulticastAddress类型的IP地址\n                if (!address.isLoopbackAddress()\n                        &amp;&amp; !address.isLinkLocalAddress() &amp;&amp; !address.isMulticastAddress()) &#123;\n                    result.add(address);\n                &#125;\n            &#125;\n        &#125;\n        return result;\n    &#125;\n\n    /**\n     * &lt;p>获取服务器临时磁盘位置&lt;/p>\n     */\n    public static String getServerTempPath() &#123;\n        String property = System.getProperty(\"user.dir\");\n        return property;\n    &#125;\n\n    /**\n     * &lt;p>获取某个网络地址对应的Mac地址&lt;/p>\n     *\n     * @param inetAddr 网络地址\n     * @return String Mac地址\n     */\n    private String getMacByInetAddress(InetAddress inetAddr) &#123;\n        try &#123;\n            byte[] mac = NetworkInterface.getByInetAddress(inetAddr).getHardwareAddress();\n            StringBuilder stringBuilder = new StringBuilder();\n            for (int i = 0; i &lt; mac.length; i++) &#123;\n                if (i != 0) &#123;\n                    stringBuilder.append(\"-\");\n                &#125;\n                /** 将十六进制byte转化为字符串 */\n                String temp = Integer.toHexString(mac[i] &amp; 0xff);\n                if (temp.length() == 1) &#123;\n                    stringBuilder.append(\"0\").append(temp);\n                &#125; else &#123;\n                    stringBuilder.append(temp);\n                &#125;\n            &#125;\n            return stringBuilder.toString().toUpperCase();\n        &#125; catch (SocketException e) &#123;\n            e.printStackTrace();\n        &#125;\n        return null;\n    &#125;\n\n&#125;\n\n\n\nLinuxServerInfos\n/**\n * @Description\n * 用于获取客户Linux服务器的基本信息\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class LinuxServerInfos extends AServerInfos &#123;\n\n    private final String[] CPU_SHELL = &#123;\"/bin/bash\",\"-c\",\"dmidecode -t processor | grep 'ID' | awk -F ':' '&#123;print $2&#125;' | head -n 1\"&#125;;\n    private final String[] MAIN_BOARD_SHELL = &#123;\"/bin/bash\",\"-c\",\"dmidecode | grep 'Serial Number' | awk -F ':' '&#123;print $2&#125;' | head -n 1\"&#125;;\n\n    @Override\n    protected String getCPUSerial() throws Exception &#123;\n        String result = \"\";\n        String CPU_ID_CMD = \"dmidecode\";\n        BufferedReader bufferedReader = null;\n        Process p = null;\n        try &#123;\n            p = Runtime.getRuntime().exec(new String[] &#123; \"sh\", \"-c\", CPU_ID_CMD &#125;);\n            bufferedReader = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            String line = null;\n            int index = -1;\n            while ((line = bufferedReader.readLine()) != null) &#123;\n                // 寻找标示字符串[hwaddr]\n                index = line.toLowerCase().indexOf(\"uuid\");\n                if (index >= 0) &#123;\n                    // 取出mac地址并去除2边空格\n                    result = line.substring(index + \"uuid\".length() + 1).trim();\n                    break;\n                &#125;\n            &#125;\n        &#125; catch (IOException e) &#123;\n            throw new LicenseException(\"获取cpu信息错误\", e);\n        &#125;\n        return result.trim();\n    &#125;\n\n    @Override\n    protected String getMainBoardSerial() throws Exception &#123;\n        String result = \"\";\n        String maniBord_cmd = \"dmidecode | grep 'Serial Number' | awk '&#123;print $3&#125;' | tail -1\";\n        Process p;\n        try &#123;\n            p = Runtime.getRuntime().exec(new String[] &#123; \"sh\", \"-c\", maniBord_cmd &#125;);\n            BufferedReader br = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            String line;\n            while ((line = br.readLine()) != null) &#123;\n                result += line;\n                break;\n            &#125;\n            br.close();\n        &#125; catch (IOException e) &#123;\n            throw new LicenseException(\"获取主板信息错误\", e);\n        &#125;\n        return  result;\n    &#125;\n\n\n&#125;\n\n\n\nMacintoshServerInfos\n/**\n * @program: license\n * @description: Macintosh系统信息获取\n * @author: Anchor\n * @create: 2021-08-30\n **/\npublic class MacintoshServerInfos extends AServerInfos &#123;\n\n    private final String SERIAL_SHELL = \"system_profiler SPHardwareDataType | grep Serial | awk '&#123;print $4&#125;'\";\n    private final String UUID_SHELL = \"system_profiler SPHardwareDataType | grep UUID | awk  '&#123;print $3&#125;'\";\n\n    @Override\n    protected String getCPUSerial() throws Exception &#123;\n        String result = \"\";\n        try &#123;\n            // 管道\n            Process p = Runtime.getRuntime().exec(new String[] &#123; \"sh\", \"-c\", SERIAL_SHELL &#125;);\n            BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            result = bufferedReader.readLine();\n        &#125; catch (IOException e) &#123;\n            throw new LicenseException(\"获取cpu信息错误\", e);\n        &#125;\n        return result.trim();\n    &#125;\n\n    @Override\n    protected String getMainBoardSerial() throws Exception &#123;\n        String result = \"\";\n        try &#123;\n            // 管道\n            Process p = Runtime.getRuntime().exec(new String[] &#123; \"sh\", \"-c\", UUID_SHELL &#125;);\n            BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            result = bufferedReader.readLine();\n        &#125; catch (IOException e) &#123;\n            throw new LicenseException(\"获取主板信息错误\", e);\n        &#125;\n        return result.trim();\n    &#125;\n&#125;\n\n\n\nWindowsServerInfos\n/**\n * @Description\n * 用于获取客户Windows服务器的基本信息\n * @author Anchor\n * @Date 2021/9/1\n*/\npublic class WindowsServerInfos extends AServerInfos &#123;\n\n    private final String CPU_COMMAND = \"wmic cpu get processorid\";\n    private final String MAIN_BOARD_COMMAND = \"wmic baseboard get serialnumber\";\n\n    @Override\n    protected String getCPUSerial() throws Exception &#123;\n        String result = \"\";\n        try &#123;\n            File file = File.createTempFile(\"tmp\", \".vbs\");\n            file.deleteOnExit();\n            FileWriter fw = new FileWriter(file);\n            String vbs = \"Set objWMIService = GetObject(\\\"winmgmts:\\\\\\\\.\\\\root\\\\cimv2\\\")\\n\"\n                    + \"Set colItems = objWMIService.ExecQuery _ \\n\" + \"   (\\\"Select * from Win32_Processor\\\") \\n\"\n                    + \"For Each objItem in colItems \\n\" + \"    Wscript.Echo objItem.ProcessorId \\n\"\n                    + \"    exit for  ' do the first cpu only! \\n\" + \"Next \\n\";\n\n            fw.write(vbs);\n            fw.close();\n            Process p = Runtime.getRuntime().exec(\"cscript //NoLogo \" + file.getPath());\n            BufferedReader input = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            String line;\n            while ((line = input.readLine()) != null) &#123;\n                result += line;\n            &#125;\n            input.close();\n            file.delete();\n        &#125; catch (Exception e) &#123;\n            throw new LicenseException(\"获取cpu信息错误\", e);\n        &#125;\n        return result.trim();\n    &#125;\n\n    @Override\n    protected String getMainBoardSerial() throws Exception &#123;\n\n        String result = \"\";\n        try &#123;\n            File file = File.createTempFile(\"realhowto\", \".vbs\");\n            file.deleteOnExit();\n            FileWriter fw = new FileWriter(file);\n\n            String vbs = \"Set objWMIService = GetObject(\\\"winmgmts:\\\\\\\\.\\\\root\\\\cimv2\\\")\\n\"\n                    + \"Set colItems = objWMIService.ExecQuery _ \\n\" + \"   (\\\"Select * from Win32_BaseBoard\\\") \\n\"\n                    + \"For Each objItem in colItems \\n\" + \"    Wscript.Echo objItem.SerialNumber \\n\"\n                    + \"    exit for  ' do the first cpu only! \\n\" + \"Next \\n\";\n\n            fw.write(vbs);\n            fw.close();\n            Process p = Runtime.getRuntime().exec(\"cscript //NoLogo \" + file.getPath());\n            BufferedReader input = new BufferedReader(new InputStreamReader(p.getInputStream()));\n            String line;\n            while ((line = input.readLine()) != null) &#123;\n                result += line;\n            &#125;\n            input.close();\n        &#125; catch (Exception e) &#123;\n            throw new LicenseException(\"获取主板信息错误\", e);\n        &#125;\n        return result.trim();\n    &#125;\n\n\n&#125;\n\n\n2、license-creatorcreator模块主要作用是根据获取到的机器特征信息生成授权license文件，所以模块中会用到第二章生成的私钥文件，整体代码结构如下：\nconfig\nLicenseCreatorAutoConfigure\n/**\n* @Description\n* License生成模块自动扫包/装配Bean实例\n* @author Anchor\n* @Date 2021/9/1\n*/\n@Configuration\n    @ComponentScan(basePackages = &#123;\"com.alihai5.license.creator\"&#125;)\n    @EnableConfigurationProperties(&#123;LicenseCreatorProperties.class&#125;)\n    public class LicenseCreatorAutoConfigure &#123;\n        public LicenseCreatorAutoConfigure()&#123;\n\n        &#125;\n    &#125;\n\n\n\nLicenseCreatorProperties\n/**\n * @Description\n * License生成配置类\n * @author Anchor\n * @Date 2021/9/1\n*/\n@ConfigurationProperties(prefix = \"springboot.license.generate\")\npublic class LicenseCreatorProperties &#123;\n\n    /**证书生成临时存放路径*/\n    private String tempPath;\n\n    public LicenseCreatorProperties() &#123;\n    &#125;\n\n    public String getTempPath() &#123;\n        return tempPath;\n    &#125;\n\n    public void setTempPath(String tempPath) &#123;\n        this.tempPath = tempPath;\n        File file = new File(tempPath);\n        if(!file.exists())&#123;\n            file.mkdirs();\n        &#125;\n    &#125;\n&#125;\n\n\ncontroller\nLicenseCreatorController\n/**\n * @Description\n * 用于生成证书文件\n * @author Anchor\n * @Date 2021/9/1\n*/\n@CrossOrigin\n@RestController\n@RequestMapping(\"/license\")\npublic class LicenseCreatorController &#123;\n\n    @Value(\"$&#123;springboot.license.server.prefix:http://localhost:8080/license/&#125;\")\n    private String licPrefixUrl ;\n\n    @Autowired\n    private LicenseCreatorService creatorService ;\n\n    @Autowired\n    private LicenseCreatorProperties properties;\n\n    /**\n     * &lt;p>生成证书（硬件信息经过加密处理）&lt;/p>\n     * @param param 生成证书需要的参数，如：\n     *\n     */\n    @PostMapping(\"/generateFirst\")\n    public AjaxResult generateFirst(@RequestBody LicenseCreatorParam param,\n                                    @RequestParam String extraParam) throws Exception &#123;\n        // 解密加密后的硬件信息\n        LicenseExtraParam orginExtraParam = JSONObject.parseObject(new String(Base64.decode(extraParam),\n                StandardCharsets.UTF_8), LicenseExtraParam.class);\n        // 将解密后的硬件信息复制给处理对象\n        LicenseExtraParam licenseExtraParam = param.getLicenseCheck();\n        licenseExtraParam.setCpuSerial(orginExtraParam.getCpuSerial());\n        licenseExtraParam.setIpAddress(orginExtraParam.getIpAddress());\n        licenseExtraParam.setMacAddress(orginExtraParam.getMacAddress());\n        licenseExtraParam.setMainBoardSerial(orginExtraParam.getMainBoardSerial());\n\n        // 生成授权证书\n        return generate(param);\n    &#125;\n\n    /**\n     * &lt;p>生成证书&lt;/p>\n     * @param param 生成证书需要的参数，如：\n     *\n     */\n    @PostMapping(\"/generate\")\n    public AjaxResult generate(@RequestBody LicenseCreatorParam param) throws Exception &#123;\n        // 如果没有人为的指定lic要生成的位置，则程序自动处理\n        if(CommonUtils.isEmpty(param.getLicensePath()))&#123;\n            //设置格式\n            SimpleDateFormat format =  new SimpleDateFormat(\"yyyyMMddHHmmss\");\n            String tempPath = properties.getTempPath();\n            if(tempPath == null || \"\".equals(tempPath))&#123;\n                // 如果默认临时文件等于空的话，就获取当前服务执行的路径\n                tempPath = AServerInfos.getServerTempPath();\n            &#125;\n            // 根据时间戳，命名lic文件\n            String licDir = tempPath+\"/license/\"+format.format(System.currentTimeMillis());\n            File file = new File(licDir);\n            if(!file.exists())&#123;\n               if(!file.mkdirs())&#123;\n                   throw new CustomException(\"创建目录\"+licDir+\",失败，请检查是是否有创建目录的权限或者手动进行创建！\");\n               &#125;\n            &#125;\n            param.setLicensePath(licDir + \"/license.lic\");\n        &#125;\n        param.setLicUrl(licPrefixUrl+\"download?path=\"+param.getLicensePath());\n        return creatorService.generateLicense(param);\n    &#125;\n\n    @GetMapping(\"/download\")\n    public void downLoad(@RequestParam(value = \"path\") String path, HttpServletRequest request, HttpServletResponse response) throws Exception&#123;\n        File file = new File(path);\n        if(!file.exists())&#123;\n            response.setStatus(HttpStatus.NOT_FOUND.value());\n            return;\n        &#125;\n        InputStream is = new FileInputStream(file);\n        String fileName = file.getName();\n        // 设置文件ContentType类型，这样设置，会自动判断下载文件类型\n        response.setContentType(\"multipart/form-data\");\n        // 设置编码格式\n        response.setCharacterEncoding(\"UTF-8\");\n        // 设置可以识别Html文件\n        response.setContentType(\"text/html\");\n        // 设置头中附件文件名的编码\n        setAttachmentCoding(request, response, fileName);\n        BufferedInputStream bis = new BufferedInputStream(is);\n        OutputStream os = response.getOutputStream();\n        byte[] buffer = new byte[1024 * 10];\n        int length ;\n        while ((length = bis.read(buffer, 0, buffer.length)) != -1) &#123;\n            os.write(buffer, 0, length);\n        &#125;\n        os.close();\n        bis.close();\n        is.close();\n    &#125;\n\n    private void setAttachmentCoding(HttpServletRequest request, HttpServletResponse response, String fileName) &#123;\n        String browser;\n        try &#123;\n            browser = request.getHeader(\"User-Agent\");\n            if (-1 &lt; browser.indexOf(\"MSIE 6.0\") || -1 &lt; browser.indexOf(\"MSIE 7.0\")) &#123;\n                // IE6, IE7 浏览器\n                response.addHeader(\"content-disposition\", \"attachment;filename=\"\n                        + new String(fileName.getBytes(), \"ISO8859-1\"));\n            &#125; else if (-1 &lt; browser.indexOf(\"MSIE 8.0\")) &#123;\n                // IE8\n                response.addHeader(\"content-disposition\", \"attachment;filename=\"\n                        + URLEncoder.encode(fileName, \"UTF-8\"));\n            &#125; else if (-1 &lt; browser.indexOf(\"MSIE 9.0\")) &#123;\n                // IE9\n                response.addHeader(\"content-disposition\", \"attachment;filename=\"\n                        + URLEncoder.encode(fileName, \"UTF-8\"));\n            &#125; else if (-1 &lt; browser.indexOf(\"Chrome\")) &#123;\n                // 谷歌\n                response.addHeader(\"content-disposition\",\n                        \"attachment;filename*=UTF-8''\" + URLEncoder.encode(fileName, \"UTF-8\"));\n            &#125; else if (-1 &lt; browser.indexOf(\"Safari\")) &#123;\n                // 苹果\n                response.addHeader(\"content-disposition\", \"attachment;filename=\"\n                        + new String(fileName.getBytes(), \"ISO8859-1\"));\n            &#125; else &#123;\n                // 火狐或者其他的浏览器\n                response.addHeader(\"content-disposition\",\n                        \"attachment;filename*=UTF-8''\" + URLEncoder.encode(fileName, \"UTF-8\"));\n            &#125;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n        &#125;\n    &#125;\n\n&#125;\n\n\nservice\nLicenseCreatorService\n/**\n * @Description\n * 证书生成接口实现\n * @author Anchor\n * @Date 2021/9/1\n*/\n@Service\npublic class LicenseCreatorService &#123;\n    /**\n     * &lt;p>生成证书&lt;/p>\n     * @param param 证书创建需要的参数对象\n     * @return Map&lt;String,Object>\n     */\n    public AjaxResult generateLicense(LicenseCreatorParam param) &#123;\n        LicenseCreatorManager licenseCreator = new LicenseCreatorManager(param);\n        LicenseResult licenseResult = licenseCreator.generateLicense();\n        if(licenseResult.getResult())&#123;\n            String message = MessageFormat.format(\"证书生成成功，证书有效期：&#123;0&#125; - &#123;1&#125;\",\n                    DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,param.getIssuedTime()),\n                    DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,param.getExpiryTime()));\n            return AjaxResult.success(message,param);\n        &#125;else&#123;\n            return AjaxResult.error(\"证书文件生成失败！\");\n        &#125;\n    &#125;\n\n\n&#125;\n\n\n3、license-verifyverify模块内嵌于客户端，用于校验授权license是否合法，所以模块中会用到第二章生成的公钥文件，项目启动后执行，如不合法则抛出异常并终止JVM，其结构如下：\nannotion\nVLicense\n/**\n * @Description\n * License自定义注解\n * @author Anchor\n * @Date 2021/9/2\n*/\n@Target(&#123;ElementType.METHOD&#125;)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface VLicense &#123;\n    String[] verifies() default&#123;&#125;;\n&#125;\n\n\nconfig\nLicenseInterceptorConfig\n/**\n * @Description\n * License拦截器配置类\n * @author Anchor\n * @Date 2021/9/2\n*/\n@Configuration\npublic class LicenseInterceptorConfig implements WebMvcConfigurer &#123;\n\n    @Bean\n    public LicenseVerifyInterceptor getLicenseCheckInterceptor() &#123;\n        return new LicenseVerifyInterceptor();\n    &#125;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n        registry.addInterceptor(this.getLicenseCheckInterceptor()).addPathPatterns(\"/**\");\n    &#125;\n&#125;\n\n\n\nLicenseVerifyAutoConfigure\n/**\n * @Description\n * License验证模块自动扫包/装配Bean实例\n * @author Anchor\n * @Date 2021/9/2\n*/\n@Configuration\n@ComponentScan(basePackages = &#123;\"com.alihai5.license.verify\"&#125;)\npublic class LicenseVerifyAutoConfigure &#123;\n\n    public LicenseVerifyAutoConfigure()&#123;\n        \n    &#125;\n&#125;\n\n\n\nLicenseVerifyProperties\n/**\n * @Description\n * License验证属性类\n * @author Anchor\n * @Date 2021/9/2\n*/\n@Component\n@ConfigurationProperties(prefix = \"groot.license.verify\")\npublic class LicenseVerifyProperties &#123;\n\n    private String subject = \"groot\";\n    private String publicAlias = \"publicCerts\";\n    private String publicKeysStorePath = \"/publicCerts.store\";\n    private String storePass = \"groot7758\";\n    private String licensePath;\n\n    public LicenseVerifyProperties() &#123;\n    &#125;\n\n    public String getSubject() &#123;\n        return subject;\n    &#125;\n\n    public void setSubject(String subject) &#123;\n        this.subject = subject;\n    &#125;\n\n    public String getPublicAlias() &#123;\n        return publicAlias;\n    &#125;\n\n    public void setPublicAlias(String publicAlias) &#123;\n        this.publicAlias = publicAlias;\n    &#125;\n\n    public String getPublicKeysStorePath() &#123;\n        return publicKeysStorePath;\n    &#125;\n\n    public void setPublicKeysStorePath(String publicKeysStorePath) &#123;\n        this.publicKeysStorePath = publicKeysStorePath;\n    &#125;\n\n    public String getStorePass() &#123;\n        return storePass;\n    &#125;\n\n    public void setStorePass(String storePass) &#123;\n        this.storePass = storePass;\n    &#125;\n\n    public String getLicensePath() &#123;\n        return licensePath;\n    &#125;\n\n    public void setLicensePath(String licensePath) &#123;\n        this.licensePath = licensePath;\n    &#125;\n\n    public LicenseVerifyParam getVerifyParam() &#123;\n        LicenseVerifyParam param = new LicenseVerifyParam();\n        param.setSubject(subject);\n        param.setPublicAlias(publicAlias);\n        param.setStorePass(storePass);\n        param.setLicensePath(licensePath);\n        param.setPublicKeysStorePath(publicKeysStorePath);\n        return param;\n    &#125;\n&#125;\n\n\ninterceptor\nLicenseVerifyInterceptor\n/**\n * @Description\n * License验证拦截器\n * @author Anchor\n * @Date 2021/9/2\n*/\npublic class LicenseVerifyInterceptor implements HandlerInterceptor &#123;\n\n    @Autowired\n    private LicenseVerifyProperties properties;\n\n    public LicenseVerifyInterceptor() &#123;\n    &#125;\n\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;\n        if (handler instanceof HandlerMethod) &#123;\n            HandlerMethod handlerMethod = (HandlerMethod) handler;\n            Method method = handlerMethod.getMethod();\n            VLicense annotation = method.getAnnotation(VLicense.class);\n            if (CommonUtils.isNotEmpty(annotation)) &#123;\n                LicenseVerifyManager licenseVerifyManager = new LicenseVerifyManager();\n                /** 1、校验证书是否有效 */\n                LicenseResult verifyResult = licenseVerifyManager.verify(properties.getVerifyParam());\n                if(!verifyResult.getResult())&#123;\n                    throw  new LicenseException(verifyResult.getMessage());\n                &#125;\n                LicenseContent content = verifyResult.getContent();\n                LicenseExtraParam licenseCheck = (LicenseExtraParam) content.getExtra();\n                if (verifyResult.getResult()) &#123;\n                    /** 增加业务系统监听，是否自定义验证 */\n                    List&lt;ACustomVerifyListener> customListenerList = ACustomVerifyListener.getCustomListenerList();\n                    boolean compare = true;\n                    for (ACustomVerifyListener listener : customListenerList) &#123;\n                        boolean verify = listener.verify(licenseCheck);\n                        compare = compare &amp;&amp; verify;\n                    &#125;\n                    return compare;\n                &#125;\n                throw new LicenseException(verifyResult.getException().getMessage());\n            &#125;\n        &#125;\n        return true;\n    &#125;\n&#125;\n\n\nlistener\nACustomVerifyListener\n/**\n * @Description\n * 增加业务系统中自定义证书验证监听器\n * @author Anchor\n * @Date 2021/9/2\n*/\npublic abstract class ACustomVerifyListener &#123;\n\n    /**软件证书参数全局验证监听容器*/\n    private static final List&lt;ACustomVerifyListener> CUSTOM_VERIFY_LISTENER_LIST = new ArrayList&lt;>(16);\n\n    public static List&lt;ACustomVerifyListener> getCustomListenerList()&#123;\n        return CUSTOM_VERIFY_LISTENER_LIST;\n    &#125;\n\n    /***\n     * 默认构造函数，干了一件事情，就是会把所有实现了这个抽象类的子类实例全部添加到全局自定义验证监听器列表中\n     * 因为在调用子类的构造函数时，会首先调用父类的构造器\n     */\n    public ACustomVerifyListener() &#123;\n        addCustomListener(this);\n    &#125;\n\n    public synchronized static void addCustomListener(ACustomVerifyListener verifyListener)&#123;\n        CUSTOM_VERIFY_LISTENER_LIST.add(verifyListener);\n    &#125;\n\n    /**\n     * 业务系统自定义证书认证方法\n     * @param licenseExtra 自定义验证参数\n     * @return boolean 是否成功\n     */\n    public abstract boolean verify(LicenseExtraParam licenseExtra) throws LicenseException;\n\n&#125;\n\n\n\nLicenseVerifyListener\n/**\n * @Description\n * 项目启动时安装证书&amp;定时检测lic变化，自动更替lic\n * @author Anchor\n * @Date 2021/9/2\n*/\n@Component\npublic class LicenseVerifyListener implements ApplicationListener&lt;ContextRefreshedEvent> &#123;\n\n    private static final Logger log = LoggerFactory.getLogger(LicenseVerifyListener.class);\n\n    /**\n     * 上下文对象实例\n     */\n    private static ApplicationContext applicationContext;\n\n    @Autowired\n    private LicenseVerifyProperties properties;\n\n    /**文件唯一身份标识 == 相当于人类的指纹一样*/\n    private static String md5 = \"\";\n    private static boolean isLoad = false;\n\n    @Override\n    public void onApplicationEvent(ContextRefreshedEvent event) &#123;\n        if(CommonUtils.isNotEmpty(properties.getLicensePath()))&#123;\n            install();\n            try&#123;\n                String readMd5 = getMd5(properties.getLicensePath());\n                isLoad = true;\n                if(LicenseVerifyListener.md5 == null || \"\".equals(LicenseVerifyListener.md5))&#123;\n                    LicenseVerifyListener.md5 =readMd5;\n                &#125;\n            &#125;catch (Exception e)&#123;\n\n            &#125;\n        &#125; else &#123;\n            HandlerLicenseRemider();\n        &#125;\n    &#125;\n\n    private void install() &#123;\n        log.info(\"++++++++ 开始安装授权证书 ++++++++\");\n        LicenseVerifyManager licenseVerifyManager = new LicenseVerifyManager();\n        /** 走定义校验证书并安装 */\n        LicenseResult result = licenseVerifyManager.install(properties.getVerifyParam());\n        if(result.getResult())&#123;\n            log.info(\"++++++++ 授权证书安装成功 ++++++++\");\n        &#125;else&#123;\n            log.error(\"++++++++ 授权证书安装失败 ++++++++\");\n            HandlerLicenseRemider();\n        &#125;\n    &#125;\n\n    /**\n     * &lt;p>获取文件的md5&lt;/p>\n     */\n    public String getMd5(String filePath) throws Exception &#123;\n        File file;\n        String md5 = \"\";\n        try &#123;\n            file = ResourceUtils.getFile(filePath);\n            if (file.exists()) &#123;\n                FileInputStream is = new FileInputStream(file);\n                byte[] data = new byte[is.available()];\n                is.read(data);\n                md5 = DigestUtils.md5DigestAsHex(data);\n                is.close();\n            &#125;\n        &#125; catch (FileNotFoundException e) &#123;\n\n        &#125;\n        return md5;\n    &#125;\n\n    /**\n     * &lt;p>日志打印授权提醒&lt;/p>\n     */\n    private void HandlerLicenseRemider() &#123;\n        try &#123;\n            log.warn(\"无有效授权证书，请联系管理员申请！申请参数[&#123;&#125;]\",\n                    Base64.encode(JSON.toJSONString(AServerInfos.getServer(\"\").getServerInfos()).getBytes(StandardCharsets.UTF_8)));\n        &#125; catch (LicenseContentException e) &#123;\n            log.error(\"读取服务器硬件信息异常:\"+e.getMessage());\n        &#125; finally &#123;\n            ConfigurableApplicationContext ctx = (ConfigurableApplicationContext) applicationContext;\n            ctx.close();\n            ctx.stop();\n        &#125;\n    &#125;\n\n&#125;\n\n\n4、license-boot-startboot-start模块非必须，仅为了模块调试及方便授权文件生成使用，代码结构非常简单：\n启动类\nLicenseApplication\n/**\n * @program: groot-license\n * @description: 启动类\n * @author: Anchor\n * @create: 2021-09-01\n **/\n@SpringBootApplication(exclude= &#123;DataSourceAutoConfiguration.class&#125;)\npublic class LicenseApplication extends SpringBootServletInitializer &#123;\n\n    public static void main(String[] args) &#123;\n        SpringApplication.run(LicenseApplication.class, args);\n    &#125;\n\n    @Override\n    protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123;\n        return application.sources(LicenseApplication.class);\n    &#125;\n&#125;\n\n\n配置文件\nApplication.yml\nserver:\n  # 服务器的HTTP端口，默认为8080\n  port: 8080\ngroot:\n  license:\n    verify:\n      prefix: http:&#x2F;&#x2F;localhost:8080&#x2F;license&#x2F;\n      licensePath: &#x2F;Users&#x2F;anchor&#x2F;Tools&#x2F;alihai5&#x2F;license.lic\n\n\n使用效果\nHTTP请求示例\nPOST /license/generate HTTP/1.1\nContent-Type: application/json; charset=utf-8\nHost: 127.0.0.1:8080\nConnection: close\nUser-Agent: RapidAPI/4.1.0 (Macintosh; OS X/13.0.1) GCDHTTPRequest\nContent-Length: 550\n\n&#123;\"subject\":\"groot\",\"privateAlias\":\"privatekeys\",\"keyPass\":\"groot7758\",\"storePass\":\"groot7758\",\"privateKeysStorePath\":\"/privateKeys.store\",\"issuedTime\":\"2022-12-01 00:00:00\",\"expiryTime\":\"2025-12-31 00:00:00\",\"description\":\"\\u7cfb\\u7edf\\u8f6f\\u4ef6\\u8bb8\\u53ef\\u8bc1\\u4e66\",\"licenseCheck\":&#123;\"ipAddress\":[\"192.168.1.111\"],\"macAddress\":[\"B0-DE-28-10-CA-92\"],\"cpuSerial\":\"L6PHQYPWGW\",\"mainBoardSerial\":\"D1F0CA19-227C-5B4C-8149-3DE736423365\",\"registerAmount\":1000,\"macCheck\":false,\"boardCheck\":false,\"cpuCheck\":false,\"ipCheck\":false,\"registerCheck\":false&#125;&#125;\n\n\n\nResponse接口返回示例\n&#123;\n  \"msg\": \"证书生成成功，证书有效期：2022-12-01 00:00:00 - 2025-12-31 00:00:00\",\n  \"code\": 200,\n  \"data\": &#123;\n    \"subject\": \"groot\",\n    \"privateAlias\": \"privatekeys\",\n    \"keyPass\": \"groot7758\",\n    \"privateKeysStorePath\": \"/privateKeys.store\",\n    \"storePass\": \"groot7758\",\n    \"licensePath\": \"/Users/anchor/Workspase/Alihai5/groot/license/20221226162407/license.lic\",\n    \"issuedTime\": \"2022-12-01 00:00:00\",\n    \"expiryTime\": \"2025-12-31 00:00:00\",\n    \"consumerType\": \"user\",\n    \"consumerAmount\": 1,\n    \"description\": \"系统软件许可证书\",\n    \"licenseCheck\": &#123;\n      \"ipAddress\": [\n        \"192.168.1.111\"\n      ],\n      \"macAddress\": [\n        \"B0-DE-28-10-CA-92\"\n      ],\n      \"cpuSerial\": \"L6PHQYPWGW\",\n      \"mainBoardSerial\": \"D1F0CA19-227C-5B4C-8149-3DE736423365\",\n      \"registerAmount\": 1000,\n      \"ipCheck\": false,\n      \"macCheck\": false,\n      \"cpuCheck\": false,\n      \"boardCheck\": false,\n      \"registerCheck\": false\n    &#125;,\n    \"licUrl\": \"http://localhost:8080/license/download?path=/Users/anchor/Workspase/Alihai5/groot/license/20221226162407/license.lic\"\n  &#125;\n&#125;\n\n\n5、实现效果有授权启动\n授权启动日志\n2022-12-31 14:51:21 INFO  [restartedMain] org.apache.coyote.http11.Http11NioProtocol Starting ProtocolHandler [\"http-nio-8080\"]\n2022-12-31 14:51:22 INFO  [restartedMain] c.a.license.verify.listener.LicenseVerifyListener ++++++++ 开始安装授权证书 ++++++++\n2022-12-31 14:51:22 INFO  [restartedMain] c.alihai5.license.core.model.LicenseVerifyManager 证书安装成功，证书有效期：2022-12-01 00:00:00 - 2025-12-31 00:00:00\n2022-12-31 14:51:22 INFO  [restartedMain] c.a.license.verify.listener.LicenseVerifyListener ++++++++ 授权证书安装成功 ++++++++\n2022-12-31 14:51:22 INFO  [restartedMain] com.alihai5.GrootApplication Started GrootApplication in 10.422 seconds (JVM running for 11.916)\n\n\n无授权启动\n无授权启动日志\n2022-12-31 14:52:56 INFO  [restartedMain] org.apache.coyote.http11.Http11NioProtocol Starting ProtocolHandler [\"http-nio-8080\"]\n2022-12-31 14:52:56 WARN  [restartedMain] c.a.license.verify.listener.LicenseVerifyListener 无有效授权证书，请联系管理员申请！申请参数[eyJib2FyZENoZWNrIjpmYWxzZSwiY3B1Q2hlY2siOmZhbHNlLCJjcHVTZXJpYWwiOiJMNlBIUVlQV0dXIiwiaXBBZGRyZXNzIjpbIjE5Mi4xNjguMC4xNSJdLCJpcENoZWNrIjpmYWxzZSwibWFjQWRkcmVzcyI6WyJCMC1ERS0yOC0xMC1DQS05MiJdLCJtYWNDaGVjayI6ZmFsc2UsIm1haW5Cb2FyZFNlcmlhbCI6IkQxRjBDQTE5LTIyN0MtNUI0Qy04MTQ5LTNERTczNjQyMzM2NSIsInJlZ2lzdGVyQ2hlY2siOmZhbHNlfQ==]\n2022-12-31 14:52:56 INFO  [restartedMain] org.apache.coyote.http11.Http11NioProtocol Pausing ProtocolHandler [\"http-nio-8080\"]\n2022-12-31 14:52:56 INFO  [restartedMain] org.apache.catalina.core.StandardService Stopping service [Tomcat]\n2022-12-31 14:52:56 WARN  [restartedMain] org.apache.catalina.loader.WebappClassLoaderBase The web application [ROOT] appears to have started a thread named [lettuce-timer-3-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:\n java.lang.Thread.sleep(Native Method)\n io.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:600)\n io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:496)\n io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n java.lang.Thread.run(Thread.java:748)\n2022-12-31 14:52:56 INFO  [restartedMain] org.apache.coyote.http11.Http11NioProtocol Stopping ProtocolHandler [\"http-nio-8080\"]\n2022-12-31 14:52:56 INFO  [restartedMain] org.apache.coyote.http11.Http11NioProtocol Destroying ProtocolHandler [\"http-nio-8080\"]\n2022-12-31 14:52:56 ERROR [restartedMain] org.springframework.boot.SpringApplication Application run failed\n\n\n五、总结有授权就一定有破解，没有绝对的防御，为防止被简单替换jar包被破解，可以尝试调整Maven引用层级，如将框架核心模块放入授权认证下，使之无法跳过验证逻辑，同时引入Allatori混淆代码等等措施，增加破解难度。\n","slug":"Java/SpringBoot集成TrueLicense实现授权管理","date":"2022-12-31T06:03:15.000Z","categories_index":"JAVA","tags_index":"JAVA,TrueLicense,SpringBoot,License","author_index":"Anchor"},{"id":"00e30bbeb7ce30522f4b80e6bd22ac09","title":"MySQL 数据库开发的三十六条军规","content":"MySQL 数据库开发的三十六条军规一、核心军规(5)1.1 尽量不在数据库做运算\n别让脚趾头想事情，那是脑瓜子的职责\n\n让数据库多做她擅长的事:\n\n尽量不在数据库做运算\n复杂运算秱到程序端 CPU\n尽可能简单应用 MySQL\n\n\n举例: md5() &#x2F; Order by Rand()\n\n\n1.2 控制单表数据量\n一年内的单表数据量预估\n\n纯 INT 不超 1000W\n含 CHAR 不超 500W\n\n\n合理分表不超载\n\nUSERID\nDATE\nAREA\n……\n\n\n建议单库不超过 300-400 个表\n\n\n1.3 保持表身段苗条\n表字段数少而精\n\nIO 高效\n全表遍历\n表修复快\n提高幵发\nalter table 快\n\n\n单表多少字段合适?\n\n单表 1G 体积 500W 行评估\n\n顺序读 1G 文件需 N 秒\n单行不超过 200Byte\n单表不超过 50 个纯 INT 字段\n单表不超过 20 个 CHAR(10)字段\n\n\n单表字段数上限控制在 20~50 个\n\n\n1.4 平衡范式不冗余\n严格遵循三大范式?\n效率优先、提升性能\n没有绝对的对不错\n适当时牺牲范式、加入冗余\n但会增加代码复杂度\n\n1.5 拒绝 3B\n数据库幵发像城市交通\n\n非线性增长\n\n\n拒绝 3B\n\n大 SQL (BIG SQL)\n大事务 (BIG Transaction)\n大批量 (BIG Batch)\n\n\n详细解析见后\n\n\n1.6 核心军规小结\n尽量不在数据库做运算\n控制单表数据量\n保持表身段苗条\n平衡范式不冗余\n拒绝 3B\n\n二、字段类军规(6)2.1 用好数值字段类型\n三类数值类型:\n\nTINYINT(1Byte)\nSMALLINT(2B)\nMEDIUMINT(3B)\nINT(4B)、BIGINT(8B)\nFLOAT(4B)、DOUBLE(8B)\nDECIMAL(M,D)\n\n\nBAD CASE:\n\nINT(1) VS INT(11)\nBIGINT AUTO_INCREMENT\nDECIMAL(18,0)\n\n\n\n2.2 将字符转化为数字\n数字型 VS 字符串型索引\n\n更高效\n查询更快\n占用空间更小\n\n\n举例:用无符号 INT 存储 IP，而非 CHAR(15)\n\nINT UNSIGNED\nINET_ATON()\nINET_NTOA()\n\n\n\n2.3 优先使用 ENUM 或 SET\n优先使用 ENUM 或 SET\n\n字符串\n可能值已知且有限\n\n\n存储\n\nENUM 占用 1 字节，转为数值运算\nSET 视节点定，最多占用 8 字节\n比较时需要加’ 单引号(即使是数值)\n\n\n举例\n\nsex enum(‘F’,’M’) COMMENT ‘性别’\nc1 enum(‘0’,’1’,’2’,’3’) COMMENT ‘职介审核’\n\n\n\n2.4 避免使用 NULL 字段\n避免使用 NULL 字段\n\n很难进行查询优化\nNULL 列加索引，需要额外空间\n含 NULL 复合索引无效\n\n\n举例\n\na char(32) DEFAULT NULL\nb int(10) NOT NULL\nc int(10) NOT NULL DEFAULT 0\n\n\n\n2.5 少用并拆分 TEXT&#x2F;BLOB\nTEXT 类型处理性能远低亍 VARCHAR\n\n强制生成硬盘临时表\n浪费更多空间\nVARCHAR(65535)&#x3D;&#x3D;&gt;64K (注意 UTF-8)\n\n\n尽量不用 TEXT&#x2F;BLOB 数据类型\n\n若必须使用则拆分到单独的表\n\n举例:\n\n\nCREATE TABLE t1 (\nid INT NOT NULL AUTO_INCREMENT, data text NOT NULL,\n‏PRIMARY KEY id\n) ENGINE=InnoDB;\n\n2.6 不在数据库里存图片2.7 字段类军规小结\n用好数值字段类型\n将字符转化为数字\n优先使用枚举 ENUM&#x2F;SET\n避免使用 NULL 字段\n少用幵拆分 TEXT&#x2F;BLOB\n不在数据库里存图片\n\n三、索引类军规(5)3.1 谨慎合理添加索引\n谨慎合理添加索引\n\n改善查询\n减慢更新\n索引不是赹多赹好\n\n\n能不加的索引尽量不加\n\n综合评估数据密度和数据分布\n最好不赸过字段数 20%\n\n\n结合核心 SQL 优先考虑覆盖索引\n\n举例\n\n不要给“性别”列创建索引\n\n\n\n3.2 字符字段必须建前缀索引\n区分度\n\n单字母区分度:26\n4 字母区分度:26_26_26*26&#x3D;456,976\n5 字母区分度:26_26_26_26_26&#x3D;11,881,376\n6 字母区分度:26_26_26_26_26*26&#x3D;308,915,776\n\n\n字符字段必须建前缀索引:\n\n\n(\n`pinyin` varchar(100) DEFAULT NULL COMMENT '小区拼音', KEY `idx_pinyin` (`pinyin`(8)),\n) ENGINE=InnoDB\n\n3.3 不在索引列做运算\n不在索引列进行数学运算或凼数运算\n\n无法使用索引\n导致全表扫描\n\n\n举例:\n\n\nBAD: SELECT * from table WHERE to_days(current_date) – to_days(date_col) &lt;= 10\nGOOD: SELECT * from table WHERE date_col >= DATE_SUB('2011-10- 22',INTERVAL 10 DAY);\n\n3.4 自增列或全局 ID 做 INNODB 主键\n对主键建立聚簇索引\n二级索引存储主键值\n主键不应更新修改\n按自增顺序揑入值\n忌用字符串做主键\n聚簇索引分裂\n推荐用独立亍业务的 AUTO_INCREMENT 列或全局 ID 生成 器做代理主键\n若不指定主键，InnoDB 会用唯一且非空值索引代替\n\n3.5 尽量不用外键\n线上 OLTP 系统(线下系统另论)\n\n外键可节省开发量\n有额外开销\n逐行操作\n可’到达’其它表，意味着锁\n高并发时容易死锁\n\n\n由程序保证约束\n\n\n3.6 索引类军规小结\n谨慎合理添加索引\n字符字段必须建前缀索引\n不在索引列做运算\n自增列或全局 ID 做 INNODB 主键\n尽量不用外键\n\n四、SQL 类军规(15)4.1 SQL 语句尽可能简单\n大 SQL VS 多个简单 SQL\n\n传统设计思想\nBUT MySQL NOT\n一条 SQL 叧能在一个 CPU 运算\n5000+ QPS 的高幵发中，1 秒大 SQL 意味着?\n可能一条大 SQL 就把整个数据库堵死\n\n\n拒绝大 SQL，拆解成多条简单 SQL\n\n简单 SQL 缓存命中率更高\n减少锁表时间，特别是 MyISAM\n用上多 CPU\n\n\n\n4.2 保持事务(连接)短小\n保持事务&#x2F;DB 连接短小精悍\n\n事务&#x2F;连接使用原则:即开即用，用完即关\n与事务无关操作放到事务外面, 减少锁资源的占用\n不破坏一致性前提下，使用多个短事务代替长事务\n\n\n举例\n\n发贴时的图片上传等待\n大量的 sleep 连接\n\n\n\n4.3 尽可能避免使用 SP&#x2F;TRIG&#x2F;FUNC\n线上 OLTP 系统(线下库另论)\n\n尽可能少用存储过程\n尽可能少用触发器\n减用使用 MySQL 凼数对结果进行处理\n\n\n由客户端程序负责\n\n\n4.4 尽量不用 SELECT\n用 SELECT * 时\n更多消耗 CPU、内存、IO、网络带宽\n先向数据库请求所有列，然后丢掉不需要列?\n尽量不用 SELECT * ，叧取需要数据列 • 更安全的设计:减少表变化带来的影响\n为使用 covering index 提供可能性\nSELECT&#x2F;JOIN 减少硬盘临时表生成，特别是有 TEXT&#x2F;BLOB 时\n举例:\n\nSELECT * FROM tag WHERE id = 999184;\nSELECT keyword FROM tag WHERE id = 999184;\n\n4.5 改写 OR 为 IN()\n同一字段，将 or 改写为 in()\nOR 效率:O(n)\nIN 效率:O(Log n)\n当 n 很大时，OR 会慢很多\n注意控制 IN 的个数，建议 n 小亍 200\n举例:\n\nSELECT * from opp WHERE phone='12347856' or phone='42242233' \\G;\nSELECT * from opp WHERE phone in ('12347856' , '42242233');\n\n4.6 改写 OR 为 UNION\n不同字段，将 or 改为 union\n减少对不同字段进行 “or” 查询\nMerge index 往往很弱智\n如果有足够信心:set global optimizer_switch&#x3D;’index_merge&#x3D;off’;\n举例:\n\nSELECT * from opp WHERE phone='010-88886666' or cellPhone='13800138000';\nSELECT * from opp WHERE phone='010-88886666' union SELECT * from opp WHERE cellPhone='13800138000';\n\n4.7 避免负向查询和% 前缀模糊查询\n避免负向查询\n\nNOT、!&#x3D;、&lt;&gt;、!&lt;、!&gt;、NOT EXISTS、NOT IN、 NOT LIKE 等\n\n\n避免 % 前缀模糊查询\n\nB+ Tree\n使用不了索引\n导致全表扫描\n\n\n举例:\n\n\nSELECT * from post WHERE title like '北京%'; -- 298 rows in set (0.01 sec)\nSELECT * from post WHERE title like '%北京%'; -- 572 rows in set (3.27 sec)\n\n4.8 COUNT(*)的几个例子\n几个有趣的例子:\n\nCOUNT(COL) VS COUNT(*)\nCOUNT(*) VS COUNT(1)\nCOUNT(1) VS COUNT(0) VS COUNT(100)\n\n\n示例:\n\n\n`id` int(10) NOT NULL AUTO_INCREMENT COMMENT '公司的id', `sale_id` int(10) unsigned DEFAULT NULL,\n\n\n结论\n\nCOUNT(*)&#x3D;count(1)\n\n\n\n*COUNT(0)&#x3D;count(1)\n\nCOUNT(1)&#x3D;count(100)\nCOUNT(*)!&#x3D;count(col)\nWHY?\n\n4.9 减少 COUNT(*)\nMyISAM VS INNODB\n\n不带 WHERE COUNT()\n带 WHERE COUNT()\n\n\nCOUNT(*)的资源开销大，尽量不用少用\n\n计数统计\n\n实时统计:用 memcache，双向更新，凌晨 跑基准\n非实时统计:尽量用单独统计表，定期重算\n\n\n\n4.10 LIMIT 高效分页\n传统分页:\n\nSELECT * from table limit 10000,10;\n\n\nLIMIT 原理:\n\nLimit 10000,10  偏秱量赹大则赹慢\n\n\n推荐分页:\n\nSELECT * from table WHERE id&gt;&#x3D;23423 limit 11;\n\n\n\n_SELECT _ from table WHERE id&gt;&#x3D;23434 limit 11;\n\n分页方式二:\n\nSELECT * from table WHERE id &gt;&#x3D; ( SELECT id from table limit 10000,1 ) limit 10;\n\n\n分页方式三:\n\nSELECT * FROM table INNER JOIN (SELECT id FROM table LIMIT 10000,10) USING (id);\n\n\n分页方式四:\n\n程序取 ID:SELECT id from table limit 10000,10;\nSELECT * from table WHERE id in (123,456…);\n\n\n可能需按场景分析幵重组索引\n\n示例:\n\n\nMySQL> SELECT sql_no_cache * from post limit 10,10; 10 row in set (0.01 sec)\nMySQL> SELECT sql_no_cache * from post limit 20000,10; 10 row in set (0.13 sec)\nMySQL> SELECT sql_no_cache * from post limit 80000,10; 10 rows in set (0.58 sec)\nMySQL> SELECT sql_no_cache id from post limit 80000,10; 10 rows in set (0.02 sec)\nMySQL> SELECT sql_no_cache * from post WHERE id>=323423 limit 10; 10 rows in set (0.01 sec)\nMySQL> SELECT * from post WHERE id >= ( SELECT sql_no_cache id from post limit 80000,1 ) limit 10; 10 rows in set (0.02 sec)\n\n4.11 用 UNION ALL 而非 UNION\n若无需对结果进行去重，则用 UNION ALL\n\nUNION 有去重开销\n\n\n举例:\n\n\nSELECT * FROM detail20091128 UNION ALL SELECT * FROM detail20110427 UNION ALL SELECT * FROM detail20110426 UNION ALL SELECT * FROM detail20110425 UNION ALL SELECT * FROM detail20110424 UNION ALL SELECT * FROM detail20110423;\n\n4.12 分解联接保证高并发\n高幵发 DB 不建议进行两个表以上的 JOIN\n\n适当分解联接保证高幵发\n\n可缓存大量早期数据\n使用了多个 MyISAM 表\n对大表的小 ID IN()\n联接引用同一个表多次\n举例:\n\n\n\nMySQL> SELECT * from tag JOIN post on tag_post.post_id=post.id WHERE tag.tag='二手玩具';\n\nMySQL> SELECT * from tag WHERE tag='二手玩具';\nMySQL> SELECT * from tag_post WHERE tag_id=1321;\nMySQL> SELECT * from post WHERE post.id in (123,456,314,141);\n\n4.13 GROUP BY 去除排序\nGROUP BY 实现\n\n分组\n自劢排序\n\n\n无需排序:Order by NULL\n\n特定排序:Group by DESC&#x2F;ASC\n\n举例:\n\n\nMySQL> SELECT phone,count(*) from post group by phone limit 1 ; 1 row in set (2.19 sec)\nMySQL> SELECT phone,count(*) from post group by phone order by null limit 1; 1 row in set (2.02 sec)\n\n4.14 同数据类型的列值比较\n原则:数字对数字，字符对字符\n\n数值列不字符类型比较\n\n同时转换为双精度\n进行比对\n\n\n字符列不数值类型比较\n\n字符列整列转数值\n不会使用索引查询\n\n\n举例:字符列不数值类型比较\n\n\n字段:`remark` varchar(50) NOT NULL COMMENT '备注, 默认为空',\n\nMySQL>SELECT `id`, `gift_code` FROM gift WHERE `deal_id` = 640 AND remark=115127; 1 row in set (0.14 sec)\nMySQL>SELECT `id`, `gift_code` FROM pool_gift WHERE `deal_id` = 640 AND remark='115127'; 1 row in set (0.005 sec)\n\n4.15 Load data 导数据\n批量数据快导入:\n\n成批装载比单行装载更快，不需要每次刷新缓存\n无索引时装载比索引装载更快\nInsert values ,values，values 减少索引刷新\nLoad data 比 insert 快约 20 倍\n\n\n尽量不用 INSERT … SELECT\n\n延迟\n同步出错\n\n\n\n4.16 打散大批量更新\n大批量更新凌晨操作，避开高峰\n凌晨不限制\n白天上限默认为 100 条&#x2F;秒(特殊再议)\n举例:\n\nupdate post set tag=1 WHERE id in (1,2,3); sleep 0.01;\nupdate post set tag=1 WHERE id in (4,5,6); sleep 0.01;\n......\n\n4.17 Know Every SQL\nSHOW PROFILE\nMySQLdumpslow\nEXPLAIN\nShow Slow Log\nSHOW QUERY_RESPONSE_TIME(Percona)\nMySQLsla\nShow Processlist\n\n4.18 SQL 类军规小结\nSQL 语句尽可能简单\n保持事务(连接)短小\n尽可能避免使用 SP&#x2F;TRIG&#x2F;FUNC\n尽量不用 SELECT *\n改写 OR 语句\n避免负向查询和% 前缀模糊查询\n减少 COUNT(*)\nLIMIT 的高效分页\n用 UNION ALL 而非 UNION\n分解联接保证高幵发\nGROUP BY 去除排序\n同数据类型的列值比较\nLoad data 导数据\n打散大批量更新\nKnow Every SQL!\n\n五、约定类军规(5)5.1 隔离线上线下\n构建数据库的生态环境\n\n开发无线上库操作权限\n\n原则:线上连线上，线下连线下\n\n实时数据用 real 库\n模拟环境用 sim 库\n测试用 qa 库\n开发用 dev 库\n\n\n\n5.2 禁止未经 DBA 确认的子查询\nMySQL 子查询\n\n大部分情况优化较差\n特别 WHERE 中使用 IN id 的子查询  一般可用 JOIN 改写\n\n\n举例:\n\n\nSELECT * from table1 where id id from table2) in (SELECT insert into table1 (SELECT * from table2); -- 可能导致复制异常\n\n5.3 永远不在程序端显式加锁\n永远不在程序端对数据库显式加锁\n\n外部锁对数据库不可控\n高并发发时是灾难\n极难调试和排查\n\n\n并发扣款等一致性问题\n\n采用事务\n相对值修改\nCommit 前二次较验冲突\n\n\n\n5.4 统一字符集为 UTF8\n字符集:\n\nMySQL 4.1 以前叧有 latin1\n为多语言支持增加多字符集\n也带来了 N 多问题\n保持简单\n\n\n统一字符集:UTF8\n\n校对规则:utf8_general_ci\n\n乱码:SET NAMES UTF8\n\n\n5.5 统一命名规范\n库表等名称统一用小写\n\nLinux VS Windows\nMySQL 库表大小写敏感\n字段名的大小写不敏感\n\n\n索引命名默认为“idx_字段名”\n\n库名用缩写，尽量在 2~7 个字母\n\nDataSharing &#x3D;&#x3D;&gt; ds\n\n\n注意避免用保留字命名\n\n……\n\n\n5.6 注意避免用保留字命名\n举例:\n\nSELECT * from return;\nSELECT * from `return`;\n\nMySQL系统关键字\n\nADD\nALL\nALTER GOTO\nGRANT\nGROUP\nPURGE\nRAID0\nRANGE\nANALYZE\nAND\nAS HAVING\nHIGH_PRIORIT Y\nHOUR_MICROSEC OND\nREAD\nREADS\nREAL\nASC\nASENSITIVE\nBEFORE HOUR_MINUTE\nHOUR_SECON D\nIF\nREFERENCES\nREGEXP\nRELEASE\nBETWEEN\nBIGINT\nBINARY IGNORE\nIN\nINDEX\nRENAME\nREPEAT\nREPLACE\nBLOB\nBOTH\nBY INFILE\nINNER\nINOUT\nREQUIRE\nRESTRICT\nRETURN\nCALL\nCASCADE\nCASE INSENSITIVE\nINSERT\nINT\nREVOKE\nRIGHT\nRLIKE\nCHANGE\nCHAR\nCHARACTER INT1\nINT2\nINT3\nSCHEMA\nSCHEMAS\nSECOND_MICROSEC OND\nCHECK\nCOLLATE\nCOLUMN INT4\nINT8\nINTEGER\nSELECT\nSENSITIVE\nSEPARATOR\nCONDITION\nCONNECTION\nCONSTRAINT INTERVAL\nINTO\nIS\nSET\nSHOW\nSMALLINT\nCONTINUE\nCONVERT\nCREATE ITERATE\nJOIN\nKEY\nSPATIAL\nSPECIFIC\nSQL\nCROSS\nCURRENT_DA TE\nCURRENT_TIM KEYS E\nKILL\nLABEL\nSQLEXCEPTION\nSQLSTATE\nSQLWARNING\nCURRENT_TIMESTA MP\nCURRENT_US ER\nCURSOR LEADING\nLEAVE\nLEFT\nSQL_BIG_RESUL T\nSQL_CALC_FOUND_R OWS\nSQL_SMALL_RESULT\nDATABASE\nDATABASES\nDAY_HOUR LIKE\nLIMIT\nLINEAR\nSSL\nSTARTING\nSTRAIGHT_JOIN\nDAY_MICROSECON D\nDAY_MINUTE\nDAY_SECOND LINES\nLOAD\nLOCALTIME\nTABLE\nTERMINATED\nTHEN\nDEC\nDECIMAL\nDECLARE LOCALTIMESTAMP\nLOCK\nLONG\nTINYBLOB\nTINYINT\nTINYTEXT\nDEFAULT\nDELAYED\nDELETE LONGBLOB\nLONGTEXT\nLOOP\nTO\nTRAILING\nTRIGGER\nDESC\nDESCRIBE\nDETERMINISTI LOW_PRIORITY C\nMATCH\nMEDIUMBLOB\nTRUE\nUNDO\nUNION\nDISTINCT\nDISTINCTROW\nDIV MEDIUMINT\nMEDIUMTEXT\nMIDDLEINT\nUNIQUE\nUNLOCK\nUNSIGNED\nDOUBLE\nDROP\nDUAL\nMINUTE_MICROSECO ND\nMINUTE_SECO ND\nMOD\nUPDATE\nUSAGE\nUSE\nEACH\nELSE\nELSEIF MODIFIES\nNATURAL\nNOT\nUSING\nUTC_DATE\nUTC_TIME\nENCLOSED\nESCAPED\nEXISTS\nNO_WRITE_TO_BINL OG\nNULL\nNUMERIC\nUTC_TIMESTAM P\nVALUES\nVARBINARY\nEXIT\nEXPLAIN\nFALSE ON\nOPTIMIZE\nOPTION\nVARCHAR\nVARCHARACTER\nVARYING\nFETCH\nFLOAT\nFLOAT4 OPTIONALLY\nOR\nORDER\nWHEN\nWHERE\nWHILE\nFLOAT8\nFOR\nFORCE OUT\nOUTER\nOUTFILE\nWITH\nWRITE\nX509\nFOREIGN\nFROM\nFULLTEXT PRECISION\nPRIMARY\nPROCEDURE\nXOR\nYEAR_MONTH\nZEROFILL\n\n5.7 约定类军规小结\n隔离线上线下\n禁止未经 DBA 确认的子查询上线\n永远不在程序端显式加锁\n统一字符集为 UTF8\n统一命名规范\n\n六、原文链接\nhttp://weibo.com/wushizhan\n\n","slug":"MySQL/MySQL数据库开发的三十六条军规","date":"2022-02-26T03:37:18.000Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"Anchor"},{"id":"1a07a30e4d12a51de2d9119320d5847f","title":"MySQL 主键设计盘点","content":"主键定义唯一标识表中每行的一个列（或一组列）称为主键。主键用来表示一个特定的行。\n主键设计和应用原则除了满足MySQL强制实施的规则（主键不可重复；一行中主键不可为空）之外，主键的设计和应用应当还遵守以下公认的原则：\n\n不更新主键列中的值；\n不重用主键列的值；\n不在主键列中使用可能会更改的值。（例如，如果使用一个 名字作为主键以标识某个供应商，当该供应商合并和更改其 名字时，必须更改这个主键。）\n\n主键生成策略自增ID使用数据库的自动增长（auto_increment），是比较简单和常见的ID生成方案，数据库内部可以确保生成id的唯一性。优点：1、数据库自动编号，速度快，而且是增量增长，聚集型主键按顺序存放，对于检索非常有利。2、 数字型，占用空间小，易排序，在程序中传递方便。缺点：1、不支持水平分片架构，水平分片的设计当中，这种方法显然不能保证全局唯一。2、对数据库有依赖，每种数据库可能实现不一样，数据库切换时候，涉及到代码的修改，不利于扩展结论：自增id做主键适用于非分布式架构。\nUUID| **UUID:通用唯一识别码（英语：Universally Unique Identifier，缩写：UUID）是用于计算机体系中以识别信息数目的一个128位标识符，还有相关的术语：全局唯一标识符（GUID）。 根据标准方法生成，不依赖中央机构的注册和分配，UUID具有唯一性，这与其他大多数编号方案不同。重复UUID码概率接近零，可以忽略不计。UUID是由一组32位数的16进制数字所构成,标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的32个字符。示例：550e8400-e29b-41d4-a716-446655440000\n\n\n\n到目前为止业界一共有5种方式生成UUID，详情可见IETF发布的UUID规范**A Universally Unique IDentifier (UUID) URN Namespace\n\n\n\n优点：性能非常高：本地生成，没有网络消耗。缺点：1、不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。2、信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。3、ID作为主键时在特定的环境会存在一些问题，比如需要排序的时候——UUID是无序的。4、MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。5、对MySQL索引不利：作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。关于MySQL 使用自增ID主键和UUID 作为主键的性能比较可以查看参考【8】。结论：1、uuid做主键适用于小规模分布式架构用。2、在使用uuid作为主键的时候，最好设计createtime（创建时间）列和modifytime（修改时间）列以应付可能的排序等场景。\n自建的id生成器Twitter的snowflake算法Twitter的snowflake算法的核心把时间戳，工作机器id，序列号组合在一起。除了最高位bit标记为不可用以外，其余三组bit占位均可浮动，看具体的业务需求而定。默认情况下41bit的时间戳可以支持该算法使用到2082年，10bit的工作机器id可以支持1023台机器，序列号支持1毫秒产生4095个自增序列id。\n具体可以查看：github.com&#x2F;twitter-arc…** （但是最近一次的提交是6年前，显示已经停止了对初始版snowflake的支持）**源码如下：\npackage com.yjd.comm.util;/**\n* Created by pc on 2017/8/16 0016.\n*/\n\n/**\n* Twitter_Snowflake&lt;br>\n* SnowFlake的结构如下(每部分用-分开):&lt;br>\n* 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br>\n* 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br>\n* 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)\n* 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br>\n* 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br>\n* 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br>\n* 加起来刚好64位，为一个Long型。&lt;br>\n* SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。\n*/\npublic class SnowflakeIdWorker &#123;\n    \n    // ==============================Fields===========================================\n    /**\n    * 开始时间截 (2015-01-01)\n    */\n    private final long twepoch = 1420041600000L;\n    \n    /**\n    * 机器id所占的位数\n    */\n    private final long workerIdBits = 5L;\n    \n    /**\n    * 数据标识id所占的位数\n    */\n    private final long datacenterIdBits = 5L;\n    \n    /**\n    * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)\n    */\n    private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits);\n    \n    /**\n    * 支持的最大数据标识id，结果是31\n    */\n    private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits);\n    \n    /**\n    * 序列在id中占的位数\n    */\n    private final long sequenceBits = 12L;\n    \n    /**\n    * 机器ID向左移12位\n    */\n    private final long workerIdShift = sequenceBits;\n    \n    /**\n    * 数据标识id向左移17位(12+5)\n    */\n    private final long datacenterIdShift = sequenceBits + workerIdBits;\n    \n    /**\n    * 时间截向左移22位(5+5+12)\n    */\n    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n    \n    /**\n    * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)\n    */\n    private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits);\n    \n    /**\n    * 工作机器ID(0~31)\n    */\n    private long workerId;\n    \n    /**\n    * 数据中心ID(0~31)\n    */\n    private long datacenterId;\n    \n    /**\n    * 毫秒内序列(0~4095)\n    */\n    private long sequence = 0L;\n    \n    /**\n    * 上次生成ID的时间截\n    */\n    private long lastTimestamp = -1L;\n    \n    //==============================Constructors=====================================\n    \n    /**\n    * 构造函数\n    *\n    * @param workerId     工作ID (0~31)\n    * @param datacenterId 数据中心ID (0~31)\n    */\n    public SnowflakeIdWorker(long workerId, long datacenterId) &#123;\n        if (workerId > maxWorkerId || workerId &lt; 0) &#123;\n            throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        &#125;\n        if (datacenterId > maxDatacenterId || datacenterId &lt; 0) &#123;\n            throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        &#125;\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    &#125;\n    \n    // ==============================Methods==========================================\n    \n    /**\n    * 获得下一个ID (该方法是线程安全的)\n    *\n    * @return SnowflakeId\n    */\n    public synchronized long nextId() &#123;\n        long timestamp = timeGen();\n        \n        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常\n        if (timestamp &lt; lastTimestamp) &#123;\n            throw new RuntimeException(\n                String.format(\"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        &#125;\n        \n        //如果是同一时间生成的，则进行毫秒内序列\n        if (lastTimestamp == timestamp) &#123;\n            sequence = (sequence + 1) &amp; sequenceMask;\n            //毫秒内序列溢出\n            if (sequence == 0) &#123;\n                //阻塞到下一个毫秒,获得新的时间戳\n                timestamp = tilNextMillis(lastTimestamp);\n            &#125;\n        &#125;\n        //时间戳改变，毫秒内序列重置\n        else &#123;\n            sequence = 0L;\n        &#125;\n        \n        //上次生成ID的时间截\n        lastTimestamp = timestamp;\n        \n        //移位并通过或运算拼到一起组成64位的ID\n        return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) //\n            | (datacenterId &lt;&lt; datacenterIdShift) //\n            | (workerId &lt;&lt; workerIdShift) //\n            | sequence;\n    &#125;\n    \n    /**\n    * 阻塞到下一个毫秒，直到获得新的时间戳\n    *\n    * @param lastTimestamp 上次生成ID的时间截\n    * @return 当前时间戳\n    */\n    protected long tilNextMillis(long lastTimestamp) &#123;\n        long timestamp = timeGen();\n        while (timestamp &lt;= lastTimestamp) &#123;\n            timestamp = timeGen();\n        &#125;\n        return timestamp;\n    &#125;\n    \n    /**\n    * 返回以毫秒为单位的当前时间\n    *\n    * @return 当前时间(毫秒)\n    */\n    protected long timeGen() &#123;\n        return System.currentTimeMillis();\n    &#125;\n    \n    //==============================Test=============================================\n    \n    /**\n    * 测试\n    */\n    public static void main(String[] args) &#123;\n        SnowflakeIdWorker idWorker = new SnowflakeIdWorker(1, 1);\n        long startime = System.currentTimeMillis();\n        for (int i = 0; i &lt; 4000000; i++) &#123;\n            long id = idWorker.nextId();\n            //            System.out.println(Long.toBinaryString(id));\n            //            System.out.println(id);\n        &#125;\n        System.out.println(System.currentTimeMillis() - startime);\n    &#125;\n&#125;\n\n\n优点：1、毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 2、 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 3、可以根据自身业务特性分配bit位，非常灵活。缺点：强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。结论：用自建的id生成器做主键适用于大规模分布式架构\n","slug":"MySQL/MySQL主键设计盘点","date":"2022-02-23T05:32:16.000Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"Anchor"},{"id":"6dd356025f124f190d32c47865445ac7","title":"MySQL 常用函数&数据类型","content":"MySQL 常用函数汇总字符串函数\n\n\n函数\n功能\n\n\n\nCONCAT(s1,s2,……)\n字符串连接\n\n\nINSERT(str,x,y,instr)\n将指定开始标记到结束的字符串替换为指定字符串\n\n\nLOWER(str)\n将字符串所有字符转为小写\n\n\nUPPER(str)\n将字符串所有字符串转为大写\n\n\nLEFT(str,x)\n返回字符串 str 最左边的 x 个字符\n\n\nRIGHT(str,x)\n返回字符串 str 最右边的 x 个字符\n\n\nLPAD(str,n,pad)\n在 str 最左边填充 n 个 pad\n\n\nRPAD(str,n,pad)\n在 str 最右边填充 n 个 pad\n\n\nLTRIM(str)\n去掉字符串 str 左侧的空格\n\n\nRTRIM(str)\n去掉字符串 str 右侧的空格\n\n\nREPEAT(str,x)\n返回 str 重复 x 次的结果\n\n\nSTRCMP(s1,s2)\n比较字符串 s1 和 s2\n\n\nREPLACE(str,a,b)\n用字符串 b 替换字符串 str 中所有出现的字符串 a\n\n\nTRIM(str)\n去掉字符串行尾和行头的空格\n\n\nSUBSTRING(str,x,y)\n返回从字符串 str x 位置起 y 个字符长度的字串\n\n\n数学函数\n\n\n函数\n功能\n\n\n\nABS(x)\n返回 x 的绝对值\n\n\nCEIL(x)\n返回大于 x 的最小整数值\n\n\nFLOOR(x)\n返回小于 x 的最大整数值\n\n\nMOD(x,y)\n返回 x&#x2F;y 的模\n\n\nRAND()\n返回 0～1 内的随机值\n\n\nROUND(x,y)\n返回参数 x 的四舍五入的有 y 位小数的值\n\n\nTRUNCATE(x,y)\n返回数字 x 截断位 y 位小数的结果\n\n\n日期和时间函数\n\n\n函数\n功能\n\n\n\nCURDATE()\n返回当前日期\n\n\nCURTIME()\n返回当前时间\n\n\nNOW()\n返回当前的日期和时间\n\n\nUNIX_TIMESTAMP(date)\n返回日期 date 的 UNIX 时间戳\n\n\nFROM_UNIXTIME\n返回 UNIX 时间戳的日期值\n\n\nWEEK(date)\n返回日期 date 为一年中的第几周\n\n\nYEAR(date)\n返回日期 date 的年份\n\n\nHOUR(time)\n返回 time 的小时值\n\n\nMINUTE(time)\n返回 time 的分钟值\n\n\nMONTHNAME(date)\n返回 date 的月份名\n\n\nDATE_FORMAT(date,fmt)\n返回按字符串 fmt 格式日期 date 值\n\n\nDATE_ADD(date,interval expr type)\n返回一个日期或时间值加上一个时间间隔的时间值\n\n\nDATEDIFF(expr,expr2)\n返回起始时间 expr 和结束时间 expr2 之间的天数\n\n\n流程函数\n\n\n函数\n功能\n\n\n\nIF(value,t f)\n如果 value 是真，返回 t；否则返回 f\n\n\nIFNULL(value1,value2)\n如果 value1 不为空，返回 value1，否则返回 value2\n\n\nCASE WHEN [value1] THEN[result1]…ELSE[default]END\n如果 value1 是真，返回 result1，否则返回 result\n\n\nCASE[expr] WHEN [value1]THEN[result1]…ELSE[default]END\n如果 expr 等于 value1，返回 result1，否则返回 default\n\n\n其他常用函数\n\n\n函数\n功能\n\n\n\nDATEBASE()\n返回当前数据库名\n\n\nVERSION()\n返回当前数据库版本\n\n\nUSER()\n返回当前登录用户名\n\n\nINET_ATON(ip)\n返回 ip 地址的数字表示\n\n\nINET_NTOA(num)\n返回数字代表的 ip 地址\n\n\nPASSWORD(str)\n返回字符串 str 的加密版本\n\n\nMD5()\n返回字符串 str 的 md5 值\n\n\nMySQL 数据类型串数据类型\n\n\n数据类型\n说明\n\n\n\nCHAR\n1～255 个字符的定长串。它的长度必须在创建时指定，否则 MySQL 假定为 CHAR(1)\n\n\nENUM\n接受最多 64 K 个串组成的一个预定义集合的某个串\n\n\nLONGTEXT\n与 TEXT 相同，但最大长度为 4GB\n\n\nMEDIUMTEXT\n与 TEXT 相同，但最大长度为 16K\n\n\nSET\n接受最多 64 个串组成的一个预定义集合的零个或多个串\n\n\nTEXT\n最大长度为 64K 的变长文本\n\n\nTINYTEXT\n与 TEXT 相同，但最大长度为 255 字节\n\n\nVARCHAR\n长度可变，最多不超过 255 字节。如果在创建时指定为 VARCHAR(n)，则可存储 0 到 n 个字符的变长串（其中 n≤255）\n\n\n数值数据类型\n\n\n数据类型\n说明\n\n\n\nBIT\n位字段，1～64 位。（在 MySQL 5 之前，BIT 在功能上等价于 TINYINT\n\n\nBIGINT\n整数值，支持9223372036854775808～9223372036854775807（如果是 UNSIGNED，为 0～18446744073709551615）的数\n\n\nBOOLEAN（或 BOOL）\n布尔标志，或者为 0 或者为 1，主要用于开&#x2F;关（on&#x2F;off）标志\n\n\nDECIMAL（或 DEC）\n精度可变的浮点值\n\n\nDOUBLE\n双精度浮点值\n\n\nFLOAT\n单精度浮点值\n\n\nINT（或 INTEGER）\n整数值，支持2147483648～2147483647（如果是 UNSIGNED，为 0～4294967295）的数\n\n\nMEDIUMINT\n整数值，支持8388608～8388607（如果是 UNSIGNED，为 0～16777215）的数\n\n\nREAL\n4 字节的浮点值\n\n\nSMALLINT\n整数值，支持32768～32767（如果是 UNSIGNED，为 0～65535）的数\n\n\nTINYINT\n整数值，支持128～127（如果为 UNSIGNED，为 0～255）的数\n\n\n日期和时间数据类型\n\n\n数据类型\n说明\n\n\n\nDATE\n表示 1000-01-01～9999-12-31 的日期，格式为 YYYY-MM-DD\n\n\nDATETIME\nDATE 和 TIME 的组合\n\n\nTIMESTAMP\n功能和 DATETIME 相同（但范围较小）\n\n\nTIME\n格式为 HH:MM:SS\n\n\nYEAR\n用 2 位数字表示，范围是 70（1970 年）～69（2069 年），用 4 位数字表示，范围是 1901 年～2155 年\n\n\n二进制数据类型\n\n\n数据类型\n说明\n\n\n\nBLOB\nBlob 最大长度为 64KB\n\n\nMEDIUMBLOB\nBlob 最大长度为 16MB\n\n\nLONGBLOB\nBlob 最大长度为 4GB\n\n\nTINYBLOB\nBlob 最大长度为 255 字节\n\n\n","slug":"MySQL/MySQL常用函数汇总","date":"2022-02-23T05:32:16.000Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"Anchor"},{"id":"87cebc6d905dece24636202906841487","title":"MySQL 数据库设计规范","content":"MySQL 数据库设计规范1. 规范背景与目的MySQL 数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用 MySQL 数据库的时候需要遵循一定规范，扬长避短。本规范旨在帮助或指导 RD、QA、OP 等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL 编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。\n2. 设计规范2.1 数据库设计以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。\n对于不满足【高危】和【强制】两个级别的设计，DBA 会强制打回要求修改。\n2.1.1 一般命名规则\n【强制】使用小写，有助于提高打字速度，避免因大小写敏感而导致的错误。\n【强制】没有空格，使用下划线代替。\n【强制】名称中没有数字，只有英文字母。\n【强制】有效的可理解的名称。\n【强制】名称应该是自我解释的。\n【强制】名称不应超过 32 个字符。\n【强制】避免使用前缀。\n\n2.1.2 库\n【强制】遵守以上全部一般命名规则。 \n【强制】使用单数。 \n【强制】库的名称格式：业务系统名称_子系统名。 \n【强制】一般分库名称命名格式是库通配名_编号，编号从 0 开始递增，比如 northwind_001，以时间进行分库的名称格式是库通配名_时间。 \n【强制】创建数据库时必须显式指定字符集，并且字符集只能是 utf8 或者 utf8mb4。创建数据库 SQL 举例：  create database db_name default character set utf8;\n\n2.1.3 表\n【强制】遵守以上全部一般命名规则。\n【强制】使用单数。\n【强制】相关模块的表名与表名之间尽量体现 join 的关系，如 user 表和 user_login 表。\n【强制】创建表时必须显式指定字符集为 utf8 或 utf8mb4。\n【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为 InnoDB。当需要使用除 InnoDB&#x2F;MyISAM&#x2F;Memory 以外的存储引擎时，必须通过 DBA 审核才能在生产环境中使用。因为 InnoDB 表支持事务、行锁、宕机恢复、MVCC 等关系型数据库重要特性，为业界使用最多的 MySQL 存储引擎。而这是其它大多数存储引擎不具备的，因此首推 InnoDB。\n【强制】建表必须有 comment。\n【强制】关于主键：(1) 命名为 id，类型为 int 或 bigint，且为 auto_increment；(2) 标识表里每一行主体的字段不要设为主键，建议设为其它字段如 user_id，order_id等，并建立 unique key 索引。因为如果设为主键且主键值为随机插入，则会导致 InnoDB 内部 page 分裂和大量随机 I&#x2F;O，性能下降。\n【建议】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段 create_time 和最后更新时间字段 update_time，便于排查问题。\n【建议】表中所有字段必须都是 NOT NULL 属性，业务可以根据需要定义 DEFAULT 值。因为使用 NULL 值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。\n【建议】建议对表里的 blob、text 等大字段，垂直拆分到其它表里，仅在需要读这些对象的时候才去 select。\n【建议】反范式设计：把经常需要 join 查询的字段，在其它表里冗余一份。如 username 属性在 user_account，user_login_log 等表里冗余一份，减少 join 查询。\n【强制】中间表用于保留中间结果集，名称必须以 tmp_ 开头。备份表用于备份或抓取源表快照，名称必须以 bak_ 开头。中间表和备份表定期清理。\n【强制】对于超过 100W 行的大表进行 alter table，必须经过 DBA 审核，并在业务低峰期执行。因为 alter table 会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。\n\n2.1.4 字段\n【强制】遵守以上全部一般命名规则。\n【建议】尽可能选择短的或一两个单词。\n【强制】避免使用保留字作为字段名称：order，date，name 是数据库的保留字，避免使用它。可以为这些名称添加前缀使其易于理解，如 user_name，signup_date 等。\n【强制】避免使用与表名相同的字段名，这会在编写查询时造成混淆。\n【强制】在数据库模式上定义外键。\n【强制】避免使用缩写或基于首字母缩写词的名称。\n【强制】外键列必须具有表名及其主键，例如：blog_id 表示来自表博客的外键 id。\n\n2.1.5 字段数据类型优化\n【建议】表中的自增列（auto_increment 属性），推荐使用 bigint 类型。因为无符号 int 存储范围为 0~4,294,967,295（不到 43 亿），溢出后会导致报错。 \n【建议】业务中选择性很少的状态 status、类型 type 等字段推荐使用 tinytint 或者 smallint 类型节省存储空间。 \n【建议】业务中 IP 地址字段推荐使用 int 类型，不推荐用 char(15)。因为 int 只占 4 字节，可以用如下函数相互转换，而 char(15) 占用至少 15 字节。\n\nSQL: \nselect inet_aton('192.168.2.12');\nselect inet_ntoa(3232236044);\nPHP: \nip2long('192.168.2.12'); \nlong2ip(3530427185);\n\nJava:  \npublic static long ipToLong(String addr)&#123;\n    String[] addrArray = addr.split(\"\\\\.\");\n    long num = 0;\n    for (int i = 0; i &lt; addrArray.length; i++)&#123;\n        int power = 3 - i;\n        num += ((Integer.parseInt(addrArray[i]) % 256 * Math.pow(256, power)));\n    &#125;\n    return num;\n&#125;\n\npublic static String longToIp(long i)&#123;\n    return ((i >> 24) &amp; 0xFF) + \".\" +\n           ((i >> 16) &amp; 0xFF) + \".\" +\n           ((i >> 8) &amp; 0xFF) + \".\" +\n           (i &amp; 0xFF);\n&#125;\n\n\n【建议】不推荐使用 enum，set。 因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用 tinyint 或 smallint。 \n【建议】不推荐使用 blob，text 等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和 PM、RD 沟通，是否真的需要这么大字段。InnoDB 中当一行记录超过 8098 字节时，会将该记录中选取最长的一个字段将其 768 字节放在原始 page 里，该字段余下内容放在 overflow-page 里。不幸的是在 compact 行格式下，原始 page 和 overflow-page 都会加载。 \n【建议】存储金钱的字段，建议用 int 以分为单位存储，最大数值约 4290 万，程序端乘以 100 和除以 100 进行存取。因为 int 占用 4 字节，而 double 占用 8 字节，空间浪费。 \n【建议】文本数据尽量用 varchar 存储。因为 varchar 是变长存储，比 char 更省空间。MySQL server 层规定一行所有文本最多存 65535 字节，因此在 utf8 字符集下最多存 21844 个字符，超过会自动转换为 mediumtext 字段。而 text 在 utf8 字符集下最多存 21844 个字符，mediumtext 最多存 2^24&#x2F;3 个字符，longtext 最多存 2^32 个字符。一般建议用 varchar 类型，字符数不要超过 2700。 \n【建议】时间类型尽量选取 timestamp。因为 datetime 占用 8 字节，timestamp 仅占用 4 字节，但是范围为 1970-01-01 00:00:01 到 2038-01-01 00:00:00。更为高阶的方法，选用 int 来存储时间，使用 SQL 函数 unix_timestamp() 和 from_unixtime() 来进行转换。\n\n\n详细存储大小参考下图：  \n\n\n类型（同义词）\n存储长度(BYTES)\n最小值(SIGNED&#x2F;UNSIGNED)\n最大值(SIGNED&#x2F;UNSIGNED)\n\n\n\n整形数字\n\n\n\n\n\nTINYINT\n1\n-128&#x2F;0\n127&#x2F;255\n\n\nSMALLINT\n2\n-32,768&#x2F;0\n32767&#x2F;65,535\n\n\nMEDIUMINT\n3\n-8,388,608&#x2F;0\n8388607&#x2F;16,777,215&#x2F;\n\n\nINT(INTEGER)\n4\n-2,14,7483,648&#x2F;0\n2147483647&#x2F;4,294,967,295&#x2F;\n\n\nBIGINT\n8\n-2^63&#x2F;0\n263-1&#x2F;264-1\n\n\n小数支持\n\n\n\n\n\nFLOAT[(M[,D])]\n4 or 8\n-\n\n\n\nDOUBLE[(M[,D])]\n\n\n\n\n\n(REAL, DOUBLE PRECISION)\n8\n-\n\n\n\n时间类型\n\n\n\n\n\nDATETIME\n8\n1001-01-01 00:00:00\n9999-12-31 23:59:59\n\n\nDATE\n3\n1001-01-01\n9999-12-31\n\n\nTIME\n3\n00:00:00\n23:59:59\n\n\nYEAR\n1\n1001\n9999\n\n\nTIMESTAMP\n4\n1970-01-01 00:00:00\n\n\n\n\n\n2.1.6 索引设计\n【强制】InnoDB 表必须主键为 id int/bigint auto_increment，且主键值禁止被更新。\n【建议】主键的名称以 pk_ 开头，唯一键以 uk_ 开头，普通索引以 ix_ 开头，一律使用小写格式，以表名&#x2F;字段的名称或缩写作为后缀。\n【强制】InnoDB 和 MyISAM 存储引擎表，索引类型必须为 BTREE；MEMORY 表可以根据需要选择 HASH 或者 BTREE 类型索引。\n【强制】单个索引中每个索引记录的长度不能超过 64KB。\n【建议】单个表上的索引个数不能超过 7 个。\n【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列 user_id 的区分度可由 select count(distinct user_id) 计算出来。\n【建议】在多表 join 的 SQL 里，保证被驱动表的连接列上有索引，这样 join 执行效率最高。\n【建议】建表或加索引时，保证表里互相不存在冗余索引。对于 MySQL 来说，如果表里已经存在 key(a, b)，则 key(a) 为冗余索引，需要删除。\n【建议】如果选择性超过 20%，那么全表扫描比使用索引性能更优，即没有设置索引的必要。\n\n2.1.7 分库分表、分区表\n【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。\n【强制】单个分区表中的分区（包括子分区）个数不能超过 1024。\n【强制】上线前 RD 或者 DBA 必须指定分区表的创建、清理策略。\n【强制】访问分区表的 SQL 必须包含分区键。\n【建议】单个分区文件不超过 2G，总大小不超过 50G。建议总分区数不超过 20 个。\n【强制】对于分区表执行 alter table 操作，必须在业务低峰期执行。\n【强制】采用分库策略的，库的数量不能超过 1024。\n【强制】采用分表策略的，表的数量不能超过 4096。\n【建议】单个分表不超过 500W 行，ibd 文件大小不超过 2G，这样才能让数据分布式变得性能更佳。\n【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。\n\n2.1.8 字符集\n【强制】数据库本身库、表、列所有字符集必须保持一致，为 utf8 或 utf8mb4。\n【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为 utf8。\n\n2.1.9 程序层 DAO 设计建议\n【建议】新的代码不要用 model，推荐使用手动拼 SQL + 绑定变量传入参数的方式。因为 model 虽然可以使用面向对象的方式操作 db，但是其使用不当很容易造成生成的 SQL 非常复杂，且 model 层自己做的强制类型转换性能较差，最终导致数据库性能下降。\n【建议】前端程序连接 MySQL 或者 Redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。\n【建议】前端程序报错里尽量能够提示 MySQL 或 Redis 原生态的报错信息，便于排查错误。\n【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。\n【建议】对于 log 或 history 类型的表，随时间增长容易越来越大，因此上线前 RD 或者 DBA 必须建立表数据清理或归档方案。\n【建议】在应用程序设计阶段，RD 必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20 秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。\n【建议】多个并发业务逻辑访问同一块数据（InnoDB 表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类 SQL 尽量基于主键去更新。\n【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。\n【建议】对于单表读写比大于 10:1 的数据行或单个列，可以将热点数据放在缓存里（如 Memcached 或 Redis），加快访问速度，降低 MySQL 压力。\n\n2.1.10 一个规范的建表语句示例\n一个较为规范的建表语句为： create table user \n( \n    `id`            bigint(11) not null auto_increment, \n    `user_id`       bigint(11) not null comment '用户 ID', \n    `username`      varchar(45) not null comment '登录名', \n    `email`         varchar(30) not null comment '邮箱', \n    `nickname`      varchar(45) not null comment '昵称', \n    `avatar`        int(11) not null comment '头像', \n    `birthday`      date not null comment '生日', \n    `gender`        tinyint(4) default '0' comment '性别', \n    `intro`         varchar(150) default null comment '简介', \n    `resume_url`    varchar(300) not null comment '简历存放地址', \n    `register_ip`   int not null comment '用户注册时的源 IP', \n    `review_status` tinyint not null comment '审核状态，1-通过，2-审核中，3-未通过，4-尚未提交审核', \n    `create_time`   timestamp not null comment '记录创建的时间', \n    `update_time`   timestamp not null comment '资料修改的时间', \n    \n    primary key (`id`), \n    unique key `idx_user_id` (`user_id`), \n    key `idx_username`(`username`), \n    key `idx_create_time`(`create_time`, `review_status`) \n) \nengine = InnoDB\ndefault charset = utf8 \ncomment = '用户基本信息';\n\n2.2 SQL 编写2.2.1 DML 语句\n【强制】select 语句必须指定具体字段名称，禁止写成 *。因为 select * 会将不该读的数据也从 MySQL 里读出来，造成网卡压力。\n【强制】insert 语句指定具体字段名称，不要写成 insert into t1 values(…)，道理同上。\n【建议】insert into … values(xx),(xx),(xx)…，这里 xx 的值不要超过 5000 个。值过多虽然上线很快，但会引起主从同步延迟。\n【建议】select 语句不要使用 union，推荐使用 union all，并且 union 子句个数限制在 5 个以内。因为 union all 不需要去重，节省数据库资源，提高性能。\n【建议】in 值列表限制在 500 以内。例如 select … where user_id in(…500 个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。\n【建议】事务里批量更新数据需要控制数量，进行必要的 sleep，做到少量多次。\n【强制】事务涉及的表必须全部是 InnoDB 表。否则一旦失败不会全部回滚，且易造成主从库同步终端。\n【强制】写入和事务发往主库，只读 SQL 发往从库。\n【强制】除静态表或小表（100 行以内），dml 语句必须有 where 条件，且使用索引查找。\n【强制】生产环境禁止使用 hint，如 sql_no_cache，force index，ignore key，straight join 等。因为 hint 是用来强制 sql 按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信 MySQL 优化器。\n【强制】where 条件里等号左右字段类型必须一致，否则无法利用索引。\n【建议】select|update|delete|replace 要有 where 子句，且 where 子句的条件必需使用索引查找。\n【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于 100 行以下的静态表可以全表扫描。查询数据量不要超过表行数的 25%，否则不会利用索引。\n【强制】where 子句中禁止只使用全模糊的 like 条件进行查找，必须有其它等值或范围查询条件，否则无法利用索引。\n【建议】索引列不要使用函数或表达式，否则无法利用索引。如 where length(name) = &#39;admin&#39; 或 where user_id + 2 = 10023。\n【建议】减少使用 or 语句，可将 or 语句优化为 union，然后在各个 where 条件上建立索引。如 where a = 1 or b = 2 优化为 where a = 1 … union … where b = 2, key(a), key(b)。\n【建议】分页查询，当 limit 起点较高时，可先用过滤条件进行过滤。如 select a, b, c from t1 limit 10000, 20; 优化为: select a, b, c from t1 where id &gt; 10000 limit 20;。\n\n2.2.2 多表连接\n【强制】禁止跨 DB 的 join 语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。\n【强制】禁止在业务的更新类 SQL 语句中使用 join，比如 update t1 join t2 …。\n【建议】不建议使用子查询，建议将子查询 SQL 拆开结合程序多次查询，或使用 join 来代替子查询。\n【建议】线上环境，多表 join 不要超过 3 个表。\n【建议】多表连接查询推荐使用别名，且 select 列表中要用别名引用字段，数据库.表格式，如 select a from db1.table1 alias1 where …。\n【建议】在多表 join 中，尽量选取结果集较小的表作为驱动表，来 join 其它表。\n\n2.2.3 事务\n【建议】事务中 insert|update|delete|replace 语句操作的行数控制在 2000 以内，以及 where 子句中 in 列表的传参个数控制在 500 以内。\n【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的 sleep，一般建议值 5-10 秒。\n【建议】对于有 auto_increment 属性字段的表的插入操作，并发需要控制在 200 以内。\n【强制】程序设计必须考虑“数据库事务隔离级别”带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为 repeatable-read。\n【建议】事务里包含 SQL 不超过 5 个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL 内部缓存、连接消耗过多等雪崩问题。\n【建议】事务里更新语句尽量基于主键或 unique key，如 update … where id = XX;，否则会产生间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。\n【建议】尽量把一些典型外部调用移出事务，如调用 Web Service，访问文件存储等，从而避免事务过长。\n【建议】对于 MySQL 主从延迟严格敏感的 select 语句，请开启事务强制访问主库。\n\n2.2.4 排序和分组\n【建议】减少使用 order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct 这些语句较为耗费 CPU，数据库的 CPU 资源是极其宝贵的。\n【建议】order by、group by、distinct 这些 SQL 尽量利用索引直接检索出排序好的数据。如 where a = 1 order by 可以利用 key(a, b)。\n【建议】包含了 order by、group by、distinct 这些查询的语句，where 条件过滤出来的结果集请保持在 1000 行以内，否则 SQL 会很慢。\n\n2.2.5 线上禁止使用的 SQL 语句\n【高危】禁用 update|delete t1 … where a = XX limit XX; 这种带 limit 的更新语句。因为会导致主从不一致，导致数据错乱。建议加上 order by PK。\n【高危】禁止使用关联子查询，如 update t1 set … where name in(select name from user where …);，效率极其低下。\n【强制】禁用 procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。\n【强制】禁用 insert into … on duplicate key update … 在高并发环境下，会造成主从不一致。\n【强制】禁止联表更新语句，如 update t1, t2 where t1.id = t2.id …。\n\n","slug":"MySQL/MySQL数据库设计规范","date":"2022-02-23T03:37:18.000Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"Anchor"},{"id":"05a67146f7d966ee36e5b6b5404bf177","title":"Java 技术栈（基础篇）","content":"一、数据类型基本类型\nbyte&#x2F;8\nchar&#x2F;16\nshort&#x2F;16\nint&#x2F;32\nfloat&#x2F;32\nlong&#x2F;64\ndouble&#x2F;64\nboolean&#x2F;~\n\nboolean 只有两个值：true、false，可以使用 1 bit 来存储，但是具体大小没有明确规定。JVM 会在编译时期将 boolean 类型的数据转换为 int，使用 1 来表示 true，0 表示 false。JVM 支持 boolean 数组，但是是通过读写 byte 数组来实现的。\n\nPrimitive Data Types\nThe Java® Virtual Machine Specification\n\n包装类型基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2;     // 装箱 调用了 Integer.valueOf(2)\nint y = x;         // 拆箱 调用了 X.intValue()\n\n\nAutoboxing and Unboxing\n\n缓存池new Integer(123) 与 Integer.valueOf(123) 的区别在于：\n\nnew Integer(123) 每次都会新建一个对象；\nInteger.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。\n\nInteger x = new Integer(123);\nInteger y = new Integer(123);\nSystem.out.println(x == y);    // false\nInteger z = Integer.valueOf(123);\nInteger k = Integer.valueOf(123);\nSystem.out.println(z == k);   // true\n\nvalueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\npublic static Integer valueOf(int i) &#123;\n    if (i >= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)\n        return IntegerCache.cache[i + (-IntegerCache.low)];\n    return new Integer(i);\n&#125;\n\n在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\nstatic final int low = -128;\nstatic final int high;\nstatic final Integer cache[];\n\nstatic &#123;\n    // high value may be configured by property\n    int h = 127;\n    String integerCacheHighPropValue =\n        sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\");\n    if (integerCacheHighPropValue != null) &#123;\n        try &#123;\n            int i = parseInt(integerCacheHighPropValue);\n            i = Math.max(i, 127);\n            // Maximum array size is Integer.MAX_VALUE\n            h = Math.min(i, Integer.MAX_VALUE - (-low) -1);\n        &#125; catch( NumberFormatException nfe) &#123;\n            // If the property cannot be parsed into an int, ignore it.\n        &#125;\n    &#125;\n    high = h;\n\n    cache = new Integer[(high - low) + 1];\n    int j = low;\n    for(int k = 0; k &lt; cache.length; k++)\n        cache[k] = new Integer(j++);\n\n    // range [-128, 127] must be interned (JLS7 5.1.7)\n    assert IntegerCache.high >= 127;\n&#125;\n\n编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。\nInteger m = 123;\nInteger n = 123;\nSystem.out.println(m == n); // true\n\n基本类型对应的缓冲池如下：\n\nboolean values true and false\nall byte values\nshort values between -128 and 127\nint values between -128 and 127\nchar in the range \\u0000 to \\u007F\n\n在使用这些基本类型对应的包装类型时，如果该数值范围在缓冲池范围内，就可以直接使用缓冲池中的对象。\n在 jdk 1.8 所有的数值类缓冲池中，Integer 的缓冲池 IntegerCache 很特殊，这个缓冲池的下界是 - 128，上界默认是 127，但是这个上界是可调的，在启动 jvm 的时候，通过 -XX:AutoBoxCacheMax&#x3D; 来指定这个缓冲池的大小，该选项在 JVM 初始化的时候会设定一个名为 java.lang.IntegerCache.high 系统属性，然后 IntegerCache 初始化的时候就会读取该系统属性来决定上界。\nStackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123\n二、String概览String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承）在 Java 8 中，String 内部使用 char 数组存储数据。\npublic final class String\n    implements java.io.Serializable, Comparable&lt;String>, CharSequence &#123;\n    /** The value is used for character storage. */\n    private final char value[];\n&#125;\n\n在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。\npublic final class String\n    implements java.io.Serializable, Comparable&lt;String>, CharSequence &#123;\n    /** The value is used for character storage. */\n    private final byte[] value;\n\n    /** The identifier of the encoding used to encode the bytes in &#123;@code value&#125;. */\n    private final byte coder;\n&#125;\n\nvalue 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\n不可变的好处1. 可以缓存 hash 值因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2. String Pool 的需要如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n\n3. 安全性String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n4. 线程安全String 不可变性天生具备线程安全，可以在多个线程中安全地使用。\nProgram Creek : Why String is immutable in Java?\nString, StringBuffer and StringBuilder1. 可变性\nString 不可变\nStringBuffer 和 StringBuilder 可变\n\n2. 线程安全\nString 不可变，因此是线程安全的\nStringBuilder 不是线程安全的\nStringBuffer 是线程安全的，内部使用 synchronized 进行同步\n\nStackOverflow : String, StringBuffer, and StringBuilder\nString Pool字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同字符串，而 s3 和 s4 是通过 s1.intern() 和 s2.intern() 方法取得同一个字符串引用。intern() 首先把 “aaa” 放到 String Pool 中，然后返回这个字符串引用，因此 s3 和 s4 引用的是同一个字符串。\nString s1 = new String(\"aaa\");\nString s2 = new String(\"aaa\");\nSystem.out.println(s1 == s2);           // false\nString s3 = s1.intern();\nString s4 = s2.intern();\nSystem.out.println(s3 == s4);           // true\n\n如果是采用 “bbb” 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中。\nString s5 = \"bbb\";\nString s6 = \"bbb\";\nSystem.out.println(s5 == s6);  // true\n\n在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n\nStackOverflow : What is String interning?\n深入解析 String#intern\n\nnew String(“abc”)使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 “abc” 字符串对象）。\n\n“abc” 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 “abc” 字符串字面量；\n而使用 new 的方式会在堆中创建一个字符串对象。\n\n创建一个测试类，其 main 方法中使用这种方式来创建字符串对象。\npublic class NewStringTest &#123;\n    public static void main(String[] args) &#123;\n        String s = new String(\"abc\");\n    &#125;\n&#125;\n\n使用 javap -verbose 进行反编译，得到以下内容：\n// ...\nConstant pool:\n// ...\n   #2 = Class              #18            // java/lang/String\n   #3 = String             #19            // abc\n// ...\n  #18 = Utf8               java/lang/String\n  #19 = Utf8               abc\n// ...\n\n  public static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=3, locals=2, args_size=1\n         0: new           #2                  // class java/lang/String\n         3: dup\n         4: ldc           #3                  // String abc\n         6: invokespecial #4                  // Method java/lang/String.\"&lt;init>\":(Ljava/lang/String;)V\n         9: astore_1\n// ...\n\n在 Constant Pool 中，#19 存储这字符串字面量 “abc”，#3 是 String Pool 的字符串对象，它指向 #19 这个字符串字面量。在 main 方法中，0: 行使用 new #2 在堆中创建一个字符串对象，并且使用 ldc #3 将 String Pool 中的字符串对象作为 String 构造函数的参数。\n以下是 String 构造函数的源码，可以看到，在将一个字符串对象作为另一个字符串对象的构造函数参数时，并不会完全复制 value 数组内容，而是都会指向同一个 value 数组。\npublic String(String original) &#123;\n    this.value = original.value;\n    this.hash = original.hash;\n&#125;\n\n三、运算参数传递Java 的参数是以值传递的形式传入方法中，而不是引用传递。以下代码中 Dog dog 的 dog 是一个指针，存储的是对象的地址。在将一个参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。\npublic class Dog &#123;\n\n    String name;\n\n    Dog(String name) &#123;\n        this.name = name;\n    &#125;\n\n    String getName() &#123;\n        return this.name;\n    &#125;\n\n    void setName(String name) &#123;\n        this.name = name;\n    &#125;\n\n    String getObjectAddress() &#123;\n        return super.toString();\n    &#125;\n&#125;\n\n在方法中改变对象的字段值会改变原对象该字段值，因为引用的是同一个对象。\nclass PassByValueExample &#123;\n    public static void main(String[] args) &#123;\n        Dog dog = new Dog(\"A\");\n        func(dog);\n        System.out.println(dog.getName());          // B\n    &#125;\n\n    private static void func(Dog dog) &#123;\n        dog.setName(\"B\");\n    &#125;\n&#125;\n\n但是在方法中将指针引用了其它对象，那么此时方法里和方法外的两个指针指向了不同的对象，在一个指针改变其所指向对象的内容对另一个指针所指向的对象没有影响。\npublic class PassByValueExample &#123;\n    public static void main(String[] args) &#123;\n        Dog dog = new Dog(\"A\");\n        System.out.println(dog.getObjectAddress()); // Dog@4554617c\n        func(dog);\n        System.out.println(dog.getObjectAddress()); // Dog@4554617c\n        System.out.println(dog.getName());          // A\n    &#125;\n\n    private static void func(Dog dog) &#123;\n        System.out.println(dog.getObjectAddress()); // Dog@4554617c\n        dog = new Dog(\"B\");\n        System.out.println(dog.getObjectAddress()); // Dog@74a14482\n        System.out.println(dog.getName());          // B\n    &#125;\n&#125;\n\nStackOverflow: Is Java “pass-by-reference” or “pass-by-value”?\nfloat 与 doubleJava 不能隐式执行向下转型，因为这会使得精度降低。1.1 字面量属于 double 类型，不能直接将 1.1 直接赋值给 float 变量，因为这是向下转型。\n// float f = 1.1;\n\n1.1f 字面量才是 float 类型。\nfloat f = 1.1f;\n\n隐式类型转换因为字面量 1 是 int 类型，它比 short 类型精度要高，因此不能隐式地将 int 类型向下转型为 short 类型。\nshort s1 = 1;\n// s1 = s1 + 1;\n\n但是使用 +&#x3D; 或者 ++ 运算符会执行隐式类型转换。\ns1 += 1;\ns1++;\n\n上面的语句相当于将 s1 + 1 的计算结果进行了向下转型：\ns1 = (short) (s1 + 1);\n\nStackOverflow : Why don’t Java’s +&#x3D;, -&#x3D;, *&#x3D;, &#x2F;&#x3D; compound assignment operators require casting?\nswitch从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。\nString s = \"a\";\nswitch (s) &#123;\n    case \"a\":\n        System.out.println(\"aaa\");\n        break;\n    case \"b\":\n        System.out.println(\"bbb\");\n        break;\n&#125;\n\nswitch 不支持 long、float、double，是因为 switch 的设计初衷是对那些只有少数几个值的类型进行等值判断，如果值过于复杂，那么还是用 if 比较合适。\n// long x = 111;\n// switch (x) &#123; // Incompatible types. Found: 'long', required: 'char, byte, short, int, Character, Byte, Short, Integer, String, or an enum'\n//     case 111:\n//         System.out.println(111);\n//         break;\n//     case 222:\n//         System.out.println(222);\n//         break;\n// &#125;\n\nStackOverflow : Why can’t your switch statement data type be long, Java?\n四、关键字final1. 数据声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n\n对于基本类型，final 使数值不变；\n对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。\n\nfinal int x = 1;\n// x = 2;  // cannot assign value to final variable 'x'\nfinal A y = new A();\ny.a = 1;\n\n2. 方法声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n3. 类声明类不允许被继承。\nstatic1. 静态变量\n静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。\n实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。\n\npublic class A &#123;\n\n    private int x;         // 实例变量\n    private static int y;  // 静态变量\n\n    public static void main(String[] args) &#123;\n        // int x = A.x;  // Non-static field 'x' cannot be referenced from a static context\n        A a = new A();\n        int x = a.x;\n        int y = A.y;\n    &#125;\n&#125;\n\n2. 静态方法静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。\npublic abstract class A &#123;\n    public static void func1()&#123;\n    &#125;\n    // public abstract static void func2();  // Illegal combination of modifiers: 'abstract' and 'static'\n&#125;\n\n只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字，因为这两个关键字与具体对象关联。\npublic class A &#123;\n\n    private static int x;\n    private int y;\n\n    public static void func1()&#123;\n        int a = x;\n        // int b = y;  // Non-static field 'y' cannot be referenced from a static context\n        // int b = this.y;     // 'A.this' cannot be referenced from a static context\n    &#125;\n&#125;\n\n3. 静态语句块静态语句块在类初始化时运行一次。\npublic class A &#123;\n    static &#123;\n        System.out.println(\"123\");\n    &#125;\n\n    public static void main(String[] args) &#123;\n        A a1 = new A();\n        A a2 = new A();\n    &#125;\n&#125;\n\n// 只会打印一次\n123\n\n4. 静态内部类非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。\npublic class OuterClass &#123;\n\n    class InnerClass &#123;\n    &#125;\n\n    static class StaticInnerClass &#123;\n    &#125;\n\n    public static void main(String[] args) &#123;\n        // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context\n        OuterClass outerClass = new OuterClass();\n        InnerClass innerClass = outerClass.new InnerClass();\n        StaticInnerClass staticInnerClass = new StaticInnerClass();\n    &#125;\n&#125;\n\n静态内部类不能访问外部类的非静态的变量和方法。\n5. 静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\nimport static com.xxx.ClassName.*\n\n6. 初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\npublic static String staticField = \"静态变量\";\n\nstatic &#123;\n    System.out.println(\"静态语句块\");\n&#125;\n\npublic String field = \"实例变量\";\n\n&#123;\n    System.out.println(\"普通语句块\");\n&#125;\n\n最后才是构造函数的初始化。\npublic InitialOrderTest() &#123;\n    System.out.println(\"构造函数\");\n&#125;\n\n存在继承的情况下，初始化顺序为：\n\n父类（静态变量、静态语句块）\n子类（静态变量、静态语句块）\n父类（实例变量、普通语句块）\n父类（构造函数）\n子类（实例变量、普通语句块）\n子类（构造函数）\n\n五、Object 通用方法概览public native int hashCode()\n\npublic boolean equals(Object obj)\n\nprotected native Object clone() throws CloneNotSupportedException\n\npublic String toString()\n\npublic final native Class&lt;?> getClass()\n\nprotected void finalize() throws Throwable &#123;&#125;\n\npublic final native void notify()\n\npublic final native void notifyAll()\n\npublic final native void wait(long timeout) throws InterruptedException\n\npublic final void wait(long timeout, int nanos) throws InterruptedException\n\npublic final void wait() throws InterruptedException\n\nequals()1. 等价关系两个对象具有等价关系，需要满足以下五个条件：\nⅠ 自反性x.equals(x); // true\n\nⅡ 对称性x.equals(y) == y.equals(x); // true\n\nⅢ 传递性if (x.equals(y) &amp;&amp; y.equals(z))\n    x.equals(z); // true;\n\nⅣ 一致性多次调用 equals() 方法结果不变\nx.equals(y) == x.equals(y); // true\n\nⅤ 与 null 的比较对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false\nx.equals(null); // false;\n\n2. 等价与相等\n对于基本类型，&#x3D;&#x3D; 判断两个值是否相等，基本类型没有 equals() 方法。\n对于引用类型，&#x3D;&#x3D; 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。\n\nInteger x = new Integer(1);\nInteger y = new Integer(1);\nSystem.out.println(x.equals(y)); // true\nSystem.out.println(x == y);      // false\n\n3. 实现\n检查是否为同一个对象的引用，如果是直接返回 true；\n检查是否是同一个类型，如果不是，直接返回 false；\n将 Object 对象进行转型；\n判断每个关键域是否相等。\n\npublic class EqualExample &#123;\n\n    private int x;\n    private int y;\n    private int z;\n\n    public EqualExample(int x, int y, int z) &#123;\n        this.x = x;\n        this.y = y;\n        this.z = z;\n    &#125;\n\n    @Override\n    public boolean equals(Object o) &#123;\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n\n        EqualExample that = (EqualExample) o;\n\n        if (x != that.x) return false;\n        if (y != that.y) return false;\n        return z == that.z;\n    &#125;\n&#125;\n\nhashCode()hashCode() 返回哈希值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价，这是因为计算哈希值具有随机性，两个值不同的对象可能计算出相同的哈希值。\n在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象哈希值也相等。\nHashSet  和 HashMap 等集合类使用了 hashCode()  方法来计算对象应该存储的位置，因此要将对象添加到这些集合类中，需要让对应的类实现 hashCode()  方法。\n下面的代码中，新建了两个等价的对象，并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的，只在集合中添加一个对象。但是 EqualExample 没有实现 hashCode() 方法，因此这两个对象的哈希值是不同的，最终导致集合添加了两个等价的对象。\nEqualExample e1 = new EqualExample(1, 1, 1);\nEqualExample e2 = new EqualExample(1, 1, 1);\nSystem.out.println(e1.equals(e2)); // true\nHashSet&lt;EqualExample> set = new HashSet&lt;>();\nset.add(e1);\nset.add(e2);\nSystem.out.println(set.size());   // 2\n\n理想的哈希函数应当具有均匀性，即不相等的对象应当均匀分布到所有可能的哈希值上。这就要求了哈希函数要把所有域的值都考虑进来。可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。\nR 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位，最左边的位丢失。并且一个数与 31 相乘可以转换成移位和减法：31*x == (x&lt;&lt;5)-x，编译器会自动进行这个优化。\n@Override\npublic int hashCode() &#123;\n    int result = 17;\n    result = 31 * result + x;\n    result = 31 * result + y;\n    result = 31 * result + z;\n    return result;\n&#125;\n\ntoString()默认返回 ToStringExample@4554617c  这种形式，其中 @ 后面的数值为散列码的无符号十六进制表示。 \npublic class ToStringExample &#123;\n\n    private int number;\n\n    public ToStringExample(int number) &#123;\n        this.number = number;\n    &#125;\n&#125;\n\nToStringExample example = new ToStringExample(123);\nSystem.out.println(example.toString());\n\nToStringExample@4554617c\n\nclone()1. cloneableclone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。\npublic class CloneExample &#123;\n    private int a;\n    private int b;\n&#125;\n\nCloneExample e1 = new CloneExample();\n// CloneExample e2 = e1.clone(); // 'clone()' has protected access in 'java.lang.Object'\n\n重写 clone() 得到以下实现：\npublic class CloneExample &#123;\n    private int a;\n    private int b;\n\n    @Override\n    public CloneExample clone() throws CloneNotSupportedException &#123;\n        return (CloneExample)super.clone();\n    &#125;\n&#125;\n\nCloneExample e1 = new CloneExample();\ntry &#123;\n    CloneExample e2 = e1.clone();\n&#125; catch (CloneNotSupportedException e) &#123;\n    e.printStackTrace();\n&#125;\n\njava.lang.CloneNotSupportedException: CloneExample\n\n以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。\n应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。\npublic class CloneExample implements Cloneable &#123;\n    private int a;\n    private int b;\n\n    @Override\n    public Object clone() throws CloneNotSupportedException &#123;\n        return super.clone();\n    &#125;\n&#125;\n\n2. 浅拷贝拷贝对象和原始对象的引用类型引用同一个对象。\npublic class ShallowCloneExample implements Cloneable &#123;\n\n    private int[] arr;\n\n    public ShallowCloneExample() &#123;\n        arr = new int[10];\n        for (int i = 0; i &lt; arr.length; i++) &#123;\n            arr[i] = i;\n        &#125;\n    &#125;\n\n    public void set(int index, int value) &#123;\n        arr[index] = value;\n    &#125;\n\n    public int get(int index) &#123;\n        return arr[index];\n    &#125;\n\n    @Override\n    protected ShallowCloneExample clone() throws CloneNotSupportedException &#123;\n        return (ShallowCloneExample) super.clone();\n    &#125;\n&#125;\n\nShallowCloneExample e1 = new ShallowCloneExample();\nShallowCloneExample e2 = null;\ntry &#123;\n    e2 = e1.clone();\n&#125; catch (CloneNotSupportedException e) &#123;\n    e.printStackTrace();\n&#125;\ne1.set(2, 222);\nSystem.out.println(e2.get(2)); // 222\n\n3. 深拷贝拷贝对象和原始对象的引用类型引用不同对象。\npublic class DeepCloneExample implements Cloneable &#123;\n\n    private int[] arr;\n\n    public DeepCloneExample() &#123;\n        arr = new int[10];\n        for (int i = 0; i &lt; arr.length; i++) &#123;\n            arr[i] = i;\n        &#125;\n    &#125;\n\n    public void set(int index, int value) &#123;\n        arr[index] = value;\n    &#125;\n\n    public int get(int index) &#123;\n        return arr[index];\n    &#125;\n\n    @Override\n    protected DeepCloneExample clone() throws CloneNotSupportedException &#123;\n        DeepCloneExample result = (DeepCloneExample) super.clone();\n        result.arr = new int[arr.length];\n        for (int i = 0; i &lt; arr.length; i++) &#123;\n            result.arr[i] = arr[i];\n        &#125;\n        return result;\n    &#125;\n&#125;\n\nDeepCloneExample e1 = new DeepCloneExample();\nDeepCloneExample e2 = null;\ntry &#123;\n    e2 = e1.clone();\n&#125; catch (CloneNotSupportedException e) &#123;\n    e.printStackTrace();\n&#125;\ne1.set(2, 222);\nSystem.out.println(e2.get(2)); // 2\n\n4. clone() 的替代方案使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。\npublic class CloneConstructorExample &#123;\n\n    private int[] arr;\n\n    public CloneConstructorExample() &#123;\n        arr = new int[10];\n        for (int i = 0; i &lt; arr.length; i++) &#123;\n            arr[i] = i;\n        &#125;\n    &#125;\n\n    public CloneConstructorExample(CloneConstructorExample original) &#123;\n        arr = new int[original.arr.length];\n        for (int i = 0; i &lt; original.arr.length; i++) &#123;\n            arr[i] = original.arr[i];\n        &#125;\n    &#125;\n\n    public void set(int index, int value) &#123;\n        arr[index] = value;\n    &#125;\n\n    public int get(int index) &#123;\n        return arr[index];\n    &#125;\n&#125;\n\nCloneConstructorExample e1 = new CloneConstructorExample();\nCloneConstructorExample e2 = new CloneConstructorExample(e1);\ne1.set(2, 222);\nSystem.out.println(e2.get(2)); // 2\n\n六、继承访问权限Java 中有三个访问权限修饰符：private、protected 以及 public，如果不加访问修饰符，表示包级可见。\n可以对类或类中的成员（字段和方法）加上访问修饰符。\n\n类可见表示其它类可以用这个类创建实例对象。\n成员可见表示其它类可以用这个类的实例对象访问到该成员；\n\nprotected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。\n如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例去代替，也就是确保满足里氏替换原则。\n字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 公有字段，如果在某个时刻，我们想要使用 int 存储 id 字段，那么就需要修改所有的客户端代码。\npublic class AccessExample &#123;\n    public String id;\n&#125;\n\n可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。\npublic class AccessExample &#123;\n\n    private int id;\n\n    public String getId() &#123;\n        return id + \"\";\n    &#125;\n\n    public void setId(String id) &#123;\n        this.id = Integer.valueOf(id);\n    &#125;\n&#125;\n\n但是也有例外，如果是包级私有的类或者私有的嵌套类，那么直接暴露成员不会有特别大的影响。\npublic class AccessWithInnerClassExample &#123;\n\n    private class InnerClass &#123;\n        int x;\n    &#125;\n\n    private InnerClass innerClass;\n\n    public AccessWithInnerClassExample() &#123;\n        innerClass = new InnerClass();\n    &#125;\n\n    public int getValue() &#123;\n        return innerClass.x;  // 直接访问\n    &#125;\n&#125;\n\n抽象类与接口1. 抽象类抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。\n抽象类和普通类最大的区别是，抽象类不能被实例化，只能被继承。\npublic abstract class AbstractClassExample &#123;\n\n    protected int x;\n    private int y;\n\n    public abstract void func1();\n\n    public void func2() &#123;\n        System.out.println(\"func2\");\n    &#125;\n&#125;\n\npublic class AbstractExtendClassExample extends AbstractClassExample &#123;\n    @Override\n    public void func1() &#123;\n        System.out.println(\"func1\");\n    &#125;\n&#125;\n\n// AbstractClassExample ac1 = new AbstractClassExample(); // 'AbstractClassExample' is abstract; cannot be instantiated\nAbstractClassExample ac2 = new AbstractExtendClassExample();\nac2.func1();\n\n2. 接口接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类，让它们都实现新增的方法。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。从 Java 9 开始，允许将方法定义为 private，这样就能定义某些复用的代码又不会把方法暴露出去。\n接口的字段默认都是 static 和 final 的。\npublic interface InterfaceExample &#123;\n\n    void func1();\n\n    default void func2()&#123;\n        System.out.println(\"func2\");\n    &#125;\n\n    int x = 123;\n    // int y;               // Variable 'y' might not have been initialized\n    public int z = 0;       // Modifier 'public' is redundant for interface fields\n    // private int k = 0;   // Modifier 'private' not allowed here\n    // protected int l = 0; // Modifier 'protected' not allowed here\n    // private void fun3(); // Modifier 'private' not allowed here\n&#125;\n\npublic class InterfaceImplementExample implements InterfaceExample &#123;\n    @Override\n    public void func1() &#123;\n        System.out.println(\"func1\");\n    &#125;\n&#125;\n\n// InterfaceExample ie1 = new InterfaceExample(); // 'InterfaceExample' is abstract; cannot be instantiated\nInterfaceExample ie2 = new InterfaceImplementExample();\nie2.func1();\nSystem.out.println(InterfaceExample.x);\n\n3. 比较\n从设计层面上看，抽象类提供了一种 IS-A 关系，需要满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。\n从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。\n接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。\n接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。\n\n4. 使用选择使用接口：\n\n需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Comparable 接口中的 compareTo() 方法；\n需要使用多重继承。\n\n使用抽象类：\n\n需要在几个相关的类中共享代码。\n需要能控制继承来的成员的访问权限，而不是都为 public。\n需要继承非静态和非常量字段。\n\n在很多情况下，接口优先于抽象类。因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。\n\nAbstract Methods and Classes\n深入理解 abstract class 和 interface\nWhen to Use Abstract Class and Interface\nJava 9 Private Methods in Interfaces\n\nsuper\n访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super() 函数。\n访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。\n\npublic class SuperExample &#123;\n\n    protected int x;\n    protected int y;\n\n    public SuperExample(int x, int y) &#123;\n        this.x = x;\n        this.y = y;\n    &#125;\n\n    public void func() &#123;\n        System.out.println(\"SuperExample.func()\");\n    &#125;\n&#125;\n\npublic class SuperExtendExample extends SuperExample &#123;\n\n    private int z;\n\n    public SuperExtendExample(int x, int y, int z) &#123;\n        super(x, y);\n        this.z = z;\n    &#125;\n\n    @Override\n    public void func() &#123;\n        super.func();\n        System.out.println(\"SuperExtendExample.func()\");\n    &#125;\n&#125;\n\nSuperExample e = new SuperExtendExample(1, 2, 3);\ne.func();\n\nSuperExample.func()\nSuperExtendExample.func()\n\nUsing the Keyword super\n重写与重载1. 重写（Override）存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有以下三个限制：\n\n子类方法的访问权限必须大于等于父类方法；\n子类方法的返回类型必须是父类方法返回类型或为其子类型。\n子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。\n\n使用 @Override  注解，可以让编译器帮忙检查是否满足上面的三个限制条件。 \n下面的示例中，SubClass 为 SuperClass 的子类，SubClass 重写了 SuperClass 的 func() 方法。其中：\n\n子类方法访问权限为 public，大于父类的 protected。\n子类的返回类型为 ArrayList，是父类返回类型 List 的子类。\n子类抛出的异常类型为 Exception，是父类抛出异常 Throwable 的子类。\n子类重写方法使用 @Override  注解，从而让编译器自动检查是否满足限制条件。\n\nclass SuperClass &#123;\n    protected List&lt;Integer> func() throws Throwable &#123;\n        return new ArrayList&lt;>();\n    &#125;\n&#125;\n\nclass SubClass extends SuperClass &#123;\n    @Override\n    public ArrayList&lt;Integer> func() throws Exception &#123;\n        return new ArrayList&lt;>();\n    &#125;\n&#125;\n\n在调用一个方法时，先从本类中查找看是否有对应的方法，如果没有再到父类中查看，看是否从父类继承来。否则就要对参数进行转型，转成父类之后看是否有对应的方法。总的来说，方法调用的优先级为：\n\nthis.func(this)\nsuper.func(this)\nthis.func(super)\nsuper.func(super)\n\n/*\n    A\n    |\n    B\n    |\n    C\n    |\n    D\n */\n\n\nclass A &#123;\n\n    public void show(A obj) &#123;\n        System.out.println(\"A.show(A)\");\n    &#125;\n\n    public void show(C obj) &#123;\n        System.out.println(\"A.show(C)\");\n    &#125;\n&#125;\n\nclass B extends A &#123;\n\n    @Override\n    public void show(A obj) &#123;\n        System.out.println(\"B.show(A)\");\n    &#125;\n&#125;\n\nclass C extends B &#123;\n&#125;\n\nclass D extends C &#123;\n&#125;\n\npublic static void main(String[] args) &#123;\n\n    A a = new A();\n    B b = new B();\n    C c = new C();\n    D d = new D();\n\n    // 在 A 中存在 show(A obj)，直接调用\n    a.show(a); // A.show(A)\n    // 在 A 中不存在 show(B obj)，将 B 转型成其父类 A\n    a.show(b); // A.show(A)\n    // 在 B 中存在从 A 继承来的 show(C obj)，直接调用\n    b.show(c); // A.show(C)\n    // 在 B 中不存在 show(D obj)，但是存在从 A 继承来的 show(C obj)，将 D 转型成其父类 C\n    b.show(d); // A.show(C)\n\n    // 引用的还是 B 对象，所以 ba 和 b 的调用结果一样\n    A ba = new B();\n    ba.show(c); // A.show(C)\n    ba.show(d); // A.show(C)\n&#125;\n\n2. 重载（Overload）存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\nclass OverloadingExample &#123;\n    public void show(int x) &#123;\n        System.out.println(x);\n    &#125;\n\n    public void show(int x, String y) &#123;\n        System.out.println(x + \" \" + y);\n    &#125;\n&#125;\n\npublic static void main(String[] args) &#123;\n    OverloadingExample example = new OverloadingExample();\n    example.show(1);\n    example.show(1, \"2\");\n&#125;\n\n七、反射每个类都有一个   Class   对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\n\nField  ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段；\nMethod  ：可以使用 invoke() 方法调用与 Method 对象关联的方法；\nConstructor  ：可以用 Constructor 的 newInstance() 创建新的对象。\n\n反射的优点：\n可扩展性   ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。\n类浏览器和可视化开发环境   ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。\n调试器和测试工具   ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。\n\n反射的缺点：尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。\n\n性能开销   ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 \n安全限制   ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 \n内部暴露   ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。 \nTrail: The Reflection API \n深入解析 Java 反射（1）- 基础\n\n八、异常Throwable 可以用来表示任何可以作为异常抛出的类，分为两种：  Error   和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种：\n\n受检异常  ：需要用 try…catch… 语句捕获并进行处理，并且可以从异常中恢复；\n非受检异常  ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。\n\n\n\nJava Exception Interview Questions and Answers \nJava提高篇——Java 异常处理\n\n九、泛型public class Box&lt;T> &#123;\n    // T stands for \"Type\"\n    private T t;\n    public void set(T t) &#123; this.t = t; &#125;\n    public T get() &#123; return t; &#125;\n&#125;\n\n\nJava 泛型详解\n10 道 Java 泛型面试题\n\n十、注解Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。\n注解 Annotation 实现原理与自定义注解例子\n十一、特性Java 各版本的新特性New highlights in Java SE 8\nLambda Expressions\nPipelines and Streams\nDate and Time API\nDefault Methods\nType Annotations\nNashhorn JavaScript Engine\nConcurrent Accumulators\nParallel operations\nPermGen Error Removed\n\nNew highlights in Java SE 7\nStrings in Switch Statement\nType Inference for Generic Instance Creation\nMultiple Exception Handling\nSupport for Dynamic Languages\nTry with Resources\nJava nio Package\nBinary Literals, Underscore in literals\nDiamond Syntax\n\n\nDifference between Java 1.8 and Java 1.7?\nJava 8 特性\n\nJava 与 C++ 的区别\nJava 是纯粹的面向对象语言，所有的对象都继承自 java.lang.Object，C++ 为了兼容 C 即支持面向对象也支持面向过程。\nJava 通过虚拟机从而实现跨平台特性，但是 C++ 依赖于特定的平台。\nJava 没有指针，它的引用可以理解为安全指针，而 C++ 具有和 C 一样的指针。\nJava 支持自动垃圾回收，而 C++ 需要手动回收。\nJava 不支持多重继承，只能通过实现多个接口来达到相同目的，而 C++ 支持多重继承。\nJava 不支持操作符重载，虽然可以对两个 String 对象执行加法运算，但是这是语言内置支持的操作，不属于操作符重载，而 C++ 可以。\nJava 的 goto 是保留字，但是不可用，C++ 可以使用 goto。\n\nWhat are the main differences between Java and C++?\nJRE or JDK\nJRE：Java Runtime Environment，Java 运行环境的简称，为 Java 的运行提供了所需的环境。它是一个 JVM 程序，主要包括了 JVM 的标准实现和一些 Java 基本类库。\nJDK：Java Development Kit，Java 开发工具包，提供了 Java 的开发及运行环境。JDK 是 Java 开发的核心，集成了 JRE 以及一些其它的工具，比如编译 Java 源码的编译器 javac 等。\n\n","slug":"Java/Java 技术栈（基础篇）","date":"2022-02-22T05:32:16.000Z","categories_index":"JAVA","tags_index":"JAVA,Java基础,Spring","author_index":"Anchor"},{"id":"66e250ca52164c88abd86f24f70b74f9","title":"工作流引擎Activiti快速入门","content":"\n\n\n\n\n\n\n\n\nActiviti是一个用Java编写的开源工作流引擎，可以执行BPMN 2.0中描述的业务流程。Activiti流程引擎优势在系统开发的易用性和轻量性上。每一项 BPM 业务功能 Activiti 流程引擎都以服务的形式提供给开发人员。通过使用这些服务，开发人员能够构建出功能丰富、轻便且高效的 BPM 应用程序。\n一、为什么要是用工作流引擎假定我们有一个支付订单状态需要维护，它的状态图如下：它的状态跃迁自左向右，清晰名了，而且没有处理角色的概念，此时我们使用代码控制好状态流转即可，无需使用框架。再来看另外一个场景，假定我们有一个企业内部采购订单，它的状态图如下：\n这个采购订单的状态复杂多变，状态的转换不稳定性很强，随时有可能增加新的状态；而且不同状态的处理人也是不同的，存在权限管理功能，若此时我们仍然使用一个状态字段来维持状态变更，无疑会困难重重。工作流引擎就是为了解决这类问题而生的，我们可以观察当前实体(如支付订单、采购订单)是否具有如下特性，由此来确定是否需要引入工作流引擎。\n\n状态的个数及其稳定性，个数多且不稳定，适合使用工作流引擎。\n每个状态的处理人，处理人角色多且不稳定，适合使用工作流引擎。\n\n工作流引擎实际上是放大了状态管理的功能，它根据既有流程图（基于BPMN2规范）的指示，指定每一次状态跃迁的处理角色，在状态变更时持久化评论、表单、附件等数据，保存了完整处理轨迹。\n\n\n\n\n\n\n\n\n\n工作流引擎 vs 规则引擎\n\n工作流更像是管理状态跃迁的，规则引擎不关心状态跃迁，它关注的是处理过程中复杂条件的组合。\n工作流引擎中包含“人”的任务，天生包含处理人角色控制；规则引擎不关心“人”的任务，不做特殊区分。\n工作流引擎是宏观控制、规则引擎是微观控制。\n\n二、BPMN2.0规范简介业务流程模型和标记法（BPMN, Business Process Model and Notation）是一套图形化表示法，用于以图形的方式详细说明各种业务流程。它最初由业务流程管理倡议组织（BPMI, Business Process Management Initiative）开发，名称为”Business Process Modeling Notation”，即“业务流程建模标记法”。BPMI于2005年与对象管理组织（OMG, Object Management Group）合并。2011年1月OMG发布2.0版本（时至今日，没人会用1.0版本了），同时改为现在的名称。BPMN2.0规范的实现，实质上是一个按照特定规范编写的XML文件，使用特定的BPMN设计器，即可以图形化的形式查看和编辑该文件。Activiti以代码的形式实现了这套图形化表示法，使任务的流转依赖图形，而非具体的实现代码。如上图所示，BPMN2.0规范包含了三个部分Gateway(网关)、Event(事件)、Activities(活动)。\n\n\n\n\n\n\n\n\n\n\n**Gateway(网关)**：exclusiveGateway-排他网关，在做判断时使用，除了排他网关还有几个其它类型的网关。\n**Event(事件)**：startEvent-开始事件、endEvent-结束事件，规范要求一个完整流程图必须包含这两个部分。\n**Activities(活动)**：task-任务、sequenceFlow-连接线，活动是流程的主体部分，内部包含的类型相对较多。\n\n三、Activiti核心API\n\n\n名称\n说明\n\n\n\nProcessEngine\n流程引擎，可以获得其他所有的Service。\n\n\nRepositoryService\nRepository中存储了流程定义文件、部署和支持数据等信息；RepositoryService提供了对repository的存取服务。\n\n\nRuntimeService\n提供启动流程、查询流程实例、设置获取流程实例变量等功能。\n\n\nTaskService\n提供运行时任务查询、领取、完成、删除以及变量设置等功能。\n\n\nHistoryService\n用于获取正在运行或已经完成的流程实例的信息。\n\n\nFormService\n提供定制任务表单和存储表单数据的功能，注意存储表单数据可选的功能，也可以向自建数据表中提交数据。\n\n\nIdentityService\n提供对内建账户体系的管理功能，注意它是可选的服务，可以是用外部账户体系。\n\n\nManagementService\n较少使用，与流程管理无关，主要用于Activiti系统的日常维护。\n\n\n完成一次流程的处理，常见步骤以及他们使用的Service如下图所示：\n1、流程&amp;流程实例流程由遵守BPMN2.0规范的xml文件指定，定义流程即完成流程文件的设计。流程发布后，使用RuntimeService可以开启一个流程实例，每个流程可以开启N次流程实例，且实例之间的数据相互隔离。\n2、用户任务用户任务是BPMN2.0规范中Activities(活动)组件下的重要组成部分，在Activiti中对应Task类；区别于其他类型的任务，用户任务需要进行领取操作，不会自动执行，且领取从待处理任务列表中移除，其他候选人不可见。\n3、用户&amp;角色Activiti中内建了一个简单的账户体系，用户和角色是多对多的关系；IdentityService中提供了对用户、角色操作的API。另外，用户、角色与任务的联系，仅仅通过userId或groupId，不要求必须使用内建账户体系；由于内建的过于简单，开发者完全可以使用自有的账户体系。\n4、受让人、候选人、候选组对用户任务做领取操作(claim)，即指定了该任务的受让人，每个任务只能有一个受让人，不能多次领取（但可以再次转让）。任务的候选人和候选组支持配置多个，目的是指定处理该任务的人，不在候选列表中的人不允许处理该任务。另外，候选人、候选组可以流程文件中指定，也可以在监听事件中动态指定。\n5、变量Activiti支持以key&#x2F;value的形式，对变量做持久化处理。变量通常有两个重要作用：\n\n存储一些跟流程相关的业务数据，例如处理任务时提交的表单数据。\n流程定义文件中，可以通过UEL表达式获取存储的变量，例如，在互斥网关中选择正确的传出顺序流。\n\n6、表单用户处理任务时，通常需要填写备注说明等表单数据，Activiti的FormService对此提供了支持，表单实现如下三种可选的方式：\n\n\n\n名称\n开启方式\n数据存储位置\n\n\n\n动态表单\n流程定义文件中的activiti:formProperty属性\n与变量一样，以key&#x2F;value的形式存储在变量表\n\n\n外置表单\n流程定义文件中的activiti:formkey属性\n与变量一样，以key&#x2F;value的形式存储在变量表\n\n\n普通表单\n脱离Activiti掌控，开发人员自行创建表单和数据表，并使表单和任务关联即可\n任意位置\n\n\n三种方式中，动态表单由于无法指定样式，使用场景不多；外置表单的赋值和提交都依托Activiti引擎。实际使用中主要使用第三种方式普通表单，它的页面渲染赋值都由个人掌控，Activiti仅负责流程流转相关工作，页面渲染部分保持独立会使结构更清晰。\n7、监听器任务执行时，开发者常常需要触发一些自定义的动作，如动态分配候选人、任务结束时发送通知等；Activiti为开发者提供了两种方式来满足此类需求。\n\n执行监听器：监听一组有限的流程执行操作，如start、end和take；\n事件监听器：每当流程实例产生变化时，监听器都能得到通知消息（官方文档）；\n\n四、请假流程实例先上代码，项目Demo：activiti-demo，配置本地正确的数据库链接，然后启动项目，Activiti会自动初始化数据库建表。\n\n\n\n\n\n\n\n\n\nActiviti的表都以act_开头，第二部分是表示表的用途的两个字母缩写标识，用途也和服务的API对应。\n\nact_hi_*：’hi’表示 history，此前缀的表包含历史数据，如历史(结束)流程实例，变量，任务等等。\nact_ge_*：’ge’表示 general，此前缀的表为通用数据，用于不同场景中。\nact_evt_*：’evt’表示 event，此前缀的表为事件日志。\nact_procdef_*：’procdef’表示 processdefine，此前缀的表为记录流程定义信息。\nact_re_*：’re’表示 repository，此前缀的表包含了流程定义和流程静态资源(图片，规则等等)。\nact_ru_*：’ru’表示 runtime，此前缀的表是记录运行时的数据，包含流程实例，任务，变量，异步任务等运行中的数据。Activiti只在流程实例执行过程中保存这些数据，在流程结束时就会删除这些记录。\n\n1、画流程图流程图本质是一个符合BPMN2.0规范的xml文件，由拖拽式的设计软件完成，方式有很多，我在Git上准备的项目中内置了一个Vue版本的流程图设计工具，可以直接使用该模块来制作流程图。\n2、部署流程/**\n     * 流程部署\n     */\n    @Test\n    public void deploy() &#123;\n        RepositoryService repositoryService = processEngine.getRepositoryService();//资源对象\n        Deployment deployment = repositoryService.createDeployment()//创建一个部署对象\n                .name(\"请假流程\")\n                .addClasspathResource(BPMN)\n                .deploy();\n        System.out.println(\"部署ID：\"+deployment.getId());\n        System.out.println(\"部署名称：\"+deployment.getName());\n    &#125;\n3、启动流程/**\n     * 启动流程实例分配任务给个人\n     */\n    @Test\n    public void start() &#123;\n        //脑补一下这个是从前台传过来的数据\n        String userKey=\"张三\";\n        //每一个流程有对应的一个key这个是某一个流程内固定的写在bpmn内的\n        String processDefinitionKey =\"myProcess\";\n        HashMap&lt;String, Object> variables=new HashMap&lt;>();\n        //userKey在上文的流程变量中指定了\n        variables.put(\"userKey\", userKey);\n        variables.put(\"day\", 2);\n        variables.put(\"users\", \"李四\");\n\n        ProcessInstance instance = runtimeService\n                .startProcessInstanceByKey(processDefinitionKey,variables);\n\n        System.out.println(\"流程实例ID:\"+instance.getId());\n        System.out.println(\"流程定义ID:\"+instance.getProcessDefinitionId());\n    &#125;\n4、查询待办/**\n     * 查询当前人的个人任务\n     */\n    @Test\n    public void findTask()&#123;\n        String assignee = \"张三\";\n        List&lt;Task> list = taskService.createTaskQuery().taskAssignee(assignee).orderByTaskCreateTime().desc().list();\n        if(list!=null &amp;&amp; list.size()>0)&#123;\n            for(Task task:list)&#123;\n                System.out.println(\"任务ID:\"+task.getId());\n                System.out.println(\"任务名称:\"+task.getName());\n                System.out.println(\"任务的创建时间:\"+task.getCreateTime());\n                System.out.println(\"任务的办理人:\"+task.getAssignee());\n                System.out.println(\"流程实例ID：\"+task.getProcessInstanceId());\n                System.out.println(\"执行对象ID:\"+task.getExecutionId());\n                System.out.println(\"流程定义ID:\"+task.getProcessDefinitionId());\n                System.out.println(\"getOwner:\"+task.getOwner());\n                System.out.println(\"getCategory:\"+task.getCategory());\n                System.out.println(\"getDescription:\"+task.getDescription());\n                System.out.println(\"getFormKey:\"+task.getFormKey());\n                Map&lt;String, Object> map = task.getProcessVariables();\n                for (Map.Entry&lt;String, Object> m : map.entrySet()) &#123;\n                    System.out.println(\"key:\" + m.getKey() + \" value:\" + m.getValue());\n                &#125;\n                for (Map.Entry&lt;String, Object> m : task.getTaskLocalVariables().entrySet()) &#123;\n                    System.out.println(\"key:\" + m.getKey() + \" value:\" + m.getValue());\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n5、处理待办/**\n     * 完成任务\n     */\n    @Test\n    public void completeTask()&#123;\n        //任务ID\n        String taskId = \"9ac93504-0ef0-11ec-99d7-acde48001122\";\n        HashMap&lt;String, Object> variables=new HashMap&lt;>();\n        variables.put(\"days\", 1);//userKey在上文的流程变量中指定了\n        taskService.complete(taskId,variables);\n        System.out.println(\"完成任务：任务ID：\"+taskId);\n    &#125;\n……….时间有限，更多接口可自行尝试实现\n","slug":"Activiti/工作流引擎Activiti快速入门","date":"2020-06-23T05:32:16.000Z","categories_index":"JAVA","tags_index":"Activiti","author_index":"Anchor"},{"id":"ab7fec85f604492a9899cdf945faa570","title":"Docker 疑难杂症汇总","content":"1. Docker 迁移存储目录默认情况系统会将 Docker 容器存放在 &#x2F;var&#x2F;lib&#x2F;docker 目录下\n\n[问题起因] 今天通过监控系统，发现公司其中一台服务器的磁盘快慢，随即上去看了下，发现 &#x2F;var&#x2F;lib&#x2F;docker 这个目录特别大。由上述原因，我们都知道，在 &#x2F;var&#x2F;lib&#x2F;docker 中存储的都是相关于容器的存储，所以也不能随便的将其删除掉。\n\n那就准备迁移 docker 的存储目录吧，或者对 &#x2F;var 设备进行扩容来达到相同的目的。更多关于 dockerd 的详细参数，请点击查看 官方文档 地址。\n\n但是需要注意的一点就是，尽量不要用软链， 因为一些 docker 容器编排系统不支持这样做，比如我们所熟知的 k8s 就在内。\n# 发现容器启动不了了 \nERROR：cannot  create temporary directory! \n# 查看系统存储情况 \n$ du -h --max-depth=1 \n\n[解决方法 1] 添加软链接\n# 1.停止docker服务 \n$ sudo systemctl stop docker \n# 2.开始迁移目录 \n$ sudo mv /var/lib/docker /data/\n# 3.添加软链接 \n$ sudo ln -s /data/docker /var/lib/docker \n# 4.启动docker服务 \n$ sudo systemctl start docker \n\n[解决方法 2] 改动 docker 配置文件\n# [方式一] 改动docker启动配置文件 \n$ sudo vim /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --graph=/data/docker/ \n# [方式二] 改动docker启动配置文件 \n$ sudo vim /etc/docker/daemon.json &#123;     \"live-restore\": true,     \"graph\": [ \"/data/docker/\" ] &#125; \n\n[操作注意事项] 在迁移 docker 目录的时候注意使用的命令，要么使用 mv 命令直接移动，要么使用 cp 命令复制文件，但是需要注意同时复制文件权限和对应属性，不然在使用的时候可能会存在权限问题。如果容器中，也是使用 root 用户，则不会存在该问题，但是也是需要按照正确的操作来迁移目录。\n# 使用mv命令 \n$ sudo mv /var/lib/docker /data/docker \n# 使用cp命令 \n$ sudo cp -arv /data/docker /data2/docker \n\n因为启动的容器使用的是普通用户运行进程的，且在运行当中需要使用 &#x2F;tmp 目录，结果提示没有权限。在我们导入容器镜像的时候，其实是会将容器启动时需要的各个目录的权限和属性都赋予了。如果我们直接是 cp 命令单纯复制文件内容的话，就会出现属性不一致的情况，同时还会有一定的安全问题。\n\n\n\n2. Docker 设备空间不足Increase Docker container size from default 10GB on rhel7.\n\n[问题起因一] 容器在导入或者启动的时候，如果提示磁盘空间不足的，那么多半是真的因为物理磁盘空间真的有问题导致的。如下所示，我们可以看到 &#x2F; 分区确实满了。\n# 查看物理磁盘空间 \n$ df -Th \nFilesystem    Size    Used    Avail    Use%    Mounted on \n/dev/vda1      40G     40G       0G    100%    / \ntmpfs         7.8G       0     7.8G      0%    /dev/shm \n/dev/vdb1     493G    289G     179G     62%    /mnt \n\n如果发现真的是物理磁盘空间满了的话，就需要查看到底是什么占据了如此大的空间，导致因为容器没有空间无法启动。其中，docker 自带的命令就是一个很好的能够帮助我们发现问题的工具。\n# 查看基本信息 \n# 硬件驱动使用的是devicemapper，空间池为docker-252 \n# 磁盘可用容量仅剩16.78MB，可用供我们使用 \n$ docker info \nContainers: 1 \nImages: 28 \nStorage Driver: devicemapper\n  Pool Name: docker-252:1-787932-pool\n  Pool Blocksize: 65.54 kB\n  Backing Filesystem: extfs\n  Data file: /dev/loop0\n  Metadata file: /dev/loop1\n  Data Space Used: 1.225 GB\n  Data Space Total: 107.4 GB\n  Data Space Available: 16.78 MB\n  Metadata Space Used: 2.073 MB\n  Metadata Space Total: 2.147 GB \n\n[解决方法] 通过查看信息，我们知道正是因为 docker 可用的磁盘空间不足，所以导致启动的时候没有足够的空间进行加载启动镜像。解决的方法也很简单，第一就是清理无效数据文件释放磁盘空间(清除日志)，第二就是修改 docker 数据的存放路径(大分区)。\n# 显示哪些容器目录具有最大的日志文件 \n$ du -d1 -h /var/lib/docker/containers | sort -h \n# 清除您选择的容器日志文件的内容 \n$ cat /dev/null > /var/lib/docker/containers/container_id/container_log_name \n\n\n\n[问题起因二] 显然我遇到的不是上一种情况，而是在启动容器的时候，容器启动之后不久就显示是 unhealthy 的状态，通过如下日志发现，原来是复制配置文件启动的时候，提示磁盘空间不足。\n\n后面发现是因为 CentOS7 的系统使用的 docker 容器默认的创建大小就是 10G 而已，然而我们使用的容器却超过了这个限制，导致无法启动时提示空间不足。\n2019-08-16 11:11:15,816 INFO spawned: 'app-demo' with pid 835 \n2019-08-16 11:11:16,268 INFO exited: app (exit status 1; not expected) \n2019-08-16 11:11:17,270 INFO gave up: app entered FATAL state, too many start retries too quickly \ncp: cannot create regular file '/etc/supervisor/conf.d/grpc-app-demo.conf': No space left on device \ncp: cannot create regular file '/etc/supervisor/conf.d/grpc-app-demo.conf': No space left on device \ncp: cannot create regular file '/etc/supervisor/conf.d/grpc-app-demo.conf': No space left on device \ncp: cannot create regular file '/etc/supervisor/conf.d/grpc-app-demo.conf': No space left on device \n\n[解决方法 1] 改动 docker 启动配置文件\n# /etc/docker/daemon.json \n&#123;     \n  \"live-restore\": true,     \n  \"storage-opt\": [ \"dm.basesize=20G\" ] \n&#125; \n\n[解决方法 2] 改动 systemctl 的 docker 启动文件\n# 1.stop the docker service \n$ sudo systemctl stop docker \n# 2.rm exised container \n$ sudo rm -rf /var/lib/docker \n# 2.edit your docker service file \n$ sudo vim /usr/lib/systemd/system/docker.service \n# 3.find the execution line\n ExecStart=/usr/bin/dockerd \nand change it to: \nExecStart=/usr/bin/dockerd --storage-opt dm.basesize=20G \n# 4.start docker service again \n$ sudo systemctl start docker \n# 5.reload daemon \n$ sudo systemctl daemon-reload \n\n\n\n[问题起因三] 还有一种情况也会让容器无法启动，并提示磁盘空间不足，但是使用命令查看发现并不是因为物理磁盘真的不足导致的。而是，因为对于分区的 inode 节点数满了导致的。\n# 报错信息 No space left on device \n\n[解决方法] 因为 ext3 文件系统使用 inode table 存储 inode 信息，而 xfs 文件系统使用 B+ tree 来进行存储。考虑到性能问题，默认情况下这个 B+ tree 只会使用前 1TB 空间，当这 1TB 空间被写满后，就会导致无法写入 inode 信息，报磁盘空间不足的错误。我们可以在 mount 时，指定 inode64 即可将这个 B+ tree 使用的空间扩展到整个文件系统。\n# 查看系统的inode节点使用情况 \n$ sudo df -i \n# 尝试重新挂载 \n$ sudo mount -o remount -o noatime,nodiratime,inode64,nobarrier /dev/vda1 \n\n[补充知识] 文件储存在硬盘上，硬盘的最小存储单位叫做 扇区(Sector)。每个扇区储存 512 字节(相当于0.5KB)。操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个块(block)。这种由多个扇区组成的块，是文件存取的最小单位。块的大小，最常见的是4KB，即连续八个 sector 组成一个 block 块。文件数据都储存在块中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做索引节点(inode)。每一个文件都有对应的 inode，里面包含了除了文件名以外的所有文件信息。\n\ninode 也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是 inode 区(inode table)，存放 inode 所包含的信息。每个 inode 节点的大小，一般是 128 字节或 256 字节。inode 节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个 inode 节点。\n# 每个节点信息的内容 \n$ stat check_port_live.sh \n   File: check_port_live.sh\n   Size: 225           Blocks: 8          IO Block: 4096   regular file \nDevice: 822h/2082d    Inode: 99621663    Links: 1 \nAccess: (0755/-rwxr-xr-x)  Uid: ( 1006/  escape)   Gid: ( 1006/  escape) \nAccess: 2019-07-29 14:59:59.498076903 +0800 \nModify: 2019-07-29 14:59:59.498076903 +0800 \nChange: 2019-07-29 23:20:27.834866649 +0800  \n  Birth: - \n# 磁盘的inode使用情况 \n$ df -i Filesystem                 Inodes   IUsed     IFree IUse% Mounted on \nudev                     16478355     801  16477554    1% /dev \ntmpfs                    16487639    2521  16485118    1% /run \n/dev/sdc2               244162560 4788436 239374124    2% / \ntmpfs                    16487639       5  16487634    1% /dev/shm \n\n\n3. Docker 缺共享链接库Docker 命令需要对&#x2F;tmp 目录下面有访问权限\n\n[问题起因] 给系统安装完 compose 之后，查看版本的时候，提示缺少一个名为 libz.so.1 的共享链接库。第一反应就是，是不是系统少安装那个软件包导致的。随即，搜索了一下，将相关的依赖包都给安装了，却还是提示同样的问题。\n# 提示错误信息 \n$ docker-compose --version \nerror while loading shared libraries: libz.so.1: failed to map segment from shared object: Operation not permitted \n\n[解决方法] 后来发现，是因为系统中 docker 没有对 &#x2F;tmp 目录的访问权限导致，需要重新将其挂载一次，就可以解决了。\n# 重新挂载 \n$ sudo mount /tmp -o remount,exec \n\n\n4. Docker 容器文件损坏对 dockerd 的配置有可能会影响到系统稳定\n\n[问题起因] 容器文件损坏，经常会导致容器无法操作。正常的 docker 命令已经无法操控这台容器了，无法关闭、重启、删除。正巧，前天就需要这个的问题，主要的原因是因为重新对 docker 的默认容器进行了重新的分配限制导致的。\n# 操作容器遇到类似的错误 \nb'devicemapper: Error running deviceCreate (CreateSnapDeviceRaw) dm_task_run failed' \n\n[解决方法] 可以通过以下操作将容器删除&#x2F;重建。\n# 1.关闭docker \n$ sudo systemctl stop docker \n# 2.删除容器文件 \n$ sudo rm -rf /var/lib/docker/containers\n # 3.重新整理容器元数据 \n$ sudo thin_check /var/lib/docker/devicemapper/devicemapper/metadata \n$ sudo thin_check --clear-needs-check-flag /var/lib/docker/devicemapper/devicemapper/metadata\n# 4.重启docker \n$ sudo systemctl start docker \n\n\n5. Docker 容器优雅重启不停止服务器上面运行的容器，重启 dockerd 服务是多么好的一件事\n\n[问题起因] 默认情况下，当 Docker 守护程序终止时，它会关闭正在运行的容器。从 Docker-ce 1.12 开始，可以在配置文件中添加 live-restore 参数，以便在守护程序变得不可用时容器保持运行。需要注意的是 Windows 平台暂时还是不支持该参数的配置。\n# Keep containers alive during daemon downtime \n$ sudo vim /etc/docker/daemon.yaml \n&#123;  \n \"live-restore\": true \n&#125; \n# 在守护进程停机期间保持容器存活 \n$ sudo dockerd --live-restore \n# 只能使用reload重载 #\n 相当于发送SIGHUP信号量给dockerd守护进程 \n$ sudo systemctl reload docker \n# 但是对应网络的设置需要restart才能生效 \n$ sudo systemctl restart docker \n\n[解决方法] 可以通过以下操作将容器删除&#x2F;重建。\n\n\njson\n# /etc/docker/daemon.yaml\n&#123;\n    \"registry-mirrors\": [\"https://vec0xydj.mirror.aliyuncs.com\"],  # 配置获取官方镜像的仓库地址\n    \"experimental\": true,  # 启用实验功能\n    \"default-runtime\": \"nvidia\",  # 容器的默认OCI运行时(默认为runc)\n    \"live-restore\": true,  # 重启dockerd服务的时候容易不终止\n    \"runtimes\": &#123;  # 配置容器运行时\n        \"nvidia\": &#123;\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        &#125;\n    &#125;,\n    \"default-address-pools\": [  # 配置容器使用的子网地址池\n        &#123;\n            \"scope\": \"local\",\n            \"base\":\"172.17.0.0/12\",\n            \"size\":24\n        &#125;\n    ]\n&#125;\n\n$ vim /etc/docker/daemon.json\n&#123;\n  \"default-address-pools\" : [\n    &#123;\n      \"base\" : \"172.240.0.0/16\",\n      \"size\" : 24\n    &#125;\n  ]\n&#125;\n\n\n6. Docker 容器无法删除找不到对应容器进程是最吓人的\n\n[问题起因] 今天遇到 docker 容器无法停止&#x2F;终止&#x2F;删除，以为这个容器可能又出现了 dockerd 守护进程托管的情况，但是通过 ps -ef  无法查到对应的运行进程。哎，后来开始开始查 supervisor 以及 Dockerfile 中的进程，都没有。这种情况的可能原因是容器启动之后，主机因任何原因重新启动并且没有优雅地终止容器。剩下的文件现在阻止你重新生成旧名称的新容器，因为系统认为旧容器仍然存在。\n# 删除容器\n$ sudo docker rm -f f8e8c3..\nError response from daemon: Conflict, cannot remove the default name of the container\n\n[解决方法] 找到 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F; 下的对应容器的文件夹，将其删除，然后重启一下 dockerd 即可。我们会发现，之前无法删除的容器没有了。\n# 删除容器文件\n$ sudo rm -rf /var/lib/docker/containers/f8e8c3...65720\n\n# 重启服务\n$ sudo systemctl restart docker.service\n\n\n7. Docker 容器中文异常容器存在问题话，记得优先在官网查询\n\n[问题起因] 今天登陆之前部署的 MySQL 数据库查询，发现使用 SQL 语句无法查询中文字段，即使直接输入中文都没有办法显示。\n# 查看容器支持的字符集\nroot@b18f56aa1e15:# locale -a\nC\nC.UTF-8\nPOSIX\n\n[解决方法] Docker 部署的 MySQL 系统使用的是 POSIX 字符集。然而 POSIX 字符集是不支持中文的，而 C.UTF-8 是支持中文的只要把系统中的环境 LANG 改为 “C.UTF-8” 格式即可解决问题。同理，在 K8S 进入 pod 不能输入中文也可用此方法解决。\n# 临时解决\ndocker exec -it some-mysql env LANG=C.UTF-8 /bin/bash\n# 永久解决\ndocker run --name some-mysql \\\n    -e MYSQL_ROOT_PASSWORD=my-secret-pw \\\n    -d mysql:tag --character-set-server=utf8mb4 \\\n    --collation-server=utf8mb4_unicode_ci\n\n\n8. Docker 容器网络互通了解 Docker 的四种网络模型\n\n[问题起因] 在本机部署 Nginx 容器想代理本机启动的 Python 后端服务程序，但是对代码服务如下的配置，结果访问的时候一直提示 502 错误。\n# 启动Nginx服务\n$ docker run -d -p 80:80 $PWD:/etc/nginx nginx\nserver &#123;\n    ...\n    location /api &#123;\n        proxy_pass http://localhost:8080\n    &#125;\n    ...\n&#125;\n\n[解决方法] 后面发现是因为 nginx.conf 配置文件中的 localhost 配置的有问题，由于 Nginx 是在容器中运行，所以 localhost 为容器中的 localhost，而非本机的 localhost，所以导致无法访问。\n\n可以将 nginx.conf 中的 localhost 改为宿主机的 IP 地址，就可以解决 502 的错误。\n# 查询宿主机IP地址 => 172.17.0.1\n$ ip addr show docker0\ndocker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:d5:4c:f2:1e brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:d5ff:fe4c:f21e/64 scope link\n       valid_lft forever preferred_lft forever\nserver &#123;\n    ...\n    location /api &#123;\n        proxy_pass http://172.17.0.1:8080\n    &#125;\n    ...\n&#125;\n\n当容器使用 host 网络时，容器与宿主共用网络，这样就能在容器中访问宿主机网络，那么容器的 localhost 就是宿主机的 localhost 了。\n# 服务的启动方式有所改变(没有映射出来端口)\n# 因为本身与宿主机共用了网络，宿主机暴露端口等同于容器中暴露端口\n$ docker run -d -p 80:80 --network=host $PWD:/etc/nginx nginxx\n\n\n9. Docker 容器总线错误总线错误看到的时候还是挺吓人了\n\n[问题起因] 在 docker 容器中运行程序的时候，提示 bus error 错误。\n# 总线报错\n$ inv app.user_op --name=zhangsan\nBus error (core dumped)\n\n[解决方法] 原因是在 docker 运行的时候，shm 分区设置太小导致 share memory 不够。不设置 –shm-size 参数时，docker 给容器默认分配的 shm 大小为 64M，导致程序启动时不足。具体原因还是因为安装 pytorch 包导致了，多进程跑任务的时候，docker 容器分配的共享内存太小，导致 torch 要在 tmpfs 上面放模型数据用于子线程的 共享不足，就出现报错了。\n# 问题原因\nroot@18...35:/opt/app# df -TH\nFilesystem     Type     Size  Used Avail Use% Mounted on\noverlay        overlay  2.0T  221G  1.4T   3% /\ntmpfs          tmpfs     68M     0   68M   0% /dev\nshm            tmpfs     68M   41k   68M   1% /dev/shm\n\n# 启动docker的时候加上--shm-size参数(单位为b,k,m或g)\n$ docker run -it --rm --shm-size=200m pytorch/pytorch:latest\n\n# 在docker-compose添加对应配置\n$ shm_size: '2gb'\n\n[解决方法] 还有一种情况就是容器内的磁盘空间不足，也会导致 bus error 这样的报错，所以如果出现了，清除多余文件和目录或者分配一个大的磁盘空间，就可以解决了。\n# 磁盘空间不足\n$ df -Th\nFilesystem     Type     Size  Used Avail Use% Mounted on\noverlay        overlay    1T    1T    0G 100% /\nshm            tmpfs     64M   24K   64M   1% /dev/shm\n\n\n10. Docker NFS 挂载报错NFS 挂载之后容器程序使用异常为内核版本太低导致的\n\n[问题起因] 我们将服务部署到 openshift 集群中，启动服务调用资源文件的时候，报错信息如下所示。从报错信息中，得知是在 Python3 程序执行 read_file() 读取文件的内容，给文件加锁的时候报错了。但是奇怪的是，本地调试的时候发现服务都是可以正常运行的，文件加锁也是没问题的。后来发现，在 openshift 集群中使用的是 NFS 挂载的共享磁盘。\n# 报错信息\nTraceback (most recent call last):\n    ......\n    File \"xxx/utils/storage.py\", line 34, in xxx.utils.storage.LocalStorage.read_file\nOSError: [Errno 9] Bad file descriptor\n# 文件加锁代码\n...\n    with open(self.mount(path), 'rb') as fileobj:\n        fcntl.flock(fileobj, fcntl.LOCK_EX)\n        data = fileobj.read()\n    return data\n...\n\n[解决方法] 从下面的信息得知，要在 Linux 中使用 flock() 的话，就需要升级内核版本到 2.6.11+ 才行。后来才发现，这实际上是由 RedHat 內核中的一个错误引起的，并在 kernel-3.10.0-693.18.1.el7 版本中得到修复。 所以对于 NFSv3 和 NFSv4 服务而已，就需要升级 Linux 内核版本才能够解决这个问题。\n# https://t.codebug.vip/questions-930901.htm\n$ In Linux kernels up to 2.6.11, flock() does not lock files over NFS (i.e.,\nthe scope of locks was limited to the local system). [...] Since Linux 2.6.12,\nNFS clients support flock() locks by emulating them as byte-range locks on the entire file.\n\n\n11. Docker 使用默认网段启动的容器网络无法相互通信，很是奇怪！\n\n[问题起因] 我们在使用 Docker 启动服务的时候，发现有时候服务之前可以相互连通，而有时启动的多个服务之前却出现了无法访问的情况。究其原因，发现原来是因为使用的内部私有地址网段不一致导致的。有的服务启动到了 172.17 - 172.31 的网段，有的服务跑到了 192.169.0 - 192.168.224 的网段，这样导致服务启动之后出现无法访问的情况(默认情况下，有下面这个两个网段可供其使用)。Docker默认使用网段\n\n[解决方法] 上述问题的处理方式，就是手动指定 Docker 服务的启动网段，二选一就可以了。\n# 查看docker容器配置\n$ cat /etc/docker/daemon.json\n&#123;\n    \"registry-mirrors\": [\"https://vec0xydj.mirror.aliyuncs.com\"],\n    \"default-address-pools\":[&#123;\"base\":\"172.17.0.0/12\", \"size\":24&#125;],\n    \"experimental\": true,\n    \"default-runtime\": \"nvidia\",\n    \"live-restore\": true,\n    \"runtimes\": &#123;\n        \"nvidia\": &#123;\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        &#125;\n    &#125;\n&#125;\n\n\n12. Docker 服务启动串台使用 docker-compose 命令各自启动两组服务，发现服务会串台！\n\n[问题起因] 在两个不同名称的目录目录下面，使用 docker-compose 来启动服务，发现当 A 组服务启动完毕之后，再启动 B 组服务的时候，发现 A 组当中对应的一部分服务又重新启动了一次，这就非常奇怪了！因为这个问题的存在会导致，A 组服务和 B 组服务无法同时启动。之前还以为是工具的 Bug，后来请教了 “上峰”，才知道了原因，恍然大悟。\n# 服务目录结构如下所示\nA: /data1/app/docker-compose.yml\nB: /data2/app/docker-compose.yml\n\n[解决方法] 发现 A 和 B 两组服务会串台的原因，原来是 docker-compose 会给启动的容器加 label 标签，然后根据这些 label 标签来识别和判断对应的容器服务是由谁启动的、谁来管理的，等等。而这里，我们需要关注的 label 变量是 com.docker.compose.project，其对应的值是使用启动配置文件的目录的最底层子目录名称，即上面的 app 就是对应的值。我们可以发现， A 和 B 两组服务对应的值都是 app，所以启动的时候被认为是同一个，这就出现了上述的问题。如果需要深入了解的话，可以去看对应源代码。Docker服务启动串台\n# 可以将目录结构调整为如下所示\nA: /data/app1/docker-compose.yml\nB: /data/app2/docker-compose.yml\n\nA: /data1/app-old/docker-compose.yml\nB: /data2/app-new/docker-compose.yml\n\n或者使用 docker-compose 命令提供的参数 -p 手动指定标签，来规避该问题的发生。\n# 指定项目项目名称\n$ docker-compose -f ./docker-compose.yml -p app1 up -d\n\n\n13. Docker 命令调用报错在编写脚本的时候常常会执行 docker 相关的命令，但是需要注意使用细节！\n\n[问题起因] CI 更新环境执行了一个脚本，但是脚本执行过程中报错了，如下所示。通过对应的输出信息，可以看到提示说正在执行的设备不是一个 tty。Docker命令调用报错\n\n随即，查看了脚本发现报错地方是执行了一个 exec 的 docker 命令，大致如下所示。很奇怪的是，手动执行或直接调脚本的时候，怎么都是没有问题的，但是等到 CI 调用的时候怎么都是有问题。后来好好看下，下面这个命令，注意到 -it 这个参数了。\n# 脚本调用docker命令\ndocker exec -it &lt;container_name> psql -Upostgres ......\n\n我们可以一起看下 exec 命令的这两个参数，自然就差不多理解了。\n\n\n\n编号\n参数\n解释说明\n\n\n\n1\n-i&#x2F;-interactive\n即使没有附加也保持 STDIN 打开；如果你需要执行命令则需要开启这个选项\n\n\n2\n-t&#x2F;–tty\n分配一个伪终端进行执行；一个连接用户的终端与容器 stdin 和 stdout 的桥梁\n\n\n\n[解决方法] docker exec 的参数 -t 是指 Allocate a pseudo-TTY 的意思，而 CI 在执行 job 的时候并不是在 TTY 终端中执行，所以 -t 这个参数会报错。同时在 『stackoverflow』也有人给出原因，可以自行查看。Docker命令调用报错\n\n\n\n14. Docker 定时任务异常在 Crontab 定时任务中也存在 Docker 命令执行异常的情况！\n\n[问题起因] 今天发现了一个问题，就是在备份 Mysql 数据库的时候，使用 docker 容器进行备份，然后使用 Crontab 定时任务来触发备份。但是发现备份的 MySQL 数据库居然是空的，但是手动执行对应命令切是好的，很奇怪。\n# Crontab定时任务\n0 */6 * * * \\\n    docker exec -it &lt;container_name> sh -c \\\n        'exec mysqldump --all-databases -uroot -ppassword ......'\n\n[解决方法] 后来发现是因为执行的 docker 命令多个 -i 导致的。因为 Crontab 命令执行的时候，并不是交互式的，所以需要把这个去掉才可以。总结就是，如果你需要回显的话则需要 -t 选项，如果需要交互式会话则需要 -i 选项。\n\n\n\n编号\n参数\n解释说明\n\n\n\n1\n-i&#x2F;-interactive\n即使没有附加也保持 STDIN 打开；如果你需要执行命令则需要开启这个选项\n\n\n2\n-t&#x2F;–tty\n分配一个伪终端进行执行；一个连接用户的终端与容器 stdin 和 stdout 的桥梁\n\n\n\n\n\n15. Docker 变量使用引号compose 里边环境变量带不带引号的问题！\n\n[问题起因] 使用过 compose 的朋友可能都遇到过，在编写启服务启动配置文件的时候，添加环境变量时到底是使用单引号、双引号还是不使用引号的问题？时间长了，我们可能会将三者混用，认为其效果是一样的。但是后来，发现的坑越来越多，才发现其越来越隐晦。\n\n反正我是遇到过很多问题，都是因为添加引号导致的服务启动异常的，后来得出的结论就是一律不使引号。裸奔，体验前所未有的爽快！直到现在看到了 Github 中对应的 issus 之后，才终于破案了。\n# 在Compose中进行引用TEST_VAR变量，无法找到\nTEST_VAR=\"test\"\n\n# 在Compose中进行引用TEST_VAR变量，可以找到\nTEST_VAR=test\n\n# 后来发现docker本身其实已经正确地处理了引号的使用\ndocker run -it --rm -e TEST_VAR=\"test\" test:latest\n\n[解决方法] 得到的结论就是，因为 Compose 解析 yaml 配置文件，发现引号也进行了解释包装。这就导致原本的 TEST_VAR&#x3D;”test” 被解析成了 ‘TEST_VAR&#x3D;”test”‘，所以我们在引用的时候就无法获取到对应的值。现在解决方法就是，不管是我们直接在配置文件添加环境变量或者使用 env_file 配置文件，能不使用引号就不适用引号。\n\n需要注意的是环境变量配置的是日志格式的话(2022-01-01)，如果使用的是 Python 的 yaml.load 模块的话，会被当做是 date 类型的，这是如果希望保持原样信息的话，可以使用 ‘&#x2F;“ 引起来将其变成字符串格式的。\n\n\n\n16. Docker 删除镜像报错无法删除镜像，归根到底还是有地方用到了！\n\n[问题起因] 清理服器磁盘空间的时候，删除某个镜像的时候提示如下信息。提示需要强制删除，但是发现及时执行了强制删除依旧没有效果。\n# 删除镜像\n$ docker rmi 3ccxxxx2e862\nError response from daemon: conflict: unable to delete 3ccxxxx2e862 (cannot be forced) - image has dependent child images\n\n# 强制删除\n$ dcoker rmi -f 3ccxxxx2e862\nError response from daemon: conflict: unable to delete 3ccxxxx2e862 (cannot be forced) - image has dependent child images\n\n[解决方法] 后来才发现，出现这个原因主要是因为 TAG，即存在其他镜像引用了这个镜像。这里我们可以使用如下命令查看对应镜像文件的依赖关系，然后根据对应 TAG 来删除镜像。\n# 查询依赖 - image_id表示镜像名称\n$ docker image inspect --format='&#123;&#123;.RepoTags&#125;&#125; &#123;&#123;.Id&#125;&#125; &#123;&#123;.Parent&#125;&#125;' $(docker image ls -q --filter since=&lt;image_id>)\n\n# 根据TAG删除镜像\n$ docker rmi -f c565xxxxc87f\n# 删除悬空镜像\n$ docker rmi $(docker images --filter \"dangling=true\" -q --no-trunc)\n\n\n17. Docker 普通用户切换切换 Docker 启动用户的话，还是需要注意下权限问题的！\n\n[问题起因] 我们知道在 Docker 容器里面使用 root 用户的话，是不安全的，很容易出现越权的安全问题，所以一般情况下，我们都会使用普通用户来代替 root 进行服务的启动和管理的。今天给一个服务切换用户的时候，发现 Nginx 服务一直无法启动，提示如下权限问题。因为对应的配置文件也没有配置 var 相关的目录，无奈 🤷‍♀ ！️\n# Nginx报错信息\nnginx: [alert] could not open error log file: open() \"/var/log/nginx/error.log\" failed (13: Permission denied)\n2020/11/12 15:25:47 [emerg] 23#23: mkdir() \"/var/cache/nginx/client_temp\" failed (13: Permission denied)\n\n[解决方法] 后来发现还是 nginx.conf 配置文件，配置的有问题，需要将 Nginx 服务启动时候需要的文件都配置到一个无权限的目录，即可解决。\nuser  www-data;\nworker_processes  1;\n\nerror_log  /data/logs/master_error.log warn;\npid        /dev/shm/nginx.pid;\n\nevents &#123;\n    worker_connections  1024;\n&#125;\n\nhttp &#123;\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    gzip               on;\n    sendfile           on;\n    tcp_nopush         on;\n    keepalive_timeout  65;\n\n    client_body_temp_path  /tmp/client_body;\n    fastcgi_temp_path      /tmp/fastcgi_temp;\n    proxy_temp_path        /tmp/proxy_temp;\n    scgi_temp_path         /tmp/scgi_temp;\n    uwsgi_temp_path        /tmp/uwsgi_temp;\n\n    include /etc/nginx/conf.d/*.conf;\n&#125;\n\n\n18. Docker 绑定到 IPv6 上Docker 服务在启动的时候，将地址绑定到 IPv6 地址上面了，提示报错信息！\n\n[问题起因] 物理机器更新了对应补丁之后，重启了服务，导致原本可以正常启动的 docker-compose 服务提示如下报错信息。不清楚是否修改了操作系统的相关配置，还是对应 docker 进行的其他方面的配置，比如修改 &#x2F;etc&#x2F;docker&#x2F;daemon.json 或者 docker 的 service 启动文件。\n# Docker的报错信息\ndocker run -p 80:80 nginx:alpine succeeds. Previously, this was failing with Error \\\nstarting userland proxy: listen tcp6 [::]:80: socket: address family not supported by protocol.\n\n[解决方法] 通过如上所示的报错信息，可以看到服务的启动端口绑定到了 tcp6 上面了，但是对应的 socket 发现系统本身并不支持。这时，我们一看下对应的操作系统 ipv6 的设置，发现系统禁用了，所有的 ipv6 地址。需要了解的朋友，可以参考 fix port forwarding with ipv6.disable&#x3D;1 和 cannot start if ipv6 is disabled on host 这两个 issus 来获取更多信息。\n# 操作系统配置\n$ cat /etc/sysctl.conf | grep ipv6\nnet.ipv6.conf.all.disable_ipv6=1\n\n[方法一] 最为简单的解决方法，就是在 docker-compose.yml 文件中，手动指定将对应服务的端口绑定到 ipv4 上面，如下所示。\nversion: \"3\"\n\nservices:\n  app:\n    restart: on-failure\n    container_name: app_web\n    image: app:latest\n    ports:\n      - \"0.0.0.0:80:80/tcp\"\n    volumes:\n      - \"./app_web:/data\"\n    networks:\n      - app_network\n\n[方法二] 或者修改 &#x2F;etc&#x2F;docker&#x2F;daemon.json 文件，在配置中，阻止 Docker 错误的将端口映射到 IPv6 上，即可达到同样的效果，且不用再次修改多个服务的启动配置文件了。\n# 修改配置\n$ vim /etc/docker/daemon.json\n&#123;\n  \"ipv6\": false,\n  \"fixed-cidr-v6\": \"2001:db8:1::/64\"\n&#125;\n\n# 重启服务\n$ systemctl reload docker\n\n[方法三] Docker 默认情况下会同时将端口映射于 IPv4 与 IPv6 两者上，而且有的时候会出现只绑定到了 IPv6，导致服务无法正常访问的情况。现在通用的始终还是 IPv4 地址，因此最简单的做法就是关闭 IPv6 地址。详细的配置，可以参考 Port redirecting binding to IPv6 but not IPv4 interfaces 这个 issus 地址。\n# 修改系统配置\necho '1' > /proc/sys/net/ipv6/conf/lo/disable_ipv6\necho '1' > /proc/sys/net/ipv6/conf/lo/disable_ipv6\necho '1' > /proc/sys/net/ipv6/conf/all/disable_ipv6\necho '1' > /proc/sys/net/ipv6/conf/default/disable_ipv6\n\n# 重启网络\n$ /etc/init.d/networking restart\n\n# 最后检测是否已关闭IPv6\nip addr show | grep net6\n\n\n19. Docker 容器启动超时Docker 服务在启动的时候，提示超时，被直接终止了！\n\n[问题起因] 使用 docker-compose 启动容器的时候，等待了很久的时候(大约 2-3 分钟左右)，之后提示如下信息。通过阅读信息内容，可以看到是因为超时导致的，提示可以通过设置环境变量，加大超时的时间。\n$ docker-compose up -d\nERROR: for xxx  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=70)\nERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information.\nIf you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).\n\n[解决方法] 按照提示设置的环境变量之后，再次启动发现确实可以正常启动了，但是还是能够感觉到有些慢。\n$ sudo vim /etc/profile\nexport COMPOSE_HTTP_TIMEOUT=500\nexport DOCKER_CLIENT_TIMEOUT=500\n\n排除了下启动流程，因为容器启动有映射目录到容器里面且目录大小比较大，所以怀疑是因为 i&#x2F;o 导致的。随即使用 iotop 命令查看服务器目前的 i&#x2F;o 情况，发现存在很多个 rg 命令，且都处于 100% 左右。查了下，发现是 vscode 远程服务器启动的搜索目录结构的进程，西八，有些坑呀！\n$ sudo iotop\n 4269 be/4 escape     15.64 K/s    0.00 B/s  0.00 % 98.36 % rg --files --hidden\n 4270 be/4 escape     28.15 K/s    0.00 B/s  0.00 % 97.46 % rg --files --hidden\n 4272 be/4 escape     31.27 K/s    0.00 B/s  0.00 % 97.39 % rg --files --hidden\n 4276 be/4 escape     34.40 K/s    0.00 B/s  0.00 % 96.98 % rg --files --hidden\n\n\n20. Docker 端口网络限制如果发现服务都一切正常，但是无法无法访问的话，则多为网络问题！\n\n[问题起因] 启用服务之后，登录跳转发现直接 502 报错了。排除了配置等相关原因都没有任何问题(做过相关测试)，这就非常奇怪了！\n# 部署服务架构\nnginx(80) -> web1(8080)\n          -> web2(8081)\n\n# 报错信息如下所示\nnginx connect() failed (113: No route to host) while connecting to upstream\n\n[解决方法] 根据错误信息可知，是因为没有路由到指定的 host 导致了，随即看了下防火墙是开着的，看了日志发现被过滤掉了，西八！问题找到了，现在需要做的就是，要么添加防火墙规则，要么关闭防火墙。\n# 检查开放的端口\n$ sudo firewall-cmd --permanent --zone=public --list-ports\n\n# 开启需要路由的端口\n$ sudo firewall-cmd --permanent --zone=public --add-port=8080/tcp\n$ sudo firewall-cmd --permanent --zone=public --add-port=8081/tcp\n\n# 配置立即生效\nfirewall-cmd --reload\n# 关闭防火墙\n$ sudo systemctl stop firewalld.service\n\n# 禁用自启动\n$ sudo systemctl disable firewalld.service\n\n\n21. Docker 无法获取镜像新初始化的机器，无法获取私有仓库的镜像文件！\n\n[问题起因] 机器初始化之后，使用如下命令登录私有 docker 仓库，发现提示无法获取对应镜像，但是在其他机器上面获取该镜像就可以执行成功，这就非常奇怪了！\n# 登录私有仓库\n$ echo '123456' | docker login -u escape --password-stdin docker.escapelife.site\n\n# 异常信息提示\n$ sudo docker pull docker.escapelife.site/app:0.10\nError response from daemon: manifest for docker.escapelife.site/app:0.10 not found: manifest unknown: manifest unknown\n\n[解决方法] 太坑了，我还以为我发现某个隐藏的 bug 了，可劲的排查，最后发现，原来是自己镜像包名字写错了，应该写成 0.0.10 的，自己却写成了 0.10。这里，纪念一下，以后碰到上述报错，那肯定是镜像不存在的。\n# 登录私有仓库之后会在用户家目录下生成一个docker配置\n# 其用来记录docker私有仓库的登录认证信息(是加密过的信息但不安全) => base64\n$ cat .docker/config.json\n&#123;\n    \"auths\": &#123;\n        \"docker.escapelife.site\": &#123;\n            \"auth\": \"d00u11Fu22B3355VG2xasE12w==\"\n        &#125;\n    &#125;\n&#125;\n\n\n22. Docker 使容器不退出如何使使用 docker-compose 启动的容器服务 hang 住而不退出\n\n[问题起因] 有时候我们启动的服务，因为某些问题(bug)导致服务无法正常启动，就会出现容器无限重启(restart: on-failure)的情况，这时就很不利于排除问题。\n➜ docker ps -a\n4e6xxx9a4   app:latest   \"/xxx/…\"   26 seconds ago   Restarting (1) 2 seconds ago\n\n[解决方法] 这时我们就需要根据，服务构建使用命令来决定是用什么命令来 hang 住服务。卡住的原理，就类似于使用 &#x2F;bin&#x2F;bash 进入容器是一样的，这里我就不过多解释了。\n# 类似原理\ndocker run -it --rm --entrypoint=/bin/bash xxx/app:latest\n\n# 使用Command命令\ntty: true\ncommand: tail -f /dev/null\n\n# 使用Entrypoint命令\ntty: true\nentrypoint: tail -f /dev/null\n\n同理，我们在使用 docker-compose 或者 k8s 平台部署服务的时候，也有时会因为启动问题需要，使启动的服务不直接退出，来手动调试和排查问题原因。所以，我这里记录下其不同部署方式的，暂停方式。\n# Compose\n\nversion: \"3\"\nservices:\n  app:\n    image: ubuntu:latest\n    tty: true\n    entrypoint: /usr/bin/tail\n    command: \"-f /dev/null\"\n# K8S\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntu\nspec:\n  containers:\n    - name: ubuntu\n      image: ubuntu:latest\n      command: [\"/bin/bash\", \"-c\", \"--\"]\n      args: [\"while true; do sleep 30; done;\"]\n      # command: [\"sleep\"]\n      # args: [\"infinity\"]\n\n\n23. Docker 不使用默认网段有些情况，内部规划的网段和可能和 Dockerd 默认的网段有冲突，导致异常出现！\n\n[问题起因] 今天在新机器上面，部署了一整套服务(多台机器)，服务部署完毕之后，通过前置 Nginx 服务发现并不能访问，后置机器开放的端口，发现发到对应端口的请求都没有转发出去。这就比较奇怪了，因为端口控制是已经开通了的，不应该出现不通的情况。\n➜ nc -v 172.16.100.12 8000\nnc: connect to 172.16.100.12 port 8000 (tcp) failed: Connection refused\n\n[解决方法] 发现服务器端口不通，我这里怀疑可能是 dockerd 服务启动导致的，所以我先将服务都停掉，直接在机器上面启动了 Python 的服务端程序(Linux 机器自带 Python2.7.x 的版本)，然后在前置 Nginx 服务发现，端口确实是通的。后来，排除发现是内部服务默认网段和 dockerd 服务启动的默认网段是冲突的，导致重写了机器的防火墙规则，导致出现上述异常的。\n$ python -m SimpleHTTPServer 8000\nServing HTTP on 0.0.0.0 port 8000 ...\n\n➜ nc -v 172.16.100.12 8000\nConnection to 172.16.100.12 8000 port [tcp/*] succeeded!\n\n既然问题已经知道了，现在需要做的就是非常简单了：不适用默认网段！通过 『mirantis』 里面，我们可以选择进行设置，然后重启服务 dockerd 服务，即可。\n# 修改配置\n$ sudo cat /etc/docker/daemon.json\n&#123;\n  \"default-address-pools\":[&#123;\"base\":\"192.168.100.0/20\",\"size\":24&#125;]\n&#125;\n\n# 重启服务\n$ sudo systemctl restart docker\n\n# 启动服务验证是否生效\n$ ip a\n$ docker network inspect app | grep Subnet\nDocker 不使用默认网段\n\n这时，就到了考验我们网络的子网划分的能力了：如何在给定的网段下面合理且高效的进行划分呢？咳咳，确实难倒我了，这时我们可以再这个在线网站上面 JSON 在线解析 进行划分，然后选定合理的 base 和 size 就可以了。\n# 报错信息\nError response from daemon: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network\n\n# 按照下图我们可以对 pool 进行合理划分\n# 给定 10.210.200.0 + 255.255.255.0 的网段来划分子网\n$ sudo cat /etc/docker/daemon.json\n&#123;\n  \"default-address-pools\":[&#123;\"base\":\"10.210.200.0/24\",\"size\":28&#125;]\n&#125;\n\n其中，base 告诉我们划分子网的网段是什么(从来开始)，是从前两位(&#x2F;16)开始，还是第三位开始(&#x2F;24)呢？而 size 则告诉我们划分的每个子网有多少 IP 地址可以使用呢？从 “10.210.200.0&#x2F;24” 我们可以知道，该网络下面只有 254 个可用的 IP 地址(直接使用肯定不够)，然后我们需要给 docker 使用，划分每个子网可用 16 个 IP 地址，所以子网就应该写成 28 了。Docker 不使用默认网段\n\n\n\n24. Docker 添加私有仓库有些情况，我们服务器上面需要使用内部私有的容器镜像地址！\n\n[问题起因] 如果新机器上面需要使用私有仓库的话，但是又没有配置，再获取镜像的时候就会出现如下报错信息。\n# 拉取/登陆私库时提示\n$ docker pull 192.168.31.191:5000/nginx:latest\nx509: certificate signed by unknown authority\n\n[解决方法] 该问题的处理方式很简单，如下所示，配置一下仓库地址，重启服务并登陆私有仓库就可以了。\n# 添加配置\n$ sudo cat /etc/docker/daemon.json\n&#123;\n    \"insecure-registries\": [\"192.168.31.191:5000\"]\n&#125;\n\n# 重启docker\n$ sudo systemctl restart docker\n\n# 重新登录即可\n$ docker login 私库地址 -u 用户名 -p 密码\n\n\n25. Docker 解决时间同步解决 Docker 容器时间时区和宿主机不同步的问题！\n\n[问题起因] 有时间我们会遇到新创建的容器，容器内部和外部时间不一致，这就导致服务的日志、定时任务等不能按照我们既定的时间触发，非常麻烦。\n# 容器内部时间(CST - 东八区 - 北京时间)\n[root@server ~]# date\nFri Apr 27 22:49:47 CST 2022\n\n# 容器外部时间(UTC - 格林尼治 - 标准时间)\n[root@server ~]# docker run --rm nginx date\nFri Apr 27 14:49:51 UTC 2022\n\n[解决方法] 宿主机设置了时区，而 Docker 容器并没有设置，导致两者相差 8 小时。\n# 以 docker run 方式启动\n$ docker run -d --name 'app' \\\n    -v /etc/localtime:/etc/localtime \\\n    escape/nginx:v1\n\n# 以 Dockerfile 构建\nENV TimeZone=Asia/Shanghai\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n# 以 docker-compose 方式启动\nenvironment:\n  TZ: Asia/Shanghai\n\n\n26. Docker 容器磁盘不足启动很多容器服务，导致存储和运行的容器目录(&#x2F;var&#x2F;lib&#x2F;docker&#x2F;)磁盘消耗很大！\n\n[问题起因] 服务器使用久了，就会出现磁盘不足的问题，这时候就需要排除到底是什么服务或者数据导致的。但如果使用容器化部署服务的话(docker)，大多数都是因为启动的容器导致，即启动的服务占用了大量的磁盘空间。Docker 容器导致磁盘不足\n\n[分析思路] 我们知道 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2 目录下的文件夹名基本都是以 md5 编码命名的，而 overlay2 是 docker 使用的文件存储驱动，也就是说该目录里面存储的就是现在服务器运行的容器。同时，我们知道镜像是分层的结构，所以这容器每次层都在这里得到了体现。\n# 查看容器的默认文件驱动\n$ docker info | grep \"Storage Driver\"\nStorage Driver: overlay2\n\n# 查看磁盘消耗大户\n$ sudo du -sh /var/lib/docker/overlay2\n900G    /var/lib/docker/overlay2\nDocker 容器导致磁盘不足\n\n[分析思路] 如果我们临时启动了一个服务，当时只是打算只是临时使用，但是后续因为某些原因导致长期使用。同时因为运行中产生的数据或者文件并没有挂载映射到宿主机，导致写入容器内本地的文件最终到了一个很大的量级(比如容器产生的日志文件、数据文件)。这就导致我们看到，对应层下面 diff 和 merged 目录很大的原因。\n\ndiff -&gt; 保存的就是差分信息 -&gt; 容器的可读可写层且初始为空\nmerged -&gt; 容器运行时才会出现的存储情况集合 -&gt; 容器的挂载点\nupperdir -&gt; 容器层\nlowerdir -&gt; 初始镜像层\n\n\n\n# 里面到底存储的啥\n# diff文件夹占用100G+，merged文件夹占用200+G\n$ sudo ls -lh /var/lib/docker/overlay2/1e3137...9706bca6\ndrwxr-xr-x  10 root root  4096 8月   5  2021 diff/   # 大\n-rw-r--r--   1 root root    26 8月   5  2021 link\n-rw-r--r--   1 root root   376 8月   5  2021 lower\ndrwxr-xr-x   1 root root  4096 8月   5  2021 merged/ # 大\ndrwx------   3 root root  4096 4月  24 12:22 work/\n\n# link文件的内容对应了/var/lib/docker/overlay2/l的文件夹名称\n# 保存了镜像层的短标识；用于解决mount参数中长字符超过页大小限制的问题\nDocker 容器导致磁盘不足\n\n[解决方法] 宿主机设置了时区，而 Docker 容器并没有设置，导致两者相差 8 小时。\n\n# 查看那个容器层占用了大量磁盘空间\n$ sudo du -sh /var/lib/docker/overlay2/* | grep G | sort -rn\n121G    1e3137...9706bca6\n33G     9d50b3...ef3ae1b0\n12G     462157...03ce3935\n\n# 查找对应层所属于那个容器镜像\n$ docker ps -q | \\\n    xargs docker inspect --format '&#123;&#123;.State.Pid&#125;&#125;, &#123;&#123;.Id&#125;&#125;, &#123;&#123;.Name&#125;&#125;, &#123;&#123;.GraphDriver.Data.WorkDir&#125;&#125;' | \\\n    grep xxx\n\n# 可以根据容器id和名称查看他的层数信息(从低到高)\n$ docker inspect xxx | grep -E \"LowerDir|UpperDir|MergedDir|WorkDir\"\n\n# 在该目录下也存在一个同样名字容器的文件夹(xxx)\n$ ls -lh /var/lib/docker/image/overlay2/layerdb/mounts/\nfff30d...bc6a0222\n8078cf...73bda80b\nb801ce...cc78e234\n\n# mount-id: 表示了我们刚才创建的容器的目录(/var/lib/docker/overlay2)\n$ ls -lh /var/lib/docker/image/overlay2/layerdb/mounts/ff30d...bc6a0222/\n-rw-r--r--  1 root root    69 8月   5  2021 init-id\n-rw-r--r--  1 root root    64 8月   5  2021 mount-id\n-rw-r--r--  1 root root    71 8月   5  2021 parent\n","slug":"Docker/Docker疑难杂症汇总","date":"2020-06-23T05:32:16.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Anchor"},{"id":"49c4631107889bc801e70cd25dbb2b0a","title":"SpringMVC项目实现Session共享","content":"\n\n\n\n\n\n\n\n\n近期接到一个老项目的改造工作，需要将其由单商户单节点应用 SAAS 化，由于老项目基于 SpringMVC 构建，未做前后端分离，无法直接接入现有平台 JWT，综合考虑继续沿用 Session 机制，使用 Spring Session 实现集群 Session 共享。事情不复杂，主要难点在于处理各种老 jar 包间的冲突问题，经过一下午尝试发现以下版本 jar 包不会触发彩蛋，特记录以下。\n1、pom.xml 添加项目依赖&lt;dependency>\n    &lt;groupId>redis.clients&lt;/groupId>\n    &lt;artifactId>jedis&lt;/artifactId>\n    &lt;version>2.6.2&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n    &lt;groupId>org.springframework.session&lt;/groupId>\n    &lt;artifactId>spring-session-data-redis&lt;/artifactId>\n    &lt;version>1.3.5.RELEASE&lt;/version>\n&lt;/dependency>\n\n2、web.xml 添加拦截器&lt;filter>\n    &lt;filter-name>springSessionRepositoryFilter&lt;/filter-name>\n    &lt;filter-class>org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class>\n&lt;/filter>\n&lt;filter-mapping>\n    &lt;filter-name>springSessionRepositoryFilter&lt;/filter-name>\n    &lt;url-pattern>/*&lt;/url-pattern>\n&lt;/filter-mapping>\n&lt;context-param>\n    &lt;param-name>contextConfigLocation&lt;/param-name>\n    &lt;param-value>classpath:spring-session-redis.xml&lt;/param-value>\n&lt;/context-param>\n\n\n\n\n\n\n\n\n\n\n补充一句，注意此处，springsession 拦截器位置要尽量靠上，实际操作中发现如果放在拦截器第一位可能导致中文乱码，建议放在SetCharacterEncoding之后~\n3、applicationContext.xml 添加配置 &lt;bean id=\"jedisConnectionFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\">\n        &lt;property name=\"hostName\" value=\"$&#123;config.redis.host&#125;\"/>\n        &lt;property name=\"port\" value=\"$&#123;config.redis.port&#125;\"/>\n        &lt;property name=\"password\" value=\"$&#123;config.redis.auth&#125;\"/>\n        &lt;property name=\"database\" value=\"$&#123;config.redis.index&#125;\" />\n    &lt;/bean>\n&lt;bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.StringRedisTemplate\">\n        &lt;property name=\"connectionFactory\" ref=\"jedisConnectionFactory\" />\n    &lt;/bean>\n\n&lt;bean id=\"redisHttpSessionConfiguration\" class=\"org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration\">\n        &lt;property name=\"maxInactiveIntervalInSeconds\" value=\"7200\" />\n    &lt;/bean>\n\n4、验证这就不再啰嗦了，可根据自己习惯，配置 Nginx+Docker 等方式快速验证。\n","slug":"Java/SpringMVC项目实现Session共享","date":"2019-12-11T12:22:12.000Z","categories_index":"JAVA","tags_index":"Session,SpringMVC","author_index":"Anchor"},{"id":"ad849fabb64e7ddec346e0f489d0c75c","title":"Kafka同组下多消费者仅一个消费者消费的情况处理","content":"1、问题描述线上某个服务有多个节点，每个节点都有一个消费者消费 Kafka 消息，查看日志发现仅有一个服务的消费者在正常运行，其他全部罢工中\n2、问题定位同组下监听同一 topic 中有多个消费者，但是只有一个消费者消费，一般情况是因为 Kafka 设置的partition的数量为 1,本地验证修改partition数量，问题消失。\n3、解决办法在 kafka 服务器下运行如下命令修改 kafka 的partition\n./kafka-topics.sh --zookeeper localhost:2181 --alter --topic topic名称 --partitions 10\n\n备注：topic 名称为正在使用的 topic 名称，后面那个数量为需要设置的 partition 的数量，这里设置为 10\n4、总结与扩展又查阅了相关资料，总结了一下 kafka 中 partition 和消费者的对应关系如下：\n\n消费者多于 partition同一个 partition 内的消息只能被同一个组中的一个 consumer 消费。当消费者数量多于 partition 的数量时，多余的消费者空闲。\n例子：\n有消息 1，2，3，4，5，6，7，8，9 ，partition 数量为 1，消费者数量为 2\nc1 消费：1，2，3，4，5，6，7，8，9\nc2 消费：\n\n消费者小于 partition\n（1）.partition 不是消费者倍数\n  会有多个partition对应一个消费者\n\n  例子：\n\n  有消息1，2，3，4，5，6，7，8，9      partition数量为3，消费者数量为2\n\n  c1消费：1，3，4，6，7，9\n\n  c2消费：2，5，8\n\n（2）.partition 是消费者倍数\n  消息在同一个组之间的消费者之间均分\n\n  例子：\n\n  有消息1，2，3，4，5，6，7，8，9      partition数量为3，消费者数量为3\n\n  c1消费：2，5，8\n\n  c2消费：3，6，9\n\n  c3消费：1，4，7\n\n\n多组同 topic 情况\n每个组都会消费同样的消息，同一消息会被多组消息\n  例子：\n\n  消息 1，2，3，4，5，6，7，8，9 `partition` 数量为 3，g1 组消费者数量为 3，g2 组消费者数量为 1\n\n  g1 组：\n\n  c1 消费：2，5，8\n\n  c2 消费：3，6，9\n\n  c3 消费：1，4，7\n\n  g2 组：\n\n  c1 消费：1，2，3，4，5，6，7，8，9\n\n\n\n","slug":"Kafka/Kafka同组下多消费者仅一个消费者消费的情况处理","date":"2019-04-10T12:42:52.000Z","categories_index":"JAVA","tags_index":"Kafka","author_index":"Anchor"}]